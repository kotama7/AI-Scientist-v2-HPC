[
    {
        "Name": "himeno_variability_fingerprint",
        "Title": "Himeno Variability Fingerprints: Minimal Probes + Distribution-First Reporting for Reproducible Stencil Benchmarking",
        "Short Hypothesis": "Himeno Bench performance instability on modern CPU nodes is mostly structured and driven by a small set of user-space-controllable factors\u2014primarily first-touch/NUMA page placement and OpenMP affinity/scheduling. A minimal, standardized probe suite (\u224812 conditions) combined with distribution-first reporting (median + dispersion + tail) can (i) produce a compact, repeatable \"variability fingerprint\" that diagnoses sensitivity/misconfiguration and (ii) automatically choose a stable configuration that significantly reduces run-to-run variance with negligible loss in median MFLOPS. Himeno is the right setting because it is simple, widely used, and memory-hierarchy dominated, so these effects are amplified and measurable without special hardware or privileged access.",
        "Related Work": "Stencil/Jacobi literature largely optimizes median throughput (blocking, vectorization, bandwidth modeling) and typically reports a single performance number. HPC best-practice guidance recommends pinning and first-touch, and OS-noise work discusses jitter, but these are rarely integrated into a benchmark\u2019s *official methodology* or outputs. This proposal is distinct by: (1) making variability a first-class benchmark output rather than an artifact; (2) embedding a standardized, controlled perturbation (probe) suite into Himeno to elicit and attribute variability; and (3) defining a compact fingerprint and a stability-oriented configuration selector. This is not a trivial tuning note: it changes what Himeno reports and how it is run for reproducible, comparable evaluation.",
        "Abstract": "Himeno Bench is a popular proxy for memory-hierarchy performance via a Jacobi-style 3D stencil, yet on modern multi-core and multi-socket CPUs its MFLOPS can fluctuate substantially across runs and configurations. Such variability undermines reproducibility and can invert cross-system rankings when only a single-number result is reported. We propose a minimal, lab-feasible refinement of Himeno that treats variability as a primary observable. The benchmark is augmented with low-overhead per-iteration timing and a standardized probe suite that toggles two dominant instability mechanisms accessible in user space: first-touch/NUMA page placement (serial vs parallel initialization) and OpenMP runtime behavior (affinity binding and scheduling). Repeated runs over a small probe matrix yield distributional metrics (median, IQR, coefficient of variation, p95/p99) and a compact variability fingerprint quantifying sensitivity to NUMA and runtime settings. Using the same measurements, we automatically recommend a stable configuration that minimizes variability subject to a small median-performance budget. Across multiple node types and deliberately induced misconfigurations, we expect fingerprints to be repeatable, to expose cross-socket allocation and poor pinning, and to reduce run-to-run variance with near-zero throughput loss. The result is a practical methodology and reporting format that improves the scientific defensibility and comparability of Himeno-based HPC evaluation.",
        "Experiments": [
            "Instrumentation & overhead: Add per-iteration timing and report median/IQR/CV/p95/p99 for (a) all iterations and (b) steady-state iterations after discarding the first K (e.g., K=5). Validate overhead by comparing median MFLOPS with/without instrumentation (<1\u20132%).",
            "Minimal probe matrix (12 conditions, fixed across platforms): Init/placement: serial first-touch vs parallel first-touch (2). Affinity: OMP_PROC_BIND={false,close,spread} (3). Schedule: OMP_SCHEDULE={static,guided} (2). Total 2\u00d73\u00d72=12.",
            "Repetition protocol: For each condition run 30 repetitions. Metrics: median MFLOPS, CV of total time, CV of steady-state iteration time, and tail ratio p99/median.",
            "Fingerprint definition (simple and interpretable): Compute three sensitivity scores using CV and tail metrics: (1) NUMA-sensitivity = average |CV(serial)\u2212CV(parallel)| over runtime settings; (2) Runtime-sensitivity = range(CV) across affinity/schedule settings averaged over init; (3) Tail-sensitivity = range(p99/median) across all probe conditions. Report fingerprint + recommended config.",
            "Stability-oriented selector: Choose configuration minimizing CV subject to \u22643% median MFLOPS loss relative to the best-median condition. Compare against baselines: default, pin-only (close), and best-median. Report CV reduction factor and tail reduction.",
            "Misconfiguration detection: Induce controlled bad cases: (i) initialize with 1 thread then run with many threads (poor first-touch), (ii) disable binding to encourage migration. Verify fingerprint spikes and selector recovers a stable config.",
            "Cross-node repeatability & ranking stability: Run on \u22653 node types; repeat on different days. Evaluate fingerprint repeatability (Spearman correlation across days) and rank flip rate when comparing systems using (a) single MFLOPS vs (b) distribution-first reporting (median + IQR/CV)."
        ],
        "Risk Factors and Limitations": [
            "Semantic Scholar searches returned no directly matching papers in this workflow; novelty must be double-checked via manual scans of SC/ICS/IPDPS proceedings and vendor docs during paper writing.",
            "If external noise dominates (shared nodes, background daemons), probe attribution may weaken; mitigation: measure a noise floor, prefer reserved nodes, and report it explicitly.",
            "Some systems enable automatic NUMA balancing that can blur first-touch effects; document behavior and treat as a confounder if it cannot be disabled at user level.",
            "The minimal probe suite intentionally omits factors like frequency scaling, huge pages, and MPI effects; future extensions can add probes, but the core contribution must remain simple and standardized.",
            "Compiler/codegen differences can confound variability; must standardize build flags and verify numerical equivalence and similar instruction mix."
        ]
    },
    {
        "Name": "himeno_phase_locked_benchmark_v2",
        "Title": "Phase-Locked Himeno v2: Automatic Steady-State Detection and Minimal Preconditioning for Stable Stencil Benchmarking",
        "Short Hypothesis": "Himeno\u2019s run-to-run variability on modern HPC nodes is largely caused by (a) early-run transients (page faults, cache/TLB warmup, NUMA settling) and (b) time-varying CPU operating points (DVFS/turbo/thermal limits) that make \u201ctime the whole run\u201d a mixture of regimes. A benchmark that (1) explicitly detects when iteration time has reached a statistically stable regime and (2) uses a short, standardized, user-space preconditioning step to reduce sensitivity to initial conditions will produce substantially lower variance and fewer rank flips across systems than fixed warmup heuristics\u2014without requiring privileged controls (e.g., disabling turbo) and without changing the core Himeno kernel.",
        "Related Work": "Most Himeno/stencil work focuses on optimizing median throughput (loop transformations, blocking, vectorization) and typical benchmarking practice uses ad hoc warmup (discard first K iterations) plus environment tuning (pinning, first-touch). OS-noise and DVFS effects are widely discussed, but existing benchmark methodologies rarely (i) separate transient vs steady-state phases algorithmically or (ii) report the transient duration as a first-class output. This proposal differs by turning phase behavior into an explicit, automatically detected quantity and by adding a minimal, deterministic preconditioning routine that standardizes initial conditions in a portable way. It is not a trivial \u201cdo warmup\u201d tweak: the key contribution is an adaptive, phase-aware measurement protocol embedded in the benchmark, yielding comparable steady-state metrics across nodes and across days.",
        "Abstract": "Himeno Bench is a widely used Jacobi-style 3D stencil benchmark, yet on modern multi-core and multi-socket CPUs its reported MFLOPS often fluctuates across runs due to memory-hierarchy transients and time-varying CPU operating conditions. Such instability reduces the benchmark\u2019s value for fair system comparison.\n\nWe propose Phase-Locked Himeno, a benchmark methodology that makes phase behavior explicit and measures only after a detected steady-state is reached. The benchmark records lightweight per-iteration timings and applies a simple online stability test over a sliding window to determine when iteration time has converged. To reduce sensitivity to initial conditions, we add a minimal preconditioning sequence: a parallel page-touch sweep matching the kernel\u2019s access pattern, followed by a brief \u201cpower settle\u201d mini-run to reduce DVFS/turbo settling effects. The benchmark then reports (i) transient length, (ii) steady-state MFLOPS distribution (median and dispersion), and (iii) a stability score.\n\nThe expected outcome is a portable, user-space approach that reduces run-to-run variance and rank flips without requiring root privileges or heavy external harnesses. Beyond improving Himeno\u2019s practicality, the phase-aware methodology can generalize to other iterative, memory-bound benchmarks that suffer from similar transient and operating-point effects.",
        "Experiments": [
            "Baseline characterization: Run unmodified Himeno and record total runtime MFLOPS over 30 repetitions under two common settings (pinned vs unpinned). Report variance (CV), tail ratio (p95/median), and rank-flip rate between two nodes when using single-number MFLOPS.",
            "Per-iteration timing instrumentation: Add timing once per iteration (or every 2 iterations) using CLOCK_MONOTONIC_RAW. Verify overhead by comparing median MFLOPS against baseline (target <2% change).",
            "Steady-state detector (kept simple): Use a sliding window W=20 of iteration times. Declare steady-state when the window median changes by <1% for S=3 consecutive windows AND (MAD/median) <2%. Compare against fixed warmup K (e.g., K=5,10,20). Metrics: steady-state start iteration, steady-state MFLOPS median, and steady-state CV.",
            "Minimal preconditioning ablation: Evaluate four modes\u2014none, page-touch only, power-settle only, both. Page-touch: one parallel write pass over arrays in the same loop nest order as the kernel. Power-settle: run 1 second of the kernel on the same grid but reduced iteration count (time-based stop).",
            "Stability improvement evaluation: For each mode, perform 30 repetitions and report (a) steady-state CV reduction factor vs baseline, (b) p95/median reduction, and (c) difference between best-median MFLOPS and phase-locked median MFLOPS (ensure no artificial inflation).",
            "Cross-day repeatability: Repeat the above on two separate days on the same nodes. Evaluate repeatability of (i) transient length and (ii) phase-locked steady-state MFLOPS (difference in medians, and Spearman correlation across conditions).",
            "Optional attribution (best-effort, not required): If accessible, log user-space CPU frequency (cpufreq) or RAPL energy and correlate stabilization with detected steady-state onset to support the DVFS/thermal interpretation."
        ],
        "Risk Factors and Limitations": [
            "If interference is highly non-stationary (shared nodes), a single steady-state may not exist; mitigation is to report a non-stationarity flag when the detector cannot converge.",
            "Preconditioning may be criticized as altering the benchmark; mitigation is to keep it short, deterministic, and to report both raw and phase-locked results, emphasizing improved comparability rather than peak score.",
            "Detector thresholds might not be universally optimal; mitigation is a small sensitivity study and conservative defaults that favor robustness over aggressiveness.",
            "Some systems\u2019 variability is dominated by NUMA misplacement; phase-locking improves stability but may not fix low median performance unless combined with standard pinning/first-touch guidance."
        ]
    },
    {
        "Name": "himeno_counterfactual_runtime",
        "Title": "Counterfactual Himeno: Isolating Runtime/OS Noise from Memory-System Limits via In-Run Synthetic Twins",
        "Short Hypothesis": "Much of Himeno\u2019s run-to-run variability is not inherent to the stencil kernel but arises from exogenous, time-varying execution conditions (OS noise, thread migration, DVFS/thermal excursions, contention) that are hard to control and differ across sites. If we embed a lightweight, \u201ccounterfactual twin\u201d measurement inside the same run\u2014constructed to match the kernel\u2019s memory traffic but be minimally sensitive to scheduling and compute\u2014then we can decompose observed performance into (i) memory-system-limited throughput and (ii) interference/runtime-limited slowdown. This is best studied in Himeno because it is memory-bound, iterative, and simple enough that a paired in-run control can be made comparable without specialized hardware counters or privileged access.",
        "Related Work": "Prior Himeno/stencil work largely targets higher median performance (blocking, vectorization) or recommends best practices (pinning, first-touch). OS-noise literature and microbenchmark suites quantify jitter, but they are typically external to the benchmark and do not provide an in-run paired control that experiences the same instantaneous system conditions. Existing reproducibility guidance also rarely yields a quantitative decomposition attributing how much of a specific run\u2019s slowdown is due to interference versus the platform\u2019s memory capability. This proposal is distinct by introducing an in-situ, paired \u201csynthetic twin\u201d that runs interleaved with the real kernel inside the same process and time window, enabling counterfactual attribution without root access, external profilers, or platform-specific counters.",
        "Abstract": "Himeno Bench is widely used to characterize HPC node performance through a Jacobi-like 3D stencil, yet its results can fluctuate substantially on modern systems due to runtime and system effects that are difficult to control (OS noise, thread migration, DVFS/thermal dynamics, background contention). This variability undermines comparability across runs and across platforms.\n\nWe propose Counterfactual Himeno, a benchmark refinement that embeds an in-run paired control (\u201csynthetic twin\u201d) designed to approximate the memory-traffic profile of the stencil while being less sensitive to compute throughput and scheduling artifacts. Each measurement epoch alternates between (A) the standard Himeno iteration block and (B) a twin block that performs deterministic streaming/strided reads and writes over the same arrays with matched working-set size and similar access ordering. Because both blocks execute back-to-back under nearly identical instantaneous system conditions, the ratio and differential of their times provides a counterfactual estimate of how much observed slowdown is attributable to interference/runtime conditions versus the platform\u2019s effective memory throughput.\n\nThe benchmark reports not only MFLOPS but also (i) a \u201cmemory-capability index\u201d from the twin, (ii) an \u201cinterference index\u201d quantifying excess slowdown in the stencil beyond what the twin predicts, and (iii) distributional stability metrics over epochs. We expect this decomposition to reduce rank flips, improve diagnosis of misconfiguration (NUMA/affinity) versus environmental noise, and enable more scientifically defensible Himeno-based evaluations without requiring privileged controls.",
        "Experiments": [
            "Design of the synthetic twin (two candidates): (T1) streaming triad-like pass over the same 3D arrays in the same loop nest order as Himeno (read a,b,c; write a) with minimal arithmetic; (T2) strided gather/scatter that matches Himeno\u2019s stencil neighbor-touch count but uses precomputed index offsets to avoid compute. Validate that twin bandwidth correlates with platform STREAM-like behavior (where available) and is stable within-run.",
            "Interleaved epoch protocol: Run E epochs; each epoch executes K Himeno iterations followed by one twin pass over the full domain. Record per-epoch times for Himeno and twin. Choose small K (e.g., 5\u201310) to track time variation without excessive overhead. Report overhead (<5%) by comparing to baseline Himeno total time.",
            "Counterfactual attribution model: Fit a simple linear predictor per run: time_himeno_epoch \u2248 \u03b1 * time_twin_epoch + \u03b2. Define Interference Index = (observed - predicted)/predicted aggregated over epochs (median and p95). Evaluate whether this index increases under induced noise (background CPU load, forced thread migration by disabling binding) while memory-capability index remains similar.",
            "NUMA/affinity sensitivity: Compare serial vs parallel first-touch and OMP_PROC_BIND close/spread/false. Test whether changes that primarily affect memory locality shift both Himeno and twin similarly (captured by \u03b1), while pure scheduling noise shifts Himeno more than twin (captured by interference index).",
            "Reproducibility and rank stability: Across \u22653 node types and two days, run 30 repetitions per configuration. Compare ranking stability using (a) raw MFLOPS, (b) twin memory-capability index, and (c) MFLOPS normalized by predicted memory capability (residual-based score). Metrics: coefficient of variation, p95/median, and rank-flip rate across repetitions.",
            "Ablation: (i) twin on same arrays vs separate arrays (to test cache/TLB interaction), (ii) twin frequency (every epoch vs every 2\u20133 epochs), (iii) twin access order (i-j-k vs k-j-i) to assess sensitivity to prefetching and cache behavior."
        ],
        "Risk Factors and Limitations": [
            "Twin fidelity risk: the synthetic twin may not match Himeno\u2019s effective memory behavior (e.g., different reuse, prefetch, write-allocate effects), weakening attribution. Mitigation: keep twin variants simple, report correlation and choose the best-matching twin per platform using a fixed selection rule.",
            "Measurement perturbation: interleaving twin passes may change cache state and thus alter Himeno performance. Mitigation: use separate arrays for twin (ablation), or insert a short cache-neutralization step; always report baseline Himeno alongside counterfactual results.",
            "Interference may affect twin similarly to Himeno (e.g., DVFS changes both), reducing separability. Mitigation: the goal is not perfect causality but a practical decomposition; evaluate under controlled induced noise to quantify sensitivity.",
            "Some environments restrict controlling affinity/NUMA, limiting diagnostic power; however, the method still provides within-run stability metrics and normalized scores.",
            "No direct literature was retrieved via the provided search tool; novelty claims should be validated by manual scanning of SC/ICS/IPDPS reproducibility papers and in-situ microbenchmarking work during writing."
        ]
    },
    {
        "Name": "himeno_affinity_autotuner",
        "Title": "Self-Calibrating Himeno: A 2-Second Affinity/NUMA Autotuner That Locks In Stable Stencil Performance",
        "Short Hypothesis": "A large fraction of Himeno Bench\u2019s run-to-run and node-to-node variability is not irreducible \u201csystem noise\u201d but configuration-induced (thread placement, first-touch NUMA placement, and OpenMP scheduling). If the benchmark contains a tiny, standardized self-calibration phase that (i) probes a small set of affinity/placement options and (ii) selects a configuration optimizing stability-first (low dispersion) under a strict time budget (e.g., 2 seconds), then Himeno can produce substantially more reproducible results (lower CV, fewer rank flips) while remaining fair, portable, and affordable. Himeno is the right setting because its kernel is simple and memory-bound, so locality/placement misconfigurations produce large, measurable swings that a short probe can detect reliably without privileged controls.",
        "Related Work": "Most stencil/Himeno work emphasizes peak/median throughput via blocking/vectorization and reports a single MFLOPS number; reproducibility guidance often recommends manual pinning/first-touch but does not embed an automatic, time-bounded, stability-oriented selection mechanism into the benchmark itself. Autotuning exists broadly in HPC (loop/block-size tuning), but applying a micro time-budgeted tuner specifically for (a) affinity/NUMA/OMP runtime choices and (b) stability-first objective (dispersion and tails, not just mean) as an *integrated benchmark methodology* appears underexplored for Himeno-like benchmarks. This proposal is distinct from prior ideas (fingerprints, phase-locking, synthetic twins) by making Himeno self-configuring with a strict, standardized calibration budget and a stability-centric objective function, producing a single recommended \u201clocked\u201d run configuration plus auditable evidence.",
        "Abstract": "Himeno Bench is widely used to evaluate HPC nodes via a Jacobi-style 3D stencil, yet its reported MFLOPS can fluctuate substantially across runs on modern multi-socket CPUs. A key practical cause is that performance is highly sensitive to user-space execution conditions\u2014thread affinity, NUMA page placement, and OpenMP scheduling\u2014whose defaults vary across systems and job launchers.\n\nWe propose Self-Calibrating Himeno, a minimal benchmark refinement that performs a short, standardized calibration phase (\u22642 seconds) to automatically select a stable execution configuration before the official measurement. The calibration runs a small probe set spanning: (i) first-touch policy (serial vs parallel initialization), (ii) OpenMP binding policy (close vs spread vs unbound), and (iii) schedule (static vs guided). For each candidate, the benchmark collects per-iteration timings over a brief window and computes a stability score combining dispersion (MAD/median) and tail risk (p95/median). The selected configuration minimizes instability subject to a small performance guardrail (e.g., within 2\u20133% of the best median among probed candidates). The benchmark then executes the official run using the locked configuration and reports both the final MFLOPS and the calibration evidence.\n\nThis approach turns fragile, manual environment tuning into a portable, auditable, and low-overhead procedure. We expect it to reduce run-to-run variance, improve cross-system comparability, and decrease ranking reversals in benchmark reporting without requiring privileged controls or expensive tooling.",
        "Experiments": [
            "Implement calibration phase: add a 2-second (configurable) probe budget. Probe candidates: Init={serial first-touch, parallel first-touch}; Bind={close, spread, false}; Schedule={static, guided}. Total 12 candidates. Use fixed small iteration count per candidate (or time-sliced) to fit budget.",
            "Stability score definition: for each candidate, record iteration times for a short window (e.g., 30\u201350 iterations). Compute median iteration time, MAD/median, and p95/median. Define score = w1*(MAD/median)+w2*(p95/median-1). Choose default weights (e.g., w1=1, w2=1) and perform a small sensitivity check.",
            "Selection rule with guardrail: select candidate with lowest stability score among those whose median MFLOPS is within X% (e.g., 3%) of the best-median candidate. Compare to baselines: (a) system default, (b) \u201cbest-median\u201d candidate, (c) manual pin-close + parallel first-touch.",
            "Variance reduction study: on at least 3 different CPU nodes (single- and dual-socket), run 30 repetitions for each baseline and for Self-Calibrating Himeno. Metrics: MFLOPS median, coefficient of variation (CV) across repetitions, p95/median, and rank-flip rate when comparing nodes.",
            "Misconfiguration robustness: induce common pitfalls\u2014initialize with 1 thread then run with many; disable binding; oversubscribe threads. Evaluate whether calibration selects a more stable configuration and whether it flags instability when no stable candidate exists (e.g., score above threshold).",
            "Overhead and fairness: report calibration overhead as fraction of total runtime for small/medium/large problem sizes. Verify that the locked configuration does not artificially inflate scores by also reporting the best-median candidate and the default candidate outcomes.",
            "Portability check: test with two OpenMP runtimes (e.g., GCC libgomp vs LLVM libomp or Intel oneAPI if available) to ensure the approach remains effective and the probe set remains interpretable."
        ],
        "Risk Factors and Limitations": [
            "Calibration may overfit to short-window behavior and pick a configuration that is stable in the probe but not over long runs; mitigate by using per-iteration stability metrics and validating on longer official runs.",
            "Some systems restrict or ignore affinity controls in batch environments, reducing the tuner\u2019s action space; mitigate by detecting ineffective binding (via observed thread migration if available) and reporting a \u201ccontrols unavailable\u201d flag.",
            "A fixed 12-candidate probe set may miss optimal settings (e.g., finer-grained affinity, chunk sizes); the goal is not global optimality but robust stability improvement under a strict, standardized budget.",
            "If dominant variability comes from external contention (shared nodes, noisy neighbors), tuning may not help; mitigate by reporting residual instability and recommending reserved-node methodology.",
            "Auto-NUMA balancing or transparent huge pages can blur first-touch effects and make results less interpretable; document OS settings when possible and include them in the benchmark output metadata."
        ]
    },
    {
        "Name": "himeno_traffic_shaping",
        "Title": "Traffic-Shaped Himeno: Can Tiny, Deterministic Memory-Traffic Shaping Eliminate Stencil Benchmark Jitter?",
        "Short Hypothesis": "A substantial fraction of Himeno\u2019s run-to-run variability on modern multi-socket CPUs is caused by uncontrolled interaction between the stencil\u2019s bursty memory access pattern and shared on-chip/off-chip resources (LLC replacement, memory-controller scheduling, prefetchers, and interconnect arbitration), which amplifies small differences in thread timing and OS noise into measurable MFLOPS swings. If we add a *minimal, standardized, deterministic* \u201ctraffic-shaping\u201d mechanism\u2014e.g., inserting a fixed micro-barrier cadence and/or per-thread phase offsets that smooth instantaneous bandwidth demand without changing total work\u2014then Himeno\u2019s performance distribution (CV, tails) will tighten significantly while median throughput drops only slightly. This setting is ideal because Himeno is memory-bound and iterative, so bandwidth-demand burstiness is a first-order effect and can be shaped in user space without privileged controls.",
        "Related Work": "Existing Himeno/stencil work largely targets median performance (tiling, vectorization, prefetching) and existing reproducibility approaches focus on controlling external conditions (pinning, first-touch/NUMA, warmup/steady-state detection). OS-noise/jitter studies and STREAM-like microbenchmarks characterize bandwidth and noise, but they do not typically propose *in-kernel demand shaping* as a benchmark methodology to reduce variance while keeping the same algorithmic kernel. This proposal differs from prior ideas (variability fingerprints, phase-locking, synthetic twins, autotuning) by introducing a new lever: shaping instantaneous memory demand to reduce sensitivity to micro-timing differences\u2014turning Himeno into a controlled stress test with a tunable \u201cburstiness knob.\u201d It is not a trivial extension because it changes the benchmark\u2019s temporal resource profile while keeping arithmetic and data volume constant, enabling a new way to study and standardize memory-system interference effects.",
        "Abstract": "Himeno Bench (a Jacobi-like 3D stencil) is widely used to approximate memory-hierarchy performance, yet on modern HPC nodes its reported MFLOPS can vary noticeably across runs even under identical pinning and NUMA settings. We hypothesize that part of this variability is endogenous: small, uncontrolled timing differences between threads create bursty, phase-aligned bandwidth demand that interacts nonlinearly with shared caches, memory controllers, and interconnect arbitration, producing amplified performance swings.\n\nWe propose Traffic-Shaped Himeno, a minimal benchmark refinement that adds deterministic, portable memory-traffic shaping while preserving the original stencil computation and total data movement. The key idea is to reduce harmful phase alignment and bandwidth bursts by (i) introducing a fixed cadence micro-barrier (or lightweight synchronization) every B planes/blocks, and/or (ii) applying deterministic per-thread phase offsets to their iteration start points so that memory requests are intentionally de-synchronized. The benchmark reports both the baseline and shaped modes, including distributional metrics (median, CV, p95/p99) and a derived \u201cburst-sensitivity\u201d score that quantifies how much shaping reduces variance.\n\nWe expect traffic shaping to significantly reduce run-to-run dispersion and tail latency with only a small median-performance cost, improving reproducibility and enabling controlled studies of memory-system contention effects using a familiar benchmark. The methodology is user-space, low-cost, and directly applicable to other memory-bound iterative kernels.",
        "Experiments": [
            "Implement shaping knobs (kept simple): (A) micro-barrier cadence: add #pragma omp barrier (or omp flush + spin) every B k-planes (e.g., B in {1,2,4,8}); (B) deterministic phase offset: before the main loop, each thread performs a fixed-size dummy memory walk over a private buffer proportional to tid (or sleeps via busy-wait for X cycles) to stagger start times; (C) combined A+B.",
            "Correctness & invariance checks: verify numerical checksum matches baseline within existing Himeno tolerance; ensure total iteration count and grid size identical; ensure shaping does not change memory footprint or data structures.",
            "Variance study protocol: on each platform, run 30 repetitions for baseline and each shaping setting under a fixed, documented pinning/NUMA policy. Metrics: MFLOPS median, coefficient of variation (CV), p95/median, p99/median, and iteration-time autocorrelation (to detect oscillations).",
            "Burst-sensitivity score: define BS = (CV_baseline - CV_shaped)/CV_baseline and similarly for tail ratios. Report BS across B values; identify whether there is a \u201csweet spot\u201d where BS is high and median loss <3\u20135%.",
            "Mechanism probing without privileged counters: record per-iteration times and compute a simple \u2018burstiness proxy\u2019\u2014the standard deviation of iteration times across threads at a barrier point (using omp reduction to collect per-thread timestamps). Test whether shaping reduces cross-thread skew and whether reduced skew correlates with lower run-to-run variance.",
            "Stress tests: introduce controlled micro-noise (a low-priority background thread doing periodic work) and compare how baseline vs shaped modes degrade. Hypothesis: shaped mode is less sensitive (smaller increase in CV and tails).",
            "Generality check: apply the same shaping knobs to a second stencil miniapp (e.g., 7-point heat equation reference kernel) to show the effect is not Himeno-specific."
        ],
        "Risk Factors and Limitations": [
            "Shaping may reduce variance simply by adding synchronization overhead that dominates, making results less meaningful; mitigation: enforce a strict median-performance loss budget (e.g., <5%) and always report baseline alongside shaped results.",
            "Barrier-based shaping could interact with OpenMP runtime behavior in non-portable ways; mitigation: include a barrier-free shaping option (phase offsets only) and test at least two OpenMP runtimes if available.",
            "If variability is dominated by external factors (noisy neighbors, DVFS) rather than endogenous burstiness, shaping may have limited effect; mitigation: quantify when shaping helps via the burst-sensitivity score and report a \u2018noise-dominated\u2019 regime.",
            "Dummy-work phase offsets might inadvertently perturb caches/TLBs; mitigation: use a small private buffer (fits in L1/L2) and include an ablation (busy-wait vs memory-walk).",
            "Novelty risk: similar ideas may exist in \u2018bandwidth throttling\u2019 or \u2018desynchronization\u2019 literature; mitigation: position contribution as a benchmark-methodology primitive for reproducibility and provide clear empirical evidence on Himeno."
        ]
    },
    {
        "Name": "himeno_temporal_locality_sweep",
        "Title": "Temporal Locality Sweep Himeno (TLS-Himeno): Turning a Single MFLOPS into a Memory-Hierarchy Signature with Built-In Stability Checks",
        "Short Hypothesis": "Himeno\u2019s instability and poor cross-system comparability come from an underappreciated mismatch: the benchmark reports one number, but modern nodes exhibit multiple performance regimes depending on effective temporal locality (cache/TLB reuse) and page placement. If we introduce a tiny, standardized \u201ctemporal locality knob\u201d that continuously interpolates between cache-friendly and streaming-like reuse\u2014without changing the stencil math\u2014then (i) each node yields a stable, repeatable *performance curve* (a memory-hierarchy signature) that is far more comparable than a single MFLOPS, and (ii) variability sources (NUMA misplacement, DVFS, OS noise) become diagnosable as distinct distortions of this curve. Himeno is the best setting because its kernel is simple, memory-bound, and widely deployed, so a controlled locality sweep can be embedded with minimal code changes and no privileged access.",
        "Related Work": "Most Himeno and stencil studies optimize a fixed kernel (blocking, vectorization) and report a single throughput number; reproducibility work typically focuses on controlling runtime conditions (pinning, first-touch, warmup) or reporting distributions for a single configuration. This proposal differs by changing the *benchmark question*: from \u201cwhat is MFLOPS?\u201d to \u201cwhat is the node\u2019s locality\u2013bandwidth response curve, and how stable is it?\u201d. While roofline/ECM-style modeling and cache-aware microbenchmarks exist, they are usually separate from Himeno and do not provide an integrated, portable locality sweep inside the benchmark that preserves the original stencil computation and outputs a compact signature plus stability diagnostics. This is not a trivial extension of \u2018report distributions\u2019: the core novelty is a standardized, algorithm-preserving locality parameterization that exposes multiple regimes and makes instability interpretable as curve deformation.",
        "Abstract": "Himeno Bench is a popular Jacobi-style 3D stencil benchmark, but its reported MFLOPS often varies across runs and is difficult to compare across modern HPC nodes where performance depends strongly on memory hierarchy, NUMA placement, and runtime conditions. We propose Temporal Locality Sweep Himeno (TLS-Himeno), a minimal refinement that replaces single-point measurement with a compact locality\u2013performance signature.\n\nTLS-Himeno introduces a standardized temporal-locality knob that preserves the stencil computation but controls reuse distance: each iteration updates the same grid as usual, while a lightweight, deterministic \u201ccache disruptor\u201d touches a tunable amount of auxiliary memory between iteration blocks. By sweeping the disruptor size from 0 to a few\u00d7LLC (and optionally varying page-touch policy), TLS-Himeno produces a performance curve that transitions from cache-resident to bandwidth-bound regimes. The benchmark reports (i) the curve (median MFLOPS vs disruptor size), (ii) a small set of derived signature features (knee location, slope, bandwidth plateau), and (iii) stability metrics (curve repeatability, tail behavior).\n\nWe hypothesize that these signatures are more stable and more diagnostic than a single MFLOPS: NUMA misplacement shifts the bandwidth plateau, DVFS/noise inflates tails across the sweep, and cache/TLB effects move the knee. TLS-Himeno remains affordable and portable, requiring only user-space code changes and standard OpenMP controls, enabling reproducible, interpretable comparisons across systems.",
        "Experiments": [
            "Implement temporal-locality knob: Add an auxiliary byte array D of size S bytes. Between iteration blocks (e.g., every K=5 Himeno iterations), run a parallel loop that reads/writes D with a fixed stride (e.g., 64B) to evict caches. Sweep S over {0, 0.25*LLC, 0.5*LLC, 1*LLC, 2*LLC, 4*LLC} using an estimated LLC size (fallback: sweep powers of two up to a fixed cap like 512MB). Keep disruptor access deterministic and identical across runs.",
            "Curve reporting protocol: For each S, run R=20 repetitions. Collect per-block times (not just total) and report median MFLOPS, IQR, CV, and p95/median. Output the full curve plus a compact summary.",
            "Signature feature extraction: Compute (i) knee point S* where MFLOPS drops below 90% of the S=0 value, (ii) plateau MFLOPS at largest S (bandwidth-bound), (iii) slope between 0.5*LLC and 2*LLC. Evaluate feature repeatability across days (Spearman correlation of curves; absolute deviation of features).",
            "Diagnosability study (controlled interventions): (a) NUMA first-touch: serial vs parallel initialization; (b) affinity: OMP_PROC_BIND close vs false; (c) schedule: static vs guided. Hypothesis: NUMA/affinity primarily changes plateau and overall level; cache-related effects primarily change knee; pure noise increases dispersion/tails without systematically shifting the curve.",
            "Cross-system comparability: Run TLS-Himeno on \u22653 node types. Compare ranking stability using (i) single MFLOPS at S=0 (baseline), (ii) plateau MFLOPS, and (iii) curve-based similarity (e.g., area under curve normalized). Metric: rank-flip rate across repetitions and across days.",
            "Overhead validation: Compare baseline Himeno runtime vs TLS-Himeno at S=0 and with full sweep. Target: <3% overhead for S=0 mode; full sweep remains within a practical benchmark budget (e.g., <2\u00d7 baseline runtime)."
        ],
        "Risk Factors and Limitations": [
            "The cache disruptor may be seen as \u2018changing the benchmark\u2019; mitigation: always report the original S=0 result and position the sweep as an optional standardized diagnostic mode, not a replacement for the baseline score.",
            "If disruptor behavior differs across architectures (prefetchers, write-allocate policies), the mapping from S to effective eviction may vary; mitigation: use simple sequential 64B stride and report disruptor bandwidth as a sanity check.",
            "Estimating LLC size portably can be unreliable; mitigation: use a fixed geometric sweep up to a conservative cap and derive knee features from the observed curve rather than assumed cache sizes.",
            "External noise (shared nodes) may still dominate; mitigation: TLS-Himeno explicitly reports dispersion/tails across the sweep and can flag a noise-dominated regime when curve shape is unstable.",
            "Novelty verification risk due to limited search results; mitigation: broaden manual literature scan around \u2018cache thrashing microbenchmarks\u2019, \u2018reuse distance control\u2019, and \u2018stencil benchmark methodology\u2019 in SC/ICS/IPDPS/TPDS before submission."
        ]
    },
    {
        "Name": "himeno_affinity_audit",
        "Title": "Affinity-Audited Himeno: Verifying (Not Assuming) Thread Placement and NUMA Locality for Stable Stencil Benchmarking",
        "Short Hypothesis": "A major hidden cause of Himeno Bench instability is that users and even batch systems frequently *think* they have pinned threads and correct NUMA placement, but the effective runtime placement differs across runs (cpuset constraints, OpenMP runtime quirks, nested affinity layers, migration). If Himeno itself performs a lightweight, portable \u201caffinity & locality audit\u201d at runtime\u2014measuring actual CPU placement consistency and approximate NUMA locality\u2014then (i) variability can be dramatically reduced by rejecting/repairing bad placements, and (ii) reported results become comparable because the benchmark can certify execution conditions. Himeno is the right testbed because it is simple, memory-bound, and extremely sensitive to placement, so auditing yields large, publishable effects without special hardware or root access.",
        "Related Work": "Existing Himeno/stencil papers and tuning guides typically prescribe setting OMP_PROC_BIND, KMP_AFFINITY, numactl, and first-touch, but they rarely *verify* that those settings took effect inside the benchmark. OS noise/affinity studies and tools (e.g., hwloc, numactl, taskset) exist, but they are external and not integrated into benchmark methodology or outputs. This proposal is distinct in making \u201cplacement certification\u201d part of the benchmark: Himeno reports an auditable placement certificate (thread\u2192CPU mapping stability, socket distribution, and a locality score derived from timed local-vs-remote memory touches) and can optionally fail fast or auto-correct. This shifts Himeno from a passive kernel to an actively self-validating benchmark, which is not a trivial performance tweak.",
        "Abstract": "Himeno Bench is widely used to evaluate HPC systems with a Jacobi-like 3D stencil, yet its MFLOPS often fluctuates across runs on modern multi-socket nodes. A recurring practical issue is that benchmark runs silently execute under different effective thread placements and NUMA localities than intended, due to cpuset restrictions, OpenMP runtime differences, and thread migration. As a result, two runs with identical environment variables can produce different memory access locality and performance.\n\nWe propose Affinity-Audited Himeno, a minimal extension that verifies (rather than assumes) execution conditions. At startup and periodically during the run, the benchmark records each thread\u2019s current CPU (via sched_getcpu) and constructs a placement stability score (migration rate, entropy of CPU IDs). It also estimates NUMA locality without privileged counters by timing a small, controlled \u201clocal vs remote touch\u201d micro-probe: each thread touches a page-aligned buffer that is first-touched either on its own thread or on a designated other socket (when available), producing an empirical locality ratio. These measurements form a placement certificate reported alongside MFLOPS.\n\nUsing the certificate, the benchmark can (optionally) enforce reproducibility policies: fail-fast when migration exceeds a threshold, re-initialize arrays with parallel first-touch when locality is poor, or recommend a corrected set of OpenMP/launcher settings. We expect this auditing to reduce run-to-run variance and prevent misleading cross-system comparisons caused by silent placement mismatches, making Himeno a more reliable methodology for modern HPC evaluation.",
        "Experiments": [
            "Implement placement audit: (i) per-thread sampling of sched_getcpu() every M iterations (e.g., M=5) to compute migration count and CPU-ID entropy; (ii) record OpenMP runtime info (num threads, proc_bind, schedule) and cpuset size (via sched_getaffinity). Validate overhead (<1\u20132%) by comparing baseline MFLOPS.",
            "NUMA locality micro-probe (portable): allocate a page-aligned probe buffer per thread sized to e.g. 8\u201332 MB total. Two modes: A) local-first-touch (each thread initializes its own buffer); B) shifted-first-touch (thread i initializes thread (i+offset) buffer) to induce remote placement when offset crosses sockets (best-effort; if single-socket or unknown topology, skip B). Time a fixed read-modify-write sweep and report locality ratio = time(B)/time(A).",
            "Certificate reporting: define a compact certificate: migration_rate (moves/sec), cpu_entropy, cpuset_coverage (unique CPUs used / allowed CPUs), locality_ratio, and a binary \u2018certified\u2019 flag when thresholds are met. Report MFLOPS with and without certification.",
            "Variance reduction study: on \u22653 nodes (including at least one dual-socket), run 30 repetitions under: (a) default environment, (b) user-specified pinning, (c) intentionally misconfigured (OMP_PROC_BIND=false, serial init then many threads, oversubscription). Compare MFLOPS median, CV, p95/median, and rate of uncertified runs. Hypothesis: many \u201cpinned\u201d runs are not actually stable; auditing detects this and reduces variance when enforcement is enabled.",
            "Enforcement policies ablation: evaluate three policies\u2014report-only, fail-fast (discard uncertified runs), and auto-repair (re-initialize arrays with parallel first-touch + recommend bind=close/spread based on observed socket distribution). Measure impact on variance and median performance; ensure auto-repair does not inflate results by also reporting the pre-repair score.",
            "Cross-runtime portability: repeat key experiments with two OpenMP runtimes (e.g., libgomp vs libomp/oneAPI if available). Evaluate whether certificate metrics remain interpretable and whether enforcement reduces variance across runtimes."
        ],
        "Risk Factors and Limitations": [
            "Remote-placement induction in the micro-probe may be unreliable without explicit NUMA APIs; mitigation: treat it as best-effort, skip remote mode when topology cannot be inferred, and still provide placement stability metrics (migration/entropy) which are useful alone.",
            "Some environments disallow thread migration sampling fidelity (e.g., very short iterations); mitigation: sample less frequently and focus on coarse migration over longer windows.",
            "Auto-repair can be viewed as changing benchmark conditions; mitigation: make it optional, always report raw + repaired results, and position the main contribution as certification and comparability.",
            "sched_getcpu and affinity APIs are Linux-centric; mitigation: provide a portability layer (fallback to reporting \u2018unknown\u2019 on unsupported OS) and keep core benchmark unchanged.",
            "If variability is dominated by external shared-node contention, certification may not reduce variance; it will still improve interpretability by separating placement-induced variability from environmental noise."
        ]
    },
    {
        "Name": "himeno_dvfs_aware_score",
        "Title": "DVFS-Aware Himeno: A Frequency-Normalized, Energy-Checked Score for Stable Stencil Benchmarking",
        "Short Hypothesis": "A large, under-controlled component of Himeno\u2019s run-to-run variability on modern CPUs comes from time-varying processor operating points (DVFS/turbo/thermal/power limits) rather than from the stencil kernel itself. If Himeno reports (1) a frequency-normalized performance score derived from per-core effective frequency estimates and (2) an energy/thermal consistency check (best-effort via user-accessible interfaces), then benchmark results become significantly more stable and comparable across runs and sites\u2014without requiring privileged actions like disabling turbo. Himeno is an ideal setting because it is memory-bound and iterative, so small frequency swings should not change the true memory-system limit much, making frequency-induced artifacts detectable and correctable in the benchmark\u2019s reporting.",
        "Related Work": "Himeno/stencil optimization papers typically focus on median throughput and assume a fixed CPU operating point; reproducibility guidance focuses on pinning/NUMA/warmup rather than explicitly modeling DVFS. DVFS and power-management effects are well-known in systems literature, and RAPL-based energy measurement is common, but these ideas are rarely integrated as a first-class, portable *scoring methodology* inside a classic HPC benchmark like Himeno. This proposal differs from prior ideas (fingerprints, phase-locking, synthetic twins, traffic shaping, locality sweep, affinity auditing) by directly targeting DVFS-induced instability with an explicit normalization and a consistency certificate, turning \u201cunknown frequency state\u201d into a measurable, reportable variable and reducing rank flips caused by opportunistic turbo or thermal throttling.",
        "Abstract": "Modern HPC CPUs frequently change operating frequency due to turbo boost, DVFS governors, power caps, and thermal limits. For memory-bound iterative benchmarks like Himeno, these dynamics can still introduce substantial variability in reported MFLOPS across runs, even when thread affinity and NUMA placement are controlled. This undermines reproducibility and cross-site comparability.\n\nWe propose DVFS-Aware Himeno, a benchmark refinement that measures and reports effective CPU operating conditions alongside performance, and derives a frequency-normalized score intended to be stable under DVFS variation. The benchmark adds lightweight per-iteration timing and periodically samples user-accessible signals: (i) APERF/MPERF (when readable) to estimate effective core frequency, and (ii) RAPL package energy (when available) to compute energy per iteration and detect throttling regimes. From these, it reports a \u201cDVFS certificate\u201d (frequency stability, throttling flags, energy drift) and a normalized performance metric that discounts frequency excursions (e.g., MFLOPS per GHz or MFLOPS adjusted to a reference frequency).\n\nWe will evaluate whether this normalization reduces run-to-run dispersion and rank flips across nodes and days, while remaining fair (no hidden boosting) and feasible (no root required). The outcome is a simple, portable methodology for making Himeno results more reproducible on modern power-managed CPUs, and a template for DVFS-aware reporting in other memory-bound benchmarks.",
        "Experiments": [
            "Instrumentation feasibility & overhead: Add per-iteration timing. Implement optional sampling backends: (A) Linux perf_event_open to read APERF/MPERF; (B) sysfs cpufreq as fallback; (C) RAPL via /sys/class/powercap (best-effort). Quantify overhead by comparing baseline median MFLOPS with/without sampling (<2%).",
            "Define DVFS certificate metrics: (i) effective frequency median and CV over steady-state iterations, (ii) frequency drift slope over time, (iii) energy per iteration median and CV, (iv) throttling flag if frequency drops >X% from median for >Y% of samples. Output these alongside MFLOPS.",
            "Normalization methods (simple ablation): Compare three reported scores: raw MFLOPS, MFLOPS_per_GHz = MFLOPS / f_eff, and reference-adjusted MFLOPS_ref = MFLOPS * (f_ref / f_eff) using f_ref as the run\u2019s median or a declared nominal base. Evaluate which best reduces variance without changing cross-platform ordering in controlled settings.",
            "Controlled DVFS perturbations (user-level): Run under different governors/settings when possible without root (e.g., within job constraints), and induce thermal/power variation using a co-running CPU stressor thread at low priority. Measure how raw MFLOPS vs normalized scores respond. Hypothesis: raw MFLOPS varies more; normalized score is more stable.",
            "Reproducibility study: On \u22653 CPU node types, run 30 repetitions across two days under fixed affinity/NUMA best practices. Compare dispersion (CV, IQR) and tail ratios (p95/median) for raw vs normalized metrics; compute rank-flip rate across nodes when using raw vs normalized scores.",
            "Fairness check: Ensure normalization does not \u2018hide\u2019 genuine memory effects by repeating experiments with a clear memory-locality change (serial vs parallel first-touch). Expectation: both raw and normalized scores shift similarly under true memory bandwidth/locality changes, while normalization mainly removes frequency-driven noise."
        ],
        "Risk Factors and Limitations": [
            "Access to APERF/MPERF and RAPL may be restricted on some systems; mitigation: implement multiple backends and clearly report \u2018unavailable\u2019 while still providing timing-based phase metrics.",
            "Frequency normalization may be criticized as over-correcting (memory-bound kernels should be less frequency-sensitive); mitigation: treat normalization as a reporting supplement, always include raw MFLOPS and the DVFS certificate, and validate that normalization reduces variance mainly under DVFS perturbations.",
            "Effective frequency estimates can be noisy under SMT and heterogeneous core behavior; mitigation: sample per-thread where possible, report dispersion across threads, and use robust statistics (median/MAD).",
            "If variability is dominated by NUMA misplacement or external contention, DVFS-aware scoring may not help; mitigation: recommend combining with standard affinity/first-touch controls and use the certificate to distinguish DVFS-driven vs locality-driven instability.",
            "Portability: the cleanest implementation is Linux-centric; mitigation: provide a minimal portable mode (timing-only + optional cpufreq) and keep DVFS-aware features optional."
        ]
    },
    {
        "Name": "himeno_time_noise_injection",
        "Title": "Noise-Injection Himeno: A Controlled \u201cJitter Transfer Function\u201d for Reproducible Stencil Benchmarking",
        "Short Hypothesis": "Himeno\u2019s run-to-run instability is not just \u201crandom noise\u201d; it reflects a system-specific sensitivity to small timing perturbations (OS jitter, daemon activity, migration, DVFS transitions) that get amplified by synchronization, memory-controller contention, and NUMA effects. If we add a tiny, deterministic, user-space jitter injector (with known amplitude/spectrum) into the benchmark, we can measure a node\u2019s \u201cjitter transfer function\u201d (how injected micro-jitter changes MFLOPS distribution and tails). This yields (i) a stable, comparable robustness metric across systems and (ii) a principled way to choose execution settings (affinity/scheduling) that minimize amplification. Himeno is the right setting because it is memory-bound and iterative, so micro-timing differences can couple strongly into shared-resource contention while remaining easy to measure without privileged access.",
        "Related Work": "Prior Himeno-focused efforts typically (a) tune for higher median MFLOPS (blocking/vectorization), or (b) improve reproducibility via pinning/NUMA/warmup and distributional reporting. OS-noise literature often measures jitter with external microbenchmarks or system-level tracing, but rarely embeds a calibrated noise source inside the target benchmark to estimate sensitivity as a first-class outcome. This proposal is distinct from earlier ideas like phase-locking, affinity auditing, synthetic twins, traffic shaping, and locality sweeps: it introduces a controlled experimental stimulus (jitter injection) to characterize and compare *robustness to noise* rather than only trying to eliminate noise or diagnose misconfiguration. The key novelty is treating the benchmark+injector as a system identification experiment that produces a reproducible robustness signature.",
        "Abstract": "Himeno Bench is widely used as a memory-hierarchy\u2013dominated 3D Jacobi stencil benchmark, yet its reported MFLOPS can vary substantially across runs on modern HPC nodes. A major challenge is that real systems exhibit small, time-varying perturbations\u2014OS jitter, background daemons, thread migration, and DVFS transitions\u2014that can be amplified by synchronization and shared memory-system resources, producing large performance swings.\n\nWe propose Noise-Injection Himeno, a minimal refinement that turns this nuisance into a measurable, comparable property. The benchmark is augmented with a lightweight, deterministic jitter injector that introduces controlled micro-perturbations during execution (e.g., periodic sub-millisecond busy-waits or cache-resident spin loops) with configurable amplitude and frequency. By sweeping a small set of injector settings and recording per-iteration timing distributions, we estimate a \u201cjitter transfer function\u201d: how injected jitter changes median throughput, dispersion (CV/MAD), and tail risk (p95/p99). This yields a robustness signature that is repeatable across days and sites because the stimulus is controlled.\n\nWe further show how robustness signatures guide stable configuration choices (affinity and OpenMP scheduling) by selecting settings that minimize jitter amplification under a fixed injection level. The result is a lab-feasible, user-space methodology that improves the scientific defensibility of Himeno-based evaluation by reporting not only peak/median performance but also robustness to realistic timing noise.",
        "Experiments": [
            "Implement deterministic jitter injector: Add an optional per-thread injector that triggers every T microseconds (or every B iterations) and executes a calibrated busy-wait for duration d (e.g., d in {0, 10us, 50us, 200us}). Keep injector cache-resident (no syscalls) and deterministic (fixed schedule).",
            "Baseline vs injected runs: For each configuration, run R=30 repetitions with injector off and on. Collect per-iteration times (or per-block times) and report MFLOPS median, CV, MAD/median, p95/median, p99/median.",
            "Jitter transfer function sweep: Sweep (d, trigger period) over a small grid (e.g., d \u2208 {10,50,200}us; period \u2208 {1ms,5ms,20ms}). For each point, compute amplification metrics: \u0394CV, \u0394(p99/median), and median MFLOPS drop. Plot robustness curves.",
            "Robustness signature features: Extract 3\u20135 compact features such as (i) slope of CV vs injected jitter amplitude, (ii) tail growth rate, (iii) \u2018critical frequency\u2019 where tails spike. Evaluate feature repeatability across two days (Spearman correlation; absolute deviation).",
            "Configuration sensitivity and selection: Repeat the sweep under a small set of runtime settings (OMP_PROC_BIND close/spread/false; OMP_SCHEDULE static/guided; serial vs parallel first-touch). Identify which settings minimize amplification at a fixed injection level while keeping median loss <3% from best-median. Compare against default and best-median-only tuning.",
            "External validity check: Introduce a realistic noise source (a low-priority background thread doing periodic work, or a co-running lightweight memory copy) and test whether the robustness signature under injection predicts which configurations have lower variance under real noise (correlation between predicted amplification and observed CV/tails)."
        ],
        "Risk Factors and Limitations": [
            "Injector realism: Busy-wait jitter may not perfectly mimic OS noise or DVFS events. Mitigation: vary injection spectrum (periodic vs pseudo-random with fixed seed) and validate predictive power against at least one realistic co-runner noise source.",
            "Perturbation side effects: Injector may change cache state or memory traffic in unintended ways. Mitigation: keep injector cache-resident, avoid touching large memory, and include an ablation comparing busy-wait vs nanosleep (where allowed) vs pure barrier delay.",
            "Benchmark acceptance: Some may argue injecting noise \u2018changes the benchmark\u2019. Mitigation: keep injector optional and always report baseline; position the contribution as an additional robustness metric and methodology, not a replacement score.",
            "If variability is dominated by uncontrollable cluster contention, robustness signatures may still vary. Mitigation: report both baseline dispersion and injection-based robustness; the controlled stimulus should still improve comparability relative to uncontrolled noise alone."
        ]
    },
    {
        "Name": "himeno_memorylayout_randomization",
        "Title": "Layout-Randomized Himeno: Measuring and Reducing Hidden Memory-Layout Sensitivity in 3D Stencil Benchmarks",
        "Short Hypothesis": "A non-trivial portion of Himeno\u2019s run-to-run and node-to-node variability is caused by *accidental* low-level memory-layout differences (heap/stack alignment, page coloring, THP placement, allocator behavior, and array base-address offsets) that change cache-set conflicts, TLB behavior, and memory-controller mapping\u2014especially on multi-socket systems. If we (1) make this sensitivity measurable by introducing a standardized, controlled \u201clayout randomization sweep\u201d (small base-address and padding perturbations) and (2) provide a simple, portable \u201clayout stabilization\u201d mode (deterministic alignment + page-sized padding + fixed allocator strategy), then Himeno can report a robust performance distribution and a new \u201clayout sensitivity index\u201d that improves reproducibility without requiring privileged controls or hardware counters. This is best investigated in Himeno because the kernel is simple and memory-bound, so subtle layout effects can dominate when other settings (affinity/NUMA) are already controlled.",
        "Related Work": "Most Himeno/stencil work focuses on raising median throughput via vectorization/blocking or on controlling runtime factors (pinning, first-touch NUMA, warmup). Reproducibility proposals for Himeno typically target OS noise, DVFS, or OpenMP settings. In contrast, this proposal targets a largely unreported but practically common source of instability: *address-level layout effects* from allocators and alignment that can change cache/TLB conflict patterns and physical-page mapping. While cache conflict and page coloring are known concepts and microbenchmarks exist, they are rarely integrated into a classic HPC benchmark methodology as a standardized sweep + stabilization protocol with an explicit reported metric. The contribution is not an optimization trick; it is a benchmark-methodology change that (i) quantifies layout sensitivity and (ii) offers a deterministic layout mode to reduce variance.",
        "Abstract": "Himeno Bench is a widely used Jacobi-style 3D stencil benchmark whose performance on modern CPUs is dominated by the memory hierarchy. Even when thread affinity and NUMA placement are carefully controlled, practitioners often observe unexplained run-to-run variability. We hypothesize that a significant part of this residual instability arises from hidden memory-layout differences: base-address alignment, allocator decisions, transparent huge pages, and physical page mapping can alter cache-set conflicts, TLB pressure, and memory-controller/interconnect routing.\n\nWe propose Layout-Randomized Himeno, a minimal refinement that makes memory-layout sensitivity a first-class, measurable property. The benchmark introduces a standardized sweep that perturbs array base addresses and padding by small, controlled offsets (e.g., 0\u20134096 bytes and page-multiple paddings) while keeping the stencil computation identical. Repeating the benchmark across offsets yields a performance distribution and a Layout Sensitivity Index (LSI) that quantifies how strongly MFLOPS depends on layout.\n\nTo improve reproducibility, we also add an optional Layout Stabilization mode: deterministic aligned allocations (e.g., 2MB alignment when available, otherwise 4KB), fixed padding to avoid pathological strides, and a consistent allocation order to reduce allocator-induced randomness. We evaluate whether stabilization reduces variance and tail risk across runs and across nodes, and whether LSI can diagnose when layout effects dominate. The result is a low-cost methodology that improves the interpretability and comparability of Himeno results on modern HPC systems.",
        "Experiments": [
            "Implement layout sweep: allocate Himeno arrays with controllable base offsets using over-allocation + manual pointer shifting. Sweep offsets in {0, 64, 128, 256, 512, 1024, 2048, 4096} bytes and (separately) page-multiple paddings between arrays (0, 4KB, 64KB, 2MB). Keep grid size and iteration count fixed.",
            "Define Layout Sensitivity Index (LSI): for each configuration, run R=20 repetitions per offset. Compute LSI = (p90(MFLOPS_offset) - p10(MFLOPS_offset)) / median(MFLOPS_offset). Also report CV across offsets and p95/median tail ratio across repetitions at each offset.",
            "Stabilization mode: add a deterministic allocator wrapper that (i) uses aligned_alloc/posix_memalign with fixed alignment (4KB and optional 2MB), (ii) inserts fixed padding between arrays, and (iii) allocates in a fixed order. Compare baseline (malloc) vs stabilized on median MFLOPS and run-to-run variance (CV, p95/p99).",
            "Interaction with known controls: repeat the sweep under two execution baselines: (A) pinned + parallel first-touch (best-practice), (B) pinned but serial initialization (NUMA-worse). Test whether layout sensitivity remains significant even when NUMA is good, and whether it compounds when NUMA is bad.",
            "Mechanism proxy without counters: add lightweight measurements of (i) page-fault counts via /proc/self/stat (best-effort), (ii) minor/major faults delta, and (iii) steady-state iteration-time distribution. Correlate LSI with fault behavior and with iteration-time variance to support the layout/TLB interpretation.",
            "Cross-platform evaluation: run on at least 3 CPU platforms (single-socket and dual-socket). Compare LSI distributions and whether stabilization consistently reduces variance. Metric: reduction factor in CV and in LSI, plus rank-flip rate when comparing nodes using single-offset MFLOPS vs layout-robust median across offsets."
        ],
        "Risk Factors and Limitations": [
            "Layout effects may be smaller than expected on some architectures or with certain allocators, limiting impact; mitigation: focus on dual-socket systems and larger problem sizes where TLB/cache pressure is higher, and treat negative results as a useful finding about robustness.",
            "Transparent Huge Pages and kernel policies can change physical mapping unpredictably; mitigation: detect THP status via /sys and report it, and treat THP as a documented confounder rather than requiring root to change it.",
            "Offset sweeps increase benchmark runtime; mitigation: keep the sweep small (8 offsets) and allow a \u2018quick LSI\u2019 mode (4 offsets) while preserving a standardized default.",
            "Some reviewers may argue this changes the benchmark; mitigation: always report the canonical (offset=0, default allocation) score alongside LSI and stabilized results, positioning LSI as an additional reproducibility diagnostic rather than a replacement score.",
            "Attributing effects to cache vs TLB vs memory-controller mapping without counters is imperfect; mitigation: rely on robust empirical signatures (consistency across offsets, correlation with page-fault/TLB-pressure proxies) and keep claims conservative."
        ]
    },
    {
        "Name": "himeno_numa_topology_stethoscope",
        "Title": "NUMA Stethoscope for Himeno: Can We Infer Topology and Locality Pathologies Using Only User-Space Timing?",
        "Short Hypothesis": "A large fraction of Himeno performance instability on modern multi-socket nodes comes from *which* memory locality regime the run accidentally falls into (local DRAM, remote DRAM, cross-CCD/NUMA domain, mixed placement). Today, diagnosing this typically requires privileged tools (numactl, hardware counters, vendor profilers) or manual expertise. Hypothesis: by embedding a tiny set of carefully designed, topology-agnostic timing probes (that reuse Himeno\u2019s own arrays and access pattern) we can infer (i) the effective NUMA domain structure visible to the process and (ii) whether the benchmark\u2019s pages are locally or remotely served\u2014purely from user-space timing\u2014then automatically choose a stable initialization/placement strategy. Himeno is the best setting because it is memory-bandwidth dominated with a regular stencil access pattern, so locality regime changes produce clear, measurable timing signatures without special hardware access.",
        "Related Work": "Common practice recommends first-touch and affinity pinning, and tools like hwloc/numactl can reveal topology, but these are external dependencies and often unavailable or inconsistently used in benchmark reporting. Prior Himeno methodology proposals (including our earlier ones) focus on distributional reporting, steady-state detection, noise injection, or DVFS-aware scoring; none directly attempt *topology inference* and *locality regime classification* inside Himeno using only timing. Microbenchmarks exist for bandwidth/latency, but they usually assume known topology and do not output a benchmark-integrated \u201clocality diagnosis + auto-fix\u201d for a stencil kernel. This proposal distinguishes itself by treating Himeno as a self-contained diagnostic instrument: it infers effective NUMA structure and page locality from controlled access/timing experiments embedded in the benchmark, then uses that information to stabilize results.",
        "Abstract": "Himeno Bench is widely used to evaluate HPC nodes via a Jacobi-style 3D stencil, yet its performance is notoriously sensitive to NUMA placement and can vary across runs even under seemingly identical settings. Diagnosing whether a run is limited by local or remote memory typically requires external tools (numactl/hwloc), hardware counters, or root-level access\u2014conditions that are often absent in shared clusters and impede reproducible benchmarking.\n\nWe propose a NUMA Stethoscope: a minimal, user-space diagnostic module integrated into Himeno that infers effective locality regimes and visible NUMA structure using only timing measurements. The stethoscope runs a short probe sequence that (i) performs controlled first-touch initialization patterns (serial, parallel, and \u201cshifted-touch\u201d where threads touch another thread\u2019s pages) and (ii) executes brief Himeno-like sweep kernels over the same arrays while recording per-thread and aggregate timings. The resulting timing matrix is used to classify the run into locality regimes (mostly-local, mostly-remote, mixed/imbalanced) and to estimate the number of distinct memory domains affecting performance (e.g., 1 vs 2+ sockets/NUMA nodes) via clustering of per-thread bandwidth signatures.\n\nUsing this diagnosis, Himeno automatically selects a stabilization action (e.g., parallel first-touch + binding recommendation) and reports a locality certificate alongside MFLOPS. The outcome is a self-contained, affordable methodology that improves comparability of Himeno results by making memory locality explicit and correctable without privileged tooling.",
        "Experiments": [
            "Implement the stethoscope probe suite (time budget <= 1\u20132 seconds): (A) serial first-touch init; (B) parallel first-touch init; (C) shifted-touch init (thread i initializes pages for thread (i+1) mod T using block ownership). After each init, run a short fixed-count sweep of the Himeno kernel (e.g., 10 iterations) and record total time and per-thread time.",
            "Define user-space locality features: (1) init_sensitivity = time(A)/time(B); (2) remote_penalty = time(C)/time(B); (3) per-thread bandwidth vector from bytes_moved / per-thread time; (4) imbalance index = std(per-thread bandwidth)/mean. These are computed without counters, using known array sizes and timings.",
            "Topology inference via clustering: cluster per-thread bandwidth vectors (e.g., k-means with k=1..4, choose k by silhouette score) to estimate the number of distinct performance groups (proxy for NUMA domains/CCDs). Validate stability of inferred k across repetitions.",
            "Locality regime classifier: simple rule-based classifier using remote_penalty and imbalance index (e.g., mostly-local if remote_penalty > 1.15 and imbalance < 0.10; mixed if imbalance >= 0.10; mostly-remote if remote_penalty <= 1.05). Evaluate classifier consistency across 30 repetitions.",
            "Auto-stabilization policy: choose initialization + recommended OMP_PROC_BIND (close/spread) that minimizes predicted imbalance and maximizes remote_penalty separation (i.e., makes locality \u2018decidable\u2019). Then run the full benchmark with the chosen policy. Compare against baseline (default) and best-practice manual (parallel first-touch + close binding). Metrics: MFLOPS median, CV across runs, p95/median, and rate of \u2018mixed/uncertain\u2019 diagnoses.",
            "Ground-truth validation (best-effort): on systems where numactl/hwloc is available, record actual NUMA node count and memory binding, and compare with inferred k and locality regime. Report agreement rates and failure modes.",
            "Cross-platform study: run on at least 3 nodes (single-socket, dual-socket, and a chiplet/CCD-heavy CPU if available). Evaluate whether the stethoscope reduces rank flips when comparing nodes using (i) raw MFLOPS vs (ii) MFLOPS + locality certificate (only certified mostly-local runs)."
        ],
        "Risk Factors and Limitations": [
            "Shifted-touch may not reliably force remote placement on all systems (auto-NUMA balancing, unknown topology, cpuset constraints). Mitigation: treat it as a perturbation, not a guarantee; report when the probe lacks separation (remote_penalty ~ 1).",
            "Clustering-based inference may confuse SMT effects or load imbalance with NUMA domains. Mitigation: include imbalance index, optionally run with SMT off if possible, and keep inference conservative (report \u2018unknown\u2019 when silhouette is weak).",
            "Probe overhead must remain small to be acceptable as a benchmark methodology change. Mitigation: strict time budget and small fixed iteration counts.",
            "External noise can distort probe timings and lead to misclassification. Mitigation: repeat probes twice and require agreement; otherwise emit \u2018uncertain\u2019 and avoid auto-fix.",
            "Novelty risk: similar ideas may exist in microbenchmark-based topology inference literature. Mitigation: position the contribution as a Himeno-integrated, stencil-pattern-specific, tool-free locality certificate and show it improves reproducibility in practice."
        ]
    },
    {
        "Name": "himeno_replayable_interference",
        "Title": "Replayable Interference Himeno: Capturing and Replaying Micro-Jitter Traces to Make Stencil Benchmark Variability Reproducible",
        "Short Hypothesis": "Himeno\u2019s run-to-run variability is often driven by short-lived, structured interference (scheduler preemption bursts, daemon wakeups, occasional migration, brief DVFS transitions) that changes iteration times in characteristic ways. If we (1) record a compact per-iteration \u201cinterference trace\u201d during a run and (2) replay that trace as a deterministic, user-space perturbation in subsequent runs, then we can convert uncontrolled variability into a reproducible experimental input. This enables fairer comparisons of mitigation strategies (pinning/first-touch/scheduling) because they can be evaluated under identical, replayed interference. Himeno is an ideal setting because it is iterative and memory-bound, so iteration-time distortions are easy to observe with low overhead and can be injected without changing the kernel math.",
        "Related Work": "Prior proposals for stabilizing Himeno typically (a) diagnose variability (fingerprints, audits), (b) avoid transients (phase-locking), (c) normalize (DVFS-aware scoring), or (d) inject synthetic jitter with simple parametric patterns. What is missing is a way to make *real* observed interference reproducible and shareable without privileged tracing. In systems research, record/replay exists for debugging, but applying a lightweight record/replay concept specifically to HPC benchmark variability\u2014at the level of iteration-time perturbations\u2014appears underexplored. This proposal is not a trivial extension of noise injection: the novelty is trace-driven replay that matches the temporal structure of interference observed on a given system/job environment, enabling controlled A/B evaluation of benchmark methodology choices under the same interference conditions.",
        "Abstract": "Himeno Bench is a widely used Jacobi-style 3D stencil benchmark whose performance on modern HPC nodes can fluctuate substantially across runs, undermining reproducibility. A key obstacle is that much of the variability comes from intermittent, structured interference\u2014brief scheduler disruptions, daemon activity, migration events, or transient frequency changes\u2014that is hard to control and differs across sites.\n\nWe propose Replayable Interference Himeno, a minimal refinement that turns uncontrolled variability into a reproducible experimental factor. The benchmark records a compact interference trace consisting of per-iteration timings (and optionally per-thread timing summaries) after a short warmup. From this trace, we derive a replay schedule that injects deterministic, user-space perturbations (calibrated busy-waits) at the same iteration indices and with amplitudes chosen to reproduce the observed slowdowns. Subsequent benchmark runs can then be executed under the same replayed interference, enabling controlled comparison of mitigation techniques (e.g., affinity policies, NUMA first-touch strategies, OpenMP schedules) under identical \u201cnoise conditions.\u201d\n\nWe will evaluate whether replayed traces reproduce key distributional properties (CV, p95/p99 tails, autocorrelation structure) and whether configuration rankings become more stable when evaluated under a fixed replay trace. The outcome is a practical, lab-feasible methodology for making variability itself reproducible, improving the scientific defensibility of Himeno-based performance evaluation and enabling shareable \u2018interference workloads\u2019 for cross-site benchmarking studies.",
        "Experiments": [
            "Trace recording: instrument Himeno to record per-iteration time for N iterations (e.g., N=200) after discarding first K warmup iterations. Optional: also record per-thread end-of-iteration timestamps to estimate skew. Quantify overhead by comparing median MFLOPS with/without instrumentation (<2%).",
            "Trace-to-replay synthesis: define slowdown_i = max(0, t_i - median(t)). Convert slowdown_i into an injected delay d_i applied once per iteration (or once per B iterations) via a calibrated busy-wait loop. Calibrate busy-wait to nanoseconds using CLOCK_MONOTONIC_RAW in a short pre-run calibration step.",
            "Replay fidelity evaluation: for a given node/config, collect 30 baseline runs (no replay) to obtain a \u2018natural variability\u2019 distribution. Then run 30 replay runs using a selected recorded trace. Compare (a) iteration-time distribution (KS distance), (b) CV and p95/p99 ratios, and (c) lag-1..lag-10 autocorrelation of iteration times between the original trace and replay runs.",
            "Controlled A/B of mitigation under identical interference: choose 3\u20134 runtime configurations (e.g., OMP_PROC_BIND close/spread/false; serial vs parallel first-touch; static vs guided). Evaluate each configuration under (i) no replay and (ii) the same replay trace. Metric: rank stability (Spearman correlation) across configurations and reduction in between-run variance when using replay as a controlled factor.",
            "Cross-trace generality: record traces in different conditions (quiet node vs loaded node; different times of day). Test whether (i) traces are distinguishable via simple features (tail mass, burstiness, autocorrelation) and (ii) mitigation strategies that help under one trace generalize to others.",
            "Trace sharing sanity check (lab-feasible): replay a trace recorded on Machine A on Machine B (same architecture if available). Evaluate what properties transfer (e.g., relative ranking of configurations) versus what does not, clarifying how to normalize trace amplitude (e.g., scale delays by median iteration time)."
        ],
        "Risk Factors and Limitations": [
            "Replay is an approximation: injected busy-waits emulate time loss but not cache pollution, migration, or DVFS side effects; replay may match timing distributions but not underlying causes.",
            "If interference affects memory-system state (e.g., cache/TLB eviction) rather than only time loss, delay-only replay may underfit; mitigation: add an optional \u2018cache-touch\u2019 replay mode that touches a small buffer to emulate eviction, with careful overhead control.",
            "Busy-wait calibration can drift with DVFS; mitigation: periodically re-calibrate or express delays in iteration-time fractions rather than absolute nanoseconds.",
            "Some reviewers may argue this changes the benchmark; mitigation: keep replay optional and always report baseline results; position replay as an experimental control for methodology research rather than a replacement score.",
            "Novelty validation risk due to limited automated literature retrieval; mitigation: broaden manual search around HPC jitter modeling, trace-driven workload replay, and benchmark reproducibility in SC/ICS/IPDPS/TPDS."
        ]
    },
    {
        "Name": "himeno_crosslayer_witness_v2",
        "Title": "Cross-Layer Witness Himeno v2: A Minimal In-Benchmark \u201cPerformance Certificate\u201d that Attributes Variability to Likely Causes",
        "Short Hypothesis": "Himeno performance varies because multiple cross-layer mechanisms (NUMA placement, thread migration, DVFS/thermal throttling, and memory-layout conflicts) can each dominate on modern nodes, yet the benchmark reports only MFLOPS. Hypothesis: a *minimal* set of short, orthogonal witness probes embedded in Himeno can produce a compact, repeatable feature vector that (i) classifies which mechanism(s) likely dominated a run and (ii) recommends one simple mitigation, thereby improving reproducibility and reducing misleading comparisons\u2014without privileged access or hardware counters.",
        "Related Work": "Himeno/stencil work typically optimizes median throughput or provides best-practice run instructions (pinning, first-touch). Reproducibility efforts often focus on one axis at a time (e.g., warmup/steady state, affinity, DVFS logging, distributional reporting). This proposal differs by integrating a *standardized, low-budget* multi-witness probe suite into the benchmark and outputting a structured Performance Certificate (cause likelihoods + suggested fix). It is not a new tuning knob or a new score; it is a benchmark-methodology change that makes runs auditable and comparable even when environments differ.",
        "Abstract": "Himeno Bench (a Jacobi-style 3D stencil) is widely used for HPC evaluation but often exhibits substantial run-to-run variability on modern multi-socket CPUs. The root cause is rarely the stencil math itself; instead, performance depends on cross-layer execution conditions such as NUMA page placement, thread migration, DVFS/thermal behavior, and subtle memory-layout conflicts. Because Himeno typically reports only MFLOPS, users cannot tell whether a slow or unstable run reflects the platform\u2019s capability or an avoidable execution pathology.\n\nWe propose Cross-Layer Witness Himeno v2, a minimal refinement that produces a per-run Performance Certificate using only user-space timing and OS APIs. The benchmark executes a strict-budget witness suite (\u22641 second total by default) consisting of short micro-runs that selectively test: (W1) NUMA sensitivity (serial vs parallel first-touch), (W2) migration/placement stability (sched_getcpu sampling + cpuset size), (W3) DVFS stability (effective frequency via APERF/MPERF when permitted, otherwise cpufreq/time-drift proxies), and (W4) layout sensitivity (small base-offset toggle). From these witnesses and per-iteration timing distributions, Himeno outputs cause likelihoods and a single recommended mitigation (e.g., parallel first-touch + bind=close; rerun due to migration; report DVFS-unstable).\n\nWe validate the certificate against controlled interventions and show it reduces variance and rank flips by enabling certified-only comparisons and automated mitigation. The outcome is a portable, lab-feasible methodology that upgrades Himeno from a single-number benchmark into an auditable instrument for stable, comparable evaluation.",
        "Experiments": [
            "Witness suite implementation (default budget \u22641s): W1 NUMA witness: allocate/initialize arrays twice\u2014serial init and parallel init\u2014then run 5 stencil iterations each; compute NUMA_ratio = t(serial)/t(parallel). W2 Migration witness: sample sched_getcpu() per thread every 2 iterations during a 20-iteration micro-run; compute migration_rate and CPU_entropy; record allowed CPUs via sched_getaffinity. W3 DVFS witness: sample APERF/MPERF via perf_event_open if available; else read scaling_cur_freq; compute freq_CV and freq_drift over the micro-run. W4 Layout witness: run 5 iterations with base offset 0 vs +2048 bytes (over-allocate + pointer shift); compute layout_ratio.",
            "Feature vector + certificate: For each run, compute robust timing stats (median, MAD/median, p95/median) for the official run and for each witness. Output: {NUMA_ratio, layout_ratio, migration_rate, CPU_entropy, cpuset_size, freq_CV, freq_drift, tail_ratio}. Define a simple, interpretable certificate with cause likelihoods using a lightweight model (below) and include a one-line recommended mitigation.",
            "Attribution model (keep simple): Train a multinomial logistic regression (or decision tree with max_depth=3) on labeled data from controlled interventions to map features to dominant cause class {NUMA, migration, DVFS, layout, external/noise, mixed/unknown}. Mixed/unknown is used when model confidence <\u03c4 (e.g., 0.6). Compare against a rule-based threshold baseline.",
            "Controlled interventions for labels (no root required): NUMA-bad: serial init then many threads; Migration: OMP_PROC_BIND=false + oversubscribe by 2\u00d7; DVFS/thermal: co-run a low-priority compute stress thread; Layout: randomize offsets across runs. Collect 30 runs per regime and 30 mixed-regime runs (e.g., NUMA-bad + DVFS).",
            "Mitigation evaluation: For each diagnosed run, apply the recommended mitigation and rerun once. Metrics: reduction in run-to-run CV and p95/median; change in median MFLOPS; fraction of runs that become \u201ccertified stable\u201d (below thresholds).",
            "Cross-system comparability: On \u22653 node types, run 30 repetitions under defaults. Compare ranking stability using (a) raw MFLOPS, (b) median+IQR only, (c) certified-only MFLOPS (exclude runs flagged migration/DVFS-unstable; enforce recommended NUMA policy). Metric: rank-flip rate across repetitions and across two separate days.",
            "Ablation: remove each witness (W1\u2013W4) and measure drop in classification F1 and in mitigation benefit to show each probe\u2019s marginal value. Also test two OpenMP runtimes if available to ensure features remain meaningful."
        ],
        "Risk Factors and Limitations": [
            "Literature novelty risk: the idea combines known best practices (pinning/first-touch/DVFS awareness) but contributes by standardizing a multi-witness certificate; novelty must be argued as methodology integration + attribution + auditable output.",
            "Witness interference: extra micro-runs may perturb caches/TLBs; mitigate by running witnesses before the official run and reporting overhead; keep witness iterations minimal.",
            "APIs may be restricted: APERF/MPERF and cpufreq may be unavailable; mitigate with graceful degradation (DVFS witness becomes \u2018unknown\u2019 and the model falls back).",
            "External contention may dominate: the certificate may classify many runs as external/noise; this is still useful but may limit mitigation gains on shared nodes.",
            "Generalization: a model trained on one cluster may not transfer; mitigate by keeping the model simple, publishing the witness dataset format, and allowing optional local re-calibration."
        ]
    },
    {
        "Name": "himeno_virtual_numa_sandbox",
        "Title": "Virtual-NUMA Himeno: Emulating Page-Placement Pathologies in User Space to Make Variability Reproducible and Comparable",
        "Short Hypothesis": "A major reason Himeno results are unstable and hard to compare is that the dominant performance factor\u2014effective NUMA locality\u2014varies silently across runs (first-touch differences, allocator behavior, auto-NUMA balancing, job placement). If we can *reproduce NUMA-like locality regimes deterministically* without relying on privileged controls or system-specific NUMA APIs, then Himeno can report stable, comparable results and quantify a node\u2019s sensitivity to locality. We hypothesize that a user-space \u201cvirtual NUMA\u201d layer that (i) partitions the grid into per-thread tiles and (ii) routes a controlled fraction of accesses through a software indirection that forces extra latency/bandwidth cost (a proxy for remote memory) can emulate local/remote/mixed regimes with high repeatability. Himeno is the right setting because its stencil is regular and memory-bound: controlled locality perturbations should produce large, interpretable shifts in throughput and variance with small code changes and no special hardware.",
        "Related Work": "Himeno/stencil literature mostly optimizes median performance (vectorization, blocking) or recommends external best practices (pinning, first-touch). Existing variability-focused ideas typically (a) diagnose sensitivity (fingerprints/audits), (b) avoid transients (phase locking), (c) normalize DVFS, or (d) inject generic jitter. What is missing is a *portable, deterministic way to reproduce NUMA locality regimes* as an experimental control inside the benchmark. NUMA microbenchmarks and numactl-based studies require topology knowledge and/or OS support; they don\u2019t provide a benchmark-integrated, tool-free mechanism to sweep locality regimes and report a standardized \u201clocality sensitivity curve.\u201d This proposal is not a trivial extension of noise injection: it targets the most important structured factor (locality) and makes it replayable and comparable across sites even when real NUMA behavior is opaque.",
        "Abstract": "Himeno Bench is widely used to evaluate HPC nodes via a Jacobi-style 3D stencil, yet its reported MFLOPS can fluctuate substantially on modern multi-socket CPUs. A central cause is effective NUMA locality: small changes in first-touch, allocator placement, and runtime behavior can shift execution between mostly-local, mixed, and remote-memory regimes. Unfortunately, these regimes are difficult to control reproducibly across clusters, and often require privileged tools.\n\nWe propose Virtual-NUMA Himeno, a benchmark refinement that makes locality regimes deterministic and comparable by emulating NUMA pathologies in user space. The key idea is to introduce an optional \u201cvirtual remote\u201d mode that routes a configurable fraction of stencil reads/writes through a software indirection designed to impose a calibrated extra cost (latency and bandwidth pressure) while preserving the stencil computation and memory footprint. By sweeping the remote fraction (e.g., 0%, 10%, 25%, 50%), the benchmark produces a locality sensitivity curve and stability metrics (median, dispersion, tails) that are repeatable across runs and sites.\n\nWe validate that virtual regimes predict and explain real-world variability: configurations that accidentally induce remote placement should align with virtual curves, and stability-oriented settings (parallel first-touch, binding) should reduce deviation from the 0% curve. The outcome is a portable methodology that (i) converts uncontrolled NUMA variability into a controlled experimental factor and (ii) enables fairer cross-system comparison by reporting both peak and locality-robust performance signatures.",
        "Experiments": [
            "Implement virtual-NUMA mechanism (two simple variants) inside Himeno: (V1) Indirection buffer: store one neighbor plane in a separate buffer accessed via an extra pointer-chase and non-temporal copy, triggered for a fraction p of grid blocks; (V2) Software \"remote\" tile: for selected blocks, read inputs from a shadow array updated each iteration via memcpy-like streaming, adding controlled extra traffic. Ensure numerical results unchanged (checksum).",
            "Calibration step (portable, no counters): choose parameters so that p=50% increases iteration time by a target factor (e.g., 1.2\u20131.5\u00d7) on a given node, using a short micro-run. Record calibration constants in output to keep runs auditable.",
            "Locality sensitivity curve: run p \u2208 {0, 0.1, 0.25, 0.5} for R=20 repetitions each under fixed affinity/first-touch best-practice. Report MFLOPS median, CV, MAD/median, p95/p99 ratios; compute curve features (slope, convexity).",
            "Predicting real NUMA pathologies: create real locality regimes using only user-level actions: serial first-touch then many threads; OMP_PROC_BIND=false; (if permitted) numactl --interleave=all. Compare the observed MFLOPS drops to the virtual curve; metric: mean absolute error between real drop and nearest virtual p level.",
            "Stability benefit for methodology: under a noisy environment (unbound threads + background load), test whether reporting the virtual curve reduces rank flips across two nodes compared to single-point MFLOPS. Metric: rank-flip rate using (a) p=0 MFLOPS, (b) area-under-curve (AUC) across p, (c) worst-case MFLOPS over p (robust score).",
            "Ablation and overhead: measure overhead of virtual mode at p=0 (should be ~0) and at other p values; ensure baseline kernel unchanged when p=0. Test both OpenMP runtimes if available (libgomp vs libomp) to ensure portability."
        ],
        "Risk Factors and Limitations": [
            "Fidelity risk: virtual-remote cost may not match real remote DRAM behavior (different latency/bandwidth/interconnect effects). Mitigation: position as an emulation that enables controlled sweeps, and empirically validate alignment with real induced NUMA regimes.",
            "Benchmark acceptance risk: adding an indirection path could be seen as changing the benchmark. Mitigation: keep p=0 exactly identical to baseline and treat virtual sweep as an optional standardized diagnostic mode; always report canonical baseline.",
            "Calibration may reduce cross-site comparability if not standardized. Mitigation: fix default parameters and report calibration constants; optionally provide both calibrated and uncalibrated modes.",
            "Implementation must avoid accidentally changing cache behavior beyond intended. Mitigation: keep the virtual mechanism simple, deterministic, and block-granular; include an ablation that uses pure extra-traffic (shadow copy) vs pointer-chase to separate bandwidth vs latency effects.",
            "If variability is dominated by DVFS or external contention rather than locality, the virtual curve may not explain observed instability. Mitigation: report residual variance not explained by virtual p and recommend combining with DVFS/affinity certificates in future work."
        ]
    },
    {
        "Name": "himeno_coldstart_contract",
        "Title": "Cold-Start Contract Himeno: Making Page-Fault, THP, and First-Touch Effects a Standardized, Reported Part of Stencil Benchmarking",
        "Short Hypothesis": "A large, poorly controlled source of Himeno performance instability is not steady-state bandwidth but run-to-run differences in *cold-start memory realization*: page faults, transparent huge page (THP) promotion/defrag, and first-touch timing/parallelism. These effects are amplified by large 3D arrays and differ across OS configurations and allocator states, yet are usually hidden behind a single MFLOPS number. If Himeno adopts a simple \u201ccold-start contract\u201d mode that (i) forces a standardized cold-start condition in user space, (ii) explicitly measures and reports cold-start cost separately from steady-state, and (iii) includes a minimal policy to make first-touch deterministic, then results will be substantially more reproducible and comparable across runs/sites\u2014without requiring root access or hardware counters. This is best investigated in Himeno because its memory footprint is large, its compute is simple, and its typical benchmarking practice conflates initialization/transient effects with kernel throughput.",
        "Related Work": "Himeno and stencil papers typically focus on kernel optimizations (blocking/vectorization) or recommend general best practices (pinning, first-touch). Prior reproducibility work in HPC often discusses OS noise and affinity, and some studies examine THP impacts, but classic benchmarks rarely *standardize and report* cold-start memory realization as a first-class outcome. Our earlier proposals focused on affinity/NUMA probes, phase detection, noise injection, and certificates; this proposal is distinct by targeting a different instability axis: allocator/VM/THP/page-fault behavior and the initialization-to-steady-state transition. The key novelty is a benchmark-integrated methodology change: a portable cold-start protocol + separate reporting of cold-start vs steady-state, enabling fair comparison of systems with different THP/VM behaviors rather than inadvertently measuring OS/allocator luck.",
        "Abstract": "Himeno Bench, a Jacobi-style 3D stencil benchmark, is widely used to characterize memory-hierarchy performance, yet its reported MFLOPS can fluctuate across runs on modern HPC systems. We hypothesize that a major and under-reported contributor is \u201ccold-start memory realization\u201d: the interaction of large allocations with the virtual memory subsystem, including page faults, transparent huge page (THP) promotion/defragmentation, and non-deterministic first-touch placement. These effects can vary across runs depending on allocator state, background memory pressure, and OS policy, contaminating both total runtime and early-iteration timings.\n\nWe propose Cold-Start Contract Himeno, a minimal refinement that makes cold-start effects explicit and standardized. The benchmark adds an optional contract mode that (1) enforces a reproducible cold-start condition by allocating fresh arrays, optionally using MADV_DONTNEED/MADV_PAGEOUT when available, and performing a deterministic page-touch sequence; (2) measures and reports cold-start time (allocation + touch) separately from steady-state iteration performance; and (3) outputs VM-related observables accessible to unprivileged users (minor/major faults deltas, RSS change, THP status when readable). We evaluate whether separating and standardizing cold-start reduces run-to-run variance and rank flips across nodes, and whether it exposes meaningful platform differences in THP/VM behavior relevant to real applications. The result is a low-cost, portable methodology that improves reproducibility and interpretability of Himeno-based HPC evaluation by turning hidden VM transients into reported, comparable signals.",
        "Experiments": [
            "Implement contract mode (kept simple): (A) baseline Himeno; (B) contract-cold: allocate arrays, apply best-effort VM hints (madvise MADV_HUGEPAGE/MADV_NOHUGEPAGE toggles if permitted), then perform a deterministic page-touch sweep; (C) contract-warm: reuse arrays without re-touch to approximate steady-state-only measurement. Ensure numerical checksum unchanged.",
            "Cold-start standardization mechanisms (ablation): compare three touch policies: (T1) serial touch, (T2) parallel touch with static partitioning, (T3) parallel touch in the same loop order as the stencil. Measure sensitivity of subsequent steady-state MFLOPS to the touch policy and choose a default that minimizes variance.",
            "Separate reporting: record (i) allocation time, (ii) page-touch time, (iii) first K iteration times, and (iv) steady-state iteration times after discarding K (e.g., K=10). Report medians and dispersion (CV or MAD/median) for cold-start and steady-state separately.",
            "VM observables (no root): collect deltas from getrusage() (minor/major faults) and /proc/self/statm or /proc/self/status (VmRSS) before/after touch and after run; read /sys/kernel/mm/transparent_hugepage/enabled if readable. Correlate these signals with cold-start time variance.",
            "Reproducibility study: on \u22653 nodes, run 30 repetitions for baseline vs contract-cold under a fixed affinity/NUMA best-practice setting. Metrics: CV of total runtime MFLOPS, CV of steady-state MFLOPS, and p95/median tail ratio. Hypothesis: contract mode reduces variance primarily by stabilizing cold-start and early iterations.",
            "THP interaction test (best-effort, user-space): compare MADV_HUGEPAGE vs MADV_NOHUGEPAGE on the same arrays (when supported) to quantify how THP policy changes cold-start cost and steady-state performance. Report whether THP benefits are stable or volatile across runs.",
            "Cross-site comparability: compare two reporting styles for ranking nodes: (i) single-number MFLOPS (baseline), vs (ii) two-number report {steady-state MFLOPS, cold-start cost}. Measure rank-flip rate across repetitions and interpretability of differences."
        ],
        "Risk Factors and Limitations": [
            "Some madvise options (e.g., MADV_PAGEOUT) and THP status files may be unavailable or restricted; the design must degrade gracefully and still provide value via timing separation and fault/RSS deltas.",
            "Forcing a true \u201ccold\u201d state is difficult without privileged cache/VM control; the contract approximates cold-start via fresh allocations and best-effort hints, so residual variability may remain.",
            "Cold-start contract may be criticized as changing what Himeno measures; mitigation is to report baseline and contract side-by-side and frame the contribution as improved methodology and transparency, not a new peak score.",
            "On systems with aggressive auto-NUMA balancing or memory overcommit, fault/RSS signals may be noisy; conclusions should focus on reproducibility improvements and observable correlations rather than strict causality.",
            "If most variability is dominated by external contention or DVFS, cold-start standardization may yield limited gains; still, separating cold-start from steady-state improves interpretability."
        ]
    },
    {
        "Name": "himeno_reservoir_bandwidth",
        "Title": "Bandwidth Reservoir Himeno: A Self-Throttling Stencil Benchmark that Converges to a Stable Target Bandwidth",
        "Short Hypothesis": "Much of Himeno\u2019s run-to-run variability is multiplicative: small changes in thread placement, DVFS, or background interference change the *available memory bandwidth*, and the stencil simply rides that supply. If the benchmark is modified to include a tiny, deterministic feedback controller that (i) estimates achieved memory bandwidth online from timing and known bytes-per-iteration and (ii) adjusts an internal throttle (e.g., controlled per-thread pause or adjustable work partition) to converge to a fixed target bandwidth, then the benchmark can report a highly stable, comparable metric: the minimum overhead required to hold the target. This is a good setting because Himeno\u2019s bytes/iteration is predictable and the kernel is bandwidth-dominated, enabling closed-loop control without privileged counters; simpler approaches (pinning/warmups) reduce variance but do not yield a control-based, comparable \u2018robustness-to-supply\u2019 score.",
        "Related Work": "Himeno methodology work and common practice focus on choosing good static settings (affinity, first-touch), reporting distributions, or separating transient/steady-state phases. Jitter/OS-noise studies typically measure variability passively rather than actively controlling resource demand. Feedback control is used in systems (e.g., CPU utilization controllers, QoS), but integrating a control loop *inside a classic stencil benchmark* to stabilize a bandwidth-dominated kernel and to report \u2018control effort\u2019 as a reproducibility metric appears distinct from prior Himeno refinements like fingerprints, phase-locking, noise injection, layout sweeps, and certificates. This is not a trivial extension: it changes the benchmark\u2019s output from raw throughput to a controlled operating-point experiment that quantifies how volatile the platform\u2019s effective bandwidth supply is under realistic conditions.",
        "Abstract": "Himeno Bench is a widely used Jacobi-style 3D stencil benchmark whose performance is dominated by the memory subsystem. On modern HPC nodes, reported MFLOPS often varies across runs due to changes in effective memory bandwidth supply caused by NUMA placement, DVFS/thermal behavior, and background interference. This variability undermines reproducible evaluation.\n\nWe propose Bandwidth Reservoir Himeno, a benchmark variant that actively stabilizes its operating point using a lightweight feedback controller. The benchmark estimates achieved memory bandwidth online from per-iteration timing and a calibrated bytes-per-iteration model. It then adjusts a deterministic throttle\u2014implemented as a per-thread pause budget or adjustable iteration micro-batching\u2014to converge to a fixed target bandwidth (e.g., 70% of the best observed steady-state bandwidth on the node). Rather than reporting only raw MFLOPS, the benchmark reports (i) the control effort required to maintain the target (pause fraction and its variance), (ii) the residual bandwidth error, and (iii) a derived Bandwidth Volatility Index (BVI) capturing how much throttling must change over time to compensate for supply fluctuations.\n\nWe hypothesize that (a) the controlled operating point yields dramatically tighter performance distributions than raw Himeno under the same environment, and (b) BVI is a more comparable, diagnostic measure across systems and job conditions, separating \u2018fast but unstable\u2019 from \u2018slower but steady\u2019 nodes. The approach is user-space, low-overhead, and requires only small code changes, enabling publishable insights into reproducible benchmarking for memory-bound kernels.",
        "Experiments": [
            "Bytes-per-iteration model validation: Derive an analytic bytes/iteration estimate for Himeno\u2019s arrays (reads/writes per stencil update). Validate by comparing predicted bandwidth (bytes/time) against a simple streaming micro-pass over the same arrays; ensure the estimate is within ~10% and is consistent across grid sizes.",
            "Controller design (keep simple): Implement a PI controller that updates a throttle parameter u each control interval (e.g., every 5 iterations). Measurement y = estimated bandwidth. Target r = fixed bandwidth. Update u <- clamp(u + Kp*(y-r) + Ki*sum(y-r), 0..umax). Throttle mechanism: each thread performs a calibrated busy-wait for u microseconds per iteration block (cache-resident, no syscalls).",
            "Stability evaluation vs baseline: On each node, run 30 repetitions of (A) baseline Himeno and (B) Reservoir Himeno with the same affinity/NUMA settings. Metrics: CV of reported performance, p95/median, and for Reservoir mode: residual error |y-r|/r and CV of error. Hypothesis: Reservoir mode reduces CV substantially.",
            "Volatility and diagnosis: Under induced perturbations\u2014(i) unpinned threads (OMP_PROC_BIND=false), (ii) serial first-touch then many threads, (iii) background low-priority memory copy loop\u2014measure how BVI changes. Expect BVI to increase when bandwidth supply is unstable, even if raw MFLOPS medians are similar.",
            "Cross-node comparability: Evaluate on \u22653 CPU platforms (single- and dual-socket). Compare ranking stability across days using (i) raw MFLOPS and (ii) BVI at a standardized target (e.g., 60% of each node\u2019s own best bandwidth, and an absolute target like 100 GB/s where feasible). Metric: rank-flip rate and Spearman correlation across days.",
            "Overhead and fairness checks: Report added overhead at u\u22480 (should be ~0\u20132% from timing/control) and ensure the baseline score is still reported. Show that Reservoir mode does not inflate throughput; it intentionally fixes it and reports control effort."
        ],
        "Risk Factors and Limitations": [
            "Novelty risk: feedback control inside benchmarks may exist in QoS literature; must clearly position the contribution as a reproducibility methodology for memory-bound stencils and demonstrate new, useful metrics (BVI) for Himeno-like kernels.",
            "Throttle fidelity: busy-wait throttling changes CPU power state and could interact with DVFS, confounding interpretation. Mitigation: use short control intervals, report effective frequency when available, and include an alternative throttle (e.g., reduced parallelism via skipping a fixed fraction of thread blocks) as an ablation.",
            "Target selection: choosing a target relative to each node\u2019s peak may reduce absolute comparability; choosing an absolute target may be infeasible on slower nodes. Mitigation: report both relative-target and absolute-target modes with clear rules.",
            "If variability is dominated by rare catastrophic events (e.g., OS pauses), the controller may not stabilize quickly and BVI may saturate. Mitigation: detect outliers, report a \u2018non-controllable\u2019 flag, and keep the controller conservative.",
            "The method changes the benchmark question from \u2018how fast\u2019 to \u2018how stable at a fixed demand\u2019; acceptance may require reporting baseline Himeno alongside Reservoir metrics and framing Reservoir mode as an optional standardized stability/robustness extension."
        ]
    },
    {
        "Name": "himeno_barrier_spectroscopy",
        "Title": "Barrier Spectroscopy for Himeno: Using Micro-Barrier Timing to Separate Memory-Bandwidth Limits from Jitter Amplification",
        "Short Hypothesis": "Himeno\u2019s instability is often diagnosed indirectly (NUMA, affinity, DVFS), but a missing piece is an in-kernel, low-overhead measurement of *how much* thread skew and synchronization delay is being amplified into performance loss. Hypothesis: inserting a tiny, fixed-rate \u201cspectroscopy barrier\u201d (a lightweight synchronization point that already exists in many OpenMP loops implicitly) and recording per-thread arrival times yields a stable, interpretable signature that (i) predicts run-to-run MFLOPS variance and tails and (ii) distinguishes bandwidth-limited slowdowns (all threads slow similarly) from jitter amplification (threads diverge in arrival times). This is best tested on Himeno because it is iterative, memory-bound, and sensitive to cross-thread timing, and there is no simpler external measurement that captures the same in-kernel skew dynamics without hardware counters or privileged tracing.",
        "Related Work": "Prior Himeno/stencil work largely reports single MFLOPS and focuses on throughput optimizations or external best practices (pinning, first-touch). OS-noise and jitter studies measure system perturbations with separate microbenchmarks or tracing, but typically do not provide a kernel-integrated, per-iteration skew measurement that can be correlated to performance tails. Our earlier proposals addressed configuration probing, phase detection, DVFS-aware reporting, noise injection, and layout sensitivity; this proposal is distinct because it introduces a new *observable*\u2014thread arrival-time distributions at a controlled synchronization cadence\u2014turning Himeno into a \u201cjitter amplifier\u201d instrument. Unlike generic per-iteration timing, barrier spectroscopy provides per-thread structure (skew) that is directly actionable (e.g., choose schedule/affinity that minimizes skew).",
        "Abstract": "Himeno Bench (Jacobi-style 3D stencil) is widely used for HPC evaluation, yet its performance on modern multi-core and multi-socket CPUs often fluctuates across runs even under nominally identical settings. Existing explanations (NUMA placement, affinity, DVFS, OS noise) are hard to validate without privileged tools or hardware counters, and benchmarks typically report only aggregate runtime.\n\nWe propose Barrier Spectroscopy for Himeno: a minimal, user-space methodology that measures how cross-thread timing skew and synchronization delay contribute to performance variability. We insert a fixed-rate micro-barrier cadence (e.g., once per k-plane block or once per iteration block) and record per-thread arrival timestamps using a low-overhead clock. From these timestamps we compute a Barrier Skew Spectrum: robust statistics of (i) arrival-time spread (MAD/IQR), (ii) tail gaps (p95\u2013p50), and (iii) temporal structure (autocorrelation of skew over time). We hypothesize that bandwidth-limited regimes produce low skew but uniformly slow arrivals, while jitter amplification regimes produce high skew and heavy performance tails.\n\nWe validate that the skew spectrum predicts MFLOPS variance and tail risk across controlled interventions (affinity/NUMA misplacement, OpenMP scheduling, induced background jitter) and that selecting configurations minimizing skew yields more stable Himeno results with minimal median-performance loss. The outcome is a portable, lab-feasible extension that upgrades Himeno from a single-number benchmark to an auditable instrument that attributes instability to synchronization-skew dynamics without requiring hardware counters or root access.",
        "Experiments": [
            "Instrumentation design & overhead: Add a spectroscopy barrier every B inner-loop blocks (e.g., every 4 k-planes) using an OpenMP barrier or a custom dissemination barrier in user space. Each thread records a timestamp at barrier entry into a per-thread array. Quantify overhead by comparing baseline MFLOPS vs instrumented MFLOPS (target <3%).",
            "Define skew metrics (per run): For each barrier event, compute spread = p75(arrivals)-p25(arrivals), tailgap = p95-p50, and leader-lagger gap = max-min. Aggregate over events using median and p95. Also compute skew autocorrelation over events (lag-1..lag-5) to detect periodic jitter.",
            "Controlled factor sweep (feasible, no root): Run across a small matrix: first-touch {serial, parallel}; OMP_PROC_BIND {close, spread, false}; OMP_SCHEDULE {static, guided}. For each condition, do 30 repetitions. Report MFLOPS median/CV/p95 and skew-spectrum features. Test correlation between skew features and MFLOPS tails (Spearman correlation; regression R^2).",
            "Bandwidth-limited vs jitter-amplified separation test: (A) bandwidth stress: increase problem size to exceed LLC and saturate DRAM; (B) jitter stress: add a low-priority background thread that wakes periodically (e.g., every 5ms busy for 200us). Hypothesis: (A) reduces MFLOPS with modest skew increase; (B) increases skew tails strongly and increases MFLOPS tail ratios.",
            "Skew-minimizing configuration selector: Choose the configuration minimizing a skew score S = median(spread)/median(iter_time) + (p95(tailgap)/median(iter_time)) subject to \u22643% median MFLOPS loss vs best-median. Compare stability (CV, p95/median) against default and best-median tuning.",
            "Cross-platform repeatability: Run on \u22653 node types (single-socket, dual-socket, and a chiplet-heavy CPU if available). Evaluate whether skew-spectrum features are repeatable across days (feature CV across days) and whether they reduce rank flips when comparing systems using certified-low-skew runs."
        ],
        "Risk Factors and Limitations": [
            "Barrier insertion may change the kernel\u2019s synchronization behavior and could be criticized as perturbing the benchmark; mitigation: keep cadence sparse, report baseline alongside spectroscopy mode, and show low overhead and consistent median MFLOPS ordering.",
            "Timestamping overhead and clock noise could distort skew measurements; mitigation: sample at a reduced cadence, use CLOCK_MONOTONIC_RAW, and aggregate with robust statistics (median/MAD).",
            "Some variability sources (DVFS changes affecting all threads equally) may not manifest as skew; the method is intended to detect jitter amplification and migration/imbalance, not all causes.",
            "Portability: relies on OpenMP barriers and Linux timing; provide a fallback mode (coarser sampling) and document unsupported environments.",
            "Novelty verification risk due to limited literature search results from the tool; must manually confirm in SC/ICS/IPDPS/TPDS whether similar barrier-skew instrumentation has been proposed for stencil benchmark methodology."
        ]
    },
    {
        "Name": "himeno_time_budgeted_repro_protocol",
        "Title": "Time-Budgeted Reproducibility Protocol for Himeno: Can We Guarantee a Stable Score in \u226460 Seconds?",
        "Short Hypothesis": "Himeno\u2019s instability in practice is less about irreducible hardware randomness and more about the lack of a standardized, time-bounded *measurement protocol* that (i) detects whether the current run is in a \u201creproducible regime\u201d and (ii) adapts minimally (warmup length + one or two configuration toggles) until stability criteria are met. Hypothesis: a strict-budget protocol (e.g., 60 seconds total wall time) embedded into Himeno can reliably output a \u2018certified\u2019 score (median MFLOPS with bounded dispersion) or a principled \u2018uncertifiable\u2019 flag. This setting is ideal because Himeno is iterative and memory-bound, so stability can be assessed quickly from iteration-time statistics without privileged access or hardware counters; simpler one-shot runs cannot distinguish a genuinely slower system from an unstable execution regime.",
        "Related Work": "Himeno and stencil literature typically reports a single MFLOPS number and focuses on throughput optimizations (blocking/vectorization) or external run advice (pinning/first-touch). Recent reproducibility discussions in HPC emphasize controlling affinity/NUMA and reporting distributions, but they rarely propose a *formal, time-bounded certification protocol* that either returns a stable score or refuses to score. This proposal is distinct from prior ideas like variability fingerprints (probing many conditions), phase-locking (steady-state detection only), DVFS-aware logging (extra signals), or noise injection (robustness characterization): here the novelty is a minimal, standardized \u2018stop-when-certified\u2019 procedure with an explicit wall-clock budget and a binary certification outcome, designed for fair, comparable benchmarking under real cluster constraints.",
        "Abstract": "Himeno Bench is widely used to characterize HPC node performance via a Jacobi-style 3D stencil, yet its reported MFLOPS often fluctuates across runs on modern multi-socket CPUs. This variability undermines comparability, especially when users can afford only short benchmark allocations and cannot control system-wide settings.\n\nWe propose a Time-Budgeted Reproducibility Protocol (TBRP) for Himeno: a minimal, standardized measurement procedure that runs within a fixed wall-clock budget (default 60 seconds) and outputs either (i) a certified performance score with bounded dispersion or (ii) an explicit uncertifiable flag. TBRP instruments per-iteration (or per-block) timings and uses a simple online stability test to determine when the iteration-time distribution has converged. If stability is not achieved, TBRP performs at most two low-cost, user-space interventions chosen from a tiny, fixed menu: parallel first-touch re-initialization and one alternate OpenMP binding policy (close vs spread). The benchmark then re-tests stability and either certifies or flags.\n\nWe evaluate whether TBRP reduces run-to-run variance and rank flips across nodes and days, and whether the uncertifiable flag correlates with identifiable pathologies (migration, severe contention, DVFS drift). The outcome is a practical methodology upgrade: Himeno becomes an auditable instrument that guarantees a stable score when possible and avoids publishing misleading numbers when not.",
        "Experiments": [
            "Protocol implementation: Add per-iteration timing (or every 2\u20135 iterations) and a wall-clock budget controller. Define stability as: over a sliding window W=30 iteration times, (i) median changes <1% for S=3 consecutive windows and (ii) MAD/median <2%.",
            "Minimal intervention menu (fixed, portable): (A) re-initialize arrays with parallel first-touch (static partitioning); (B) switch OMP_PROC_BIND between {close, spread} (keeping thread count fixed). Limit to at most two interventions per run to preserve fairness and simplicity.",
            "Certification output: If stable, report certified_median_MFLOPS, certified_CV (or MAD/median), steady_state_start_iter, and total_time_used. If not stable within budget, report uncertifiable plus the best observed median and its dispersion (clearly labeled as uncertified).",
            "Evaluation protocol: On \u22653 node types (including at least one dual-socket), run 30 repetitions of (i) baseline Himeno (single run, default warmup), (ii) phase-locked only (steady-state detection but no interventions), and (iii) TBRP. Metrics: run-to-run CV, p95/median tail ratio, fraction certified, and rank-flip rate across nodes when using a single-number score.",
            "Stress tests: Induce common instability sources without root: (i) disable binding (OMP_PROC_BIND=false), (ii) serial init then many threads, (iii) background low-priority CPU load. Measure how certification rate and variance change, and whether interventions recover certification.",
            "Ablation: Compare budgets {15s, 30s, 60s} and intervention sets {none, A only, A+B}. Goal: show diminishing returns and justify the default protocol as the simplest that works."
        ],
        "Risk Factors and Limitations": [
            "Novelty risk: \u2018adaptive warmup\u2019 exists informally; contribution must be framed as a formal, time-bounded certification protocol with explicit refusal-to-score behavior and strict intervention limits.",
            "Some systems may remain unstable due to uncontrollable shared-node contention; the protocol may frequently return \u2018uncertifiable\u2019. This is still valuable but could reduce perceived usability; mitigation is to report certification rate as a first-class metric.",
            "Interventions could be criticized as changing benchmark conditions; mitigation: fixed, tiny menu; strict cap on interventions; always report what was applied; and keep the core kernel unchanged.",
            "Stability thresholds (1%, 2%) may not be universally optimal; mitigation: conservative defaults and a small sensitivity study, but avoid over-parameterization.",
            "No papers were retrieved via the provided search tool; a manual scan of SC/ICS/IPDPS reproducibility and benchmarking methodology papers is required before publication claims."
        ]
    },
    {
        "Name": "himeno_coherence_choreography",
        "Title": "Coherence Choreography Himeno: Stabilizing Memory-Bound Stencils by De-Synchronizing Write Ownership",
        "Short Hypothesis": "Even with correct NUMA placement and thread pinning, Himeno can show residual run-to-run variance because multi-threaded stencil updates create near lockstep bursts of write-ownership (RFO/invalidation) and eviction pressure in shared caches and memory controllers. Small timing perturbations (OS jitter, minor migration, OpenMP runtime effects) can shift these bursts and cause non-linear throughput changes. If we keep the stencil math and data volume identical but deterministically *de-synchronize when threads perform writes* (write-ownership acquisitions) using a lightweight intra-iteration schedule (\u201ccoherence choreography\u201d), then Himeno\u2019s performance distribution tightens (lower CV and tails) with only a small median MFLOPS loss. This is best tested in Himeno because it is iterative, regular, memory-bound, and widely used; simpler knobs (warmup/pinning) do not directly control temporal coherence contention.",
        "Related Work": "Himeno/stencil work typically targets median throughput (vectorization, cache blocking) or addresses variability via affinity/NUMA best practices, phase/warmup protocols, DVFS-aware reporting, and noise injection. Cache-coherence and false-sharing studies exist, but they usually focus on correctness/performance bugs (padding) or on counter-based analysis, not on benchmark-methodology changes that control *temporal write phasing* while preserving algorithmic work. This proposal differs from prior variability-oriented ideas (distribution-first reporting, phase-locking, synthetic twins, jitter injection, locality sweeps) by introducing a new, kernel-internal control knob: deterministic de-synchronization of write ownership acquisition. It aims to reduce variance by shaping coherence bursts rather than by changing external conditions or adding heavy instrumentation.",
        "Abstract": "Himeno Bench is a widely used Jacobi-style 3D stencil benchmark whose performance is dominated by the memory hierarchy. On modern multi-core CPUs, its reported MFLOPS can fluctuate across runs even when thread affinity and NUMA placement appear correct, undermining reproducible evaluation. We hypothesize that part of this residual instability arises from coherence-traffic burstiness: threads repeatedly acquire write ownership of cache lines (RFO/invalidation) and compete for shared LLC and memory-controller resources. When write ownership transitions occur in near lockstep across threads, small timing perturbations can trigger non-linear contention patterns and amplify jitter into throughput variance.\n\nWe propose Coherence Choreography Himeno, a minimal, algorithm-preserving refinement that deterministically de-synchronizes write streams across threads. The core idea is to keep the stencil computation and total data movement unchanged, while altering only the intra-iteration order of updates so that threads do not acquire write ownership for adjacent regions simultaneously. We implement two portable choreography schemes: (i) rotating plane-color sub-steps within each iteration, and (ii) staggered per-thread write windows over k-plane blocks. The benchmark reports baseline and choreographed results with distributional metrics (median, CV, p95/p99) and a Coherence Burst Sensitivity score.\n\nWe evaluate whether choreography reduces dispersion and tail risk across CPU platforms and under controlled micro-jitter, and whether reductions correlate with user-space timing proxies for cross-thread alignment. The outcome is a low-cost methodology primitive for making memory-bound stencil benchmarking more stable and interpretable by explicitly controlling an otherwise hidden dimension: cross-thread coherence timing.",
        "Experiments": [
            "Implement two choreography variants:\n- C1 Rotating plane-color: choose G in {2,4,8}. For each iteration, execute G sub-steps; in sub-step g, update only k where (k mod G)==((g+iter) mod G). This defers some writes within the iteration but performs the same stencil updates.\n- C2 Staggered write windows: each thread processes its assigned k-range in blocks of B planes (B in {2,4,8,16}) but starts at a tid-dependent cyclic offset, de-synchronizing write ownership acquisition without adding extra global barriers beyond the normal OpenMP loop barrier.",
            "Correctness & invariance checks: confirm Himeno\u2019s verification/checksum matches baseline within tolerance; ensure identical iteration count, grid size, and arrays; verify that C1/C2 do not change total floating-point operations or memory footprint.",
            "Baseline stability study: for baseline, C1, and C2, run 30 repetitions under a fixed, documented best-practice environment (OMP_PROC_BIND=close or spread; parallel first-touch). Metrics: median MFLOPS, CV across runs, p95/median and p99/median tail ratios; also compute steady-state CV from per-iteration times after discarding first K=10 iterations.",
            "Coherence Burst Sensitivity (CBS): define CBS_CV=(CV_base\u2212CV_choreo)/CV_base and CBS_tail=(p99/median_base\u2212p99/median_choreo)/(p99/median_base\u22121). Report CBS across (G,B) and identify settings with CBS high and median MFLOPS loss <5%.",
            "Timing-based mechanism proxy (no counters): record per-thread completion timestamps per sub-step (C1) or per block (C2) and compute an alignment index (e.g., median over events of (p90\u2212p10) completion spread / median completion time). Test whether choreography reduces alignment and whether alignment predicts run-to-run variance (Spearman correlation).",
            "Noise robustness: add a deterministic micro-jitter source (one low-priority background thread busy-waiting 100\u2013200\u00b5s every 5ms). Compare baseline vs choreographed amplification: \u0394CV and \u0394p99/median under noise. Hypothesis: choreographed modes amplify less.",
            "Cross-platform evaluation: run on \u22653 CPU nodes (single-socket, dual-socket, and if available a chiplet-heavy CPU). Compare (i) best choreography parameters, (ii) CBS repeatability across days, and (iii) whether reduced variance also reduces cross-node rank flips when using single-number MFLOPS."
        ],
        "Risk Factors and Limitations": [
            "C1 introduces extra sub-steps that may reduce locality and add loop overhead; may lower median MFLOPS more than desired. Mitigation: keep G small, optimize loop nests, and treat C2 (no extra sub-steps) as the primary low-overhead option.",
            "The effect may be small if coherence contention is not a dominant variability source on some systems. Mitigation: position contribution as identifying when coherence choreography helps; report negative cases as insight.",
            "Without hardware counters, attributing improvements specifically to coherence effects is indirect. Mitigation: focus claims on stability/tail reductions and on timing-based alignment proxies; keep causal language conservative.",
            "OpenMP runtime differences could affect determinism. Mitigation: use static scheduling, explicit chunk sizes, and test at least two runtimes when feasible.",
            "Benchmark-methodology acceptance: altering intra-iteration order may be viewed as changing the benchmark. Mitigation: always report baseline; present choreography as an optional standardized stability mode with explicit parameter defaults and a median-loss budget."
        ]
    },
    {
        "Name": "himeno_threadgroup_redundancy_v2",
        "Title": "Replica-Himeno v2: In-Run Redundant Thread-Groups to Decompose Variability into Common-Mode vs Differential Noise",
        "Short Hypothesis": "Himeno\u2019s run-to-run instability on modern CPU nodes is hard to interpret because a single measurement conflates (a) node-wide effects that impact all cores similarly (DVFS/power limits, DRAM throttling, noisy-neighbor bandwidth contention) with (b) localized effects that hit only some threads/cores (migration, cpuset fragmentation, NUMA page imbalance, scheduler artifacts). By running two identical Himeno replicas concurrently on disjoint, pinned thread-groups and synchronizing them into short epochs, we can estimate a common-mode signal (average of replica times) and a differential-mode signal (difference of replica times). This decomposition is feasible entirely in user space and yields a new, auditable benchmark output: a certified stable score based on epochs where replicas agree, plus indices quantifying common-mode volatility and differential instability. Himeno is the right setting because it is memory-bound, iterative, and easily duplicated; there is no simpler in-process method to obtain a same-time control experiencing the same node-wide conditions.",
        "Related Work": "Typical Himeno methodology (and most stencil benchmarking) reports a single MFLOPS and relies on external best practices (pinning/first-touch) or repeated runs. Prior variability-focused approaches (probing configurations, steady-state detection, DVFS-aware reporting, synthetic twins, noise injection) do not create a within-run, same-time control that shares node-wide conditions. Redundancy is well-known in fault tolerance, but using redundant replicas as a *benchmarking instrument* to separate common-mode from differential-mode performance noise appears underexplored for stencil benchmarks. This is not a trivial extension of distributional reporting: it introduces a new observable\u2014replica divergence\u2014that directly indicates whether instability is local vs global, enabling certification and diagnosis without privileged counters or external profilers. (Semantic Scholar search returned no directly matching papers; novelty should be further validated by manual scans of SC/ICS/IPDPS benchmarking/reproducibility work.)",
        "Abstract": "Himeno Bench is a widely used Jacobi-style 3D stencil benchmark whose performance is often unstable on modern multi-core and multi-socket CPUs. A core obstacle to reproducible evaluation is attribution: variability may stem from node-wide operating-point changes (DVFS, power/thermal limits, memory-controller throttling, shared-node contention) or from localized runtime pathologies (thread migration, cpuset fragmentation, NUMA imbalance) that affect only subsets of threads.\n\nWe propose Replica-Himeno v2, a minimal benchmark methodology that embeds in-run redundancy. The benchmark partitions available cores into two disjoint thread-groups, pins each group, and runs two identical Himeno replicas concurrently. Execution is organized into synchronized epochs; each epoch records per-replica timing. The per-epoch average time estimates common-mode volatility, while per-epoch divergence estimates differential instability. We report (i) a certified stable MFLOPS score computed from epochs where divergence is below a tolerance, (ii) a Common-Mode Volatility Index (CVI), (iii) a Replica Divergence Index (RDI), and (iv) a certification rate.\n\nWe validate that differential interventions (e.g., NUMA-mismatched initialization for one replica, unpinned migration) increase RDI, while common-mode interventions (e.g., node-wide thermal/DVFS perturbation) increase CVI. Replica-Himeno improves interpretability and reduces misleading comparisons by revealing whether instability is local or global, using only user-space timing and standard affinity controls.",
        "Experiments": [
            "Core implementation (keep simple): Create two independent Himeno contexts (separate arrays per replica to avoid artificial cache-line sharing). Partition threads into two groups of size T/2. Pin each group to a disjoint CPU subset (best-effort via OpenMP places or a small Linux sched_setaffinity wrapper). Run both replicas concurrently using OpenMP parallel regions bound to their CPU sets.",
            "Epoch timing protocol: Choose epoch length K iterations (e.g., K=5). Run E epochs (e.g., E=40). After each epoch, synchronize replicas with one barrier and record epoch times tA[e], tB[e]. Overhead target: <10% vs baseline single-instance when E*K equals the baseline iteration count.",
            "Metrics and certification: Compute RDI = median_e(|tA[e]-tB[e]| / ((tA[e]+tB[e])/2)) and RDI_p95. Compute CVI = CV_e((tA[e]+tB[e])/2). Define certified epochs where divergence < \u03c4 (default \u03c4=2%). Certified score = median MFLOPS over certified epochs; report certification rate.",
            "Controlled differential-mode tests (no root): (a) Disable binding (OMP_PROC_BIND=false) to encourage migration; expect higher RDI and lower certification. (b) Induce NUMA imbalance for one replica by initializing its arrays with 1 thread (serial first-touch) while the other uses parallel first-touch; expect RDI to increase (especially on dual-socket).",
            "Controlled common-mode tests (no root): Add a low-priority background worker that periodically stresses all cores (or performs a memory copy) to perturb node-wide conditions; expect CVI to rise while RDI rises less than in differential tests.",
            "Cross-run reproducibility: On \u22653 node types, run 30 repetitions of (i) standard Himeno single-instance and (ii) Replica-Himeno v2. Compare dispersion of reported score (CV across repetitions) and rank-flip rate across nodes. Hypothesis: certified replica score yields fewer rank flips; high CVI will flag environments where no stable score exists.",
            "Ablations (to avoid over-claiming): (i) Same-socket vs split-socket pinning when topology is known/available; (ii) separate arrays vs shared arrays; (iii) epoch size K sweep {1,5,10} to show robustness of RDI/CVI trends."
        ],
        "Risk Factors and Limitations": [
            "Replica contention changes the measured operating point (two memory-bound kernels co-run). Mitigation: position as a diagnostic/certification mode; always also report the standard single-instance score for comparability.",
            "Affinity partitioning may be unreliable on some schedulers/cpuset setups. Mitigation: detect allowed CPUs via sched_getaffinity and partition within that set; if disjoint partitioning is impossible, report 'partition_failed' and fall back to single-instance.",
            "If variability is dominated by common-mode effects, certification may succeed but the certified score may still drift across runs; CVI is intended to reveal this, but stability may not improve without additional methodology (warmup/phase-locking).",
            "On single-socket or small-core nodes, splitting cores reduces per-replica bandwidth and may reduce sensitivity. Mitigation: enable 3 modes: 1-replica (baseline), 2-replica (default), and 4-replica (optional) for larger nodes to increase diagnostic resolution.",
            "Novelty verification: redundancy-for-variability-decomposition may overlap with co-scheduled microbenchmarking ideas; must manually search SC/ICS/IPDPS/TPDS for similar within-run A/B benchmarking designs."
        ]
    }
]