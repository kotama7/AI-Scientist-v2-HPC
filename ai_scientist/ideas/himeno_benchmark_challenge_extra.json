[
    {
        "Name": "stability_oriented_autotuning_v2",
        "Title": "Autotuning for Reproducibility: Jointly Optimizing Median Speed and Variability (CV, p99/median) for NUMA Stencil Codes",
        "Short Hypothesis": "For stencil benchmarks (Himeno as a controlled proxy), the configuration that maximizes median MFLOPS is often different from the configuration that minimizes run-to-run variability and tail slowdowns, because median is dominated by locality/SIMD while variability and p99 are dominated by runtime placement and system noise (NUMA first-touch, migration, frequency scaling). Therefore, treating performance as a distribution (median, CV, p99/median) and autotuning across a small, practical set of code variants and runtime knobs will produce Pareto-optimal configurations that (i) reduce CV and p99/median substantially and (ii) often preserve or even improve median by removing pathological placements. This question is best answered in stencil codes because their memory access is simple enough to attribute causes via counters, yet large enough to trigger NUMA/cache/bandwidth regime changes across problem sizes; simpler microbenchmarks (STREAM) lack the synchronization and stencil reuse patterns that interact with affinity and tiling.",
        "Related Work": "Existing stencil optimization and autotuning work (tiling, vectorization, unrolling, prefetching) largely targets average throughput and reports single-number speedups. Separately, HPC systems work studies OS noise/jitter, thread pinning, and NUMA placement, typically as best practices or isolated sensitivity studies. Tail metrics (p99) are standard in datacenter latency work but rarely made first-class in HPC kernel tuning. This proposal is distinct in (1) making distributional objectives explicit (median + variability + tail), (2) jointly searching code and runtime knobs rather than treating system settings as fixed, and (3) producing an actionable \u201cconfiguration policy\u201d that can pick a stable-vs-fast point on the Pareto front with a short probe run. It is not a trivial extension of autotuning because the objective, measurement protocol, and output artifact (Pareto front + selection policy) change fundamentally.",
        "Abstract": "Modern HPC nodes exhibit stochastic performance due to NUMA placement, thread migration, dynamic frequency scaling, and OS jitter. For memory-sensitive stencil solvers, these effects can dominate run-to-run reproducibility even when median performance appears strong. We propose a stability-oriented autotuning methodology that treats performance as a distribution rather than a single scalar. Using the Himeno benchmark across three regimes (\u224850MB, \u2248400MB, \u22483.2GB footprints), we jointly tune a small set of compile-time transformations (loop order, 3D tiling, SIMD pragmas, unrolling, prefetch distance) and runtime/system knobs (OpenMP affinity/places, scheduling, NUMA allocation policy) to optimize three metrics: median MFLOPS, coefficient of variation (CV), and tail degradation (p99/median). We use replicated measurements (\u226530 runs/config) with robust statistics to build Pareto fronts that expose speed\u2013stability trade-offs. Finally, we train a lightweight selector that uses topology and a short probe run\u2019s counters (LLC misses, remote NUMA accesses, TLB misses, context switches) to choose a configuration matching a user\u2019s preference (fastest vs most stable). The outcome is a practical, open-source toolkit and a set of empirical findings showing which knobs control median vs variability vs tails in each memory regime, enabling more reproducible benchmarking and more reliable stencil performance on shared systems.",
        "Experiments": [
            "Distribution-first baseline: For each problem size (64\u00d764\u00d7128, 128\u00d7128\u00d7256, 256\u00d7256\u00d7512) and thread count, run 50 repetitions under default settings. Report median, CV, p99/median. Collect perf counters: LLC misses, memory bandwidth, remote NUMA accesses (where available), dTLB load misses, context switches/interrupts.",
            "Runtime knob sweep (no code changes): Evaluate combinations of OMP_PROC_BIND={false,close,spread}, OMP_PLACES={cores,sockets}, OMP_SCHEDULE={static,guided}, and NUMA allocation via numactl={default,localalloc,interleave}. Quantify effect sizes on (median, CV, p99/median) per problem size; identify which knobs mostly reduce CV vs improve median.",
            "Code variant sweep (runtime fixed): Implement 6\u201312 code variants: (a) loop reordering for stride-1, (b) 3D tiling with a small grid of tile sizes, (c) SIMD via OpenMP simd or intrinsics, (d) unroll factors, (e) optional software prefetch. Evaluate under a fixed \u201cstable\u201d runtime setting to separate algorithmic locality gains from system noise effects.",
            "Joint multi-objective autotuning: Search over the combined space (runtime knobs + code variants) using a simple multi-objective strategy (e.g., NSGA-II or random search with Pareto filtering). Budget: ~150\u2013250 configurations per size, 30 runs each. Output Pareto front; compare against (i) median-only tuning and (ii) best-practice manual settings (pinning + localalloc).",
            "Stability policy learning: Train a small model (e.g., gradient-boosted trees) to map features from a 1\u20132 second probe run (counters + topology + problem size) to a Pareto-front configuration given a user objective (weights over median/CV/p99). Evaluate generalization across nodes and across mild background load. Metrics: regret vs oracle (distance to Pareto front), achieved median/CV/p99.",
            "Ablation and causal attribution: Remove one knob class at a time (affinity, NUMA allocation, tiling/SIMD) from the search and measure Pareto-front shrinkage. Use counter shifts (remote accesses, LLC misses, dTLB misses) to explain why median vs CV vs tail changed."
        ],
        "Risk Factors and Limitations": [
            "p99 estimation can be sample-hungry; mitigation: report p95 alongside p99/median, and validate p99 with a smaller subset of configurations using 200+ runs.",
            "Some clusters restrict frequency/turbo control; this version avoids requiring privileged frequency changes and focuses on user-level knobs (affinity, numactl, scheduling) plus code variants.",
            "Remote-NUMA counters are platform-dependent; mitigation: use proxy signals (bandwidth imbalance, latency via cycles stalled, LLC miss locality) and numactl placement as controlled interventions.",
            "Search cost may be high; mitigation: keep variant set small (dozens), use early stopping for clearly dominated configurations, and reuse compiled variants across runs.",
            "Findings may not fully transfer beyond stencils; mitigation: include a second stencil-like kernel (e.g., 7-point Jacobi miniapp) to demonstrate generality without expanding scope significantly."
        ]
    },
    {
        "Name": "counterfactual_noise_injection_v2",
        "Title": "Counterfactual Noise Injection for HPC: Causally Attributing Himeno\u2019s CV and p99 to Frequency, NUMA, and Jitter",
        "Short Hypothesis": "A small set of dominant perturbation channels\u2014(1) frequency excursions/downclocking, (2) NUMA remote-page placement and cross-socket execution, and (3) interrupt/jitter bursts\u2014explains most of Himeno\u2019s run-to-run dispersion (CV) and tail slowdowns (p95/p99). By establishing a stabilized baseline and then injecting each channel with controlled intensity to match observed signatures from unstable runs, we can causally decompose variability and identify the minimal intervention that fixes tails for each problem-size regime. This is best studied on Himeno because its stencil structure makes performance counter signatures interpretable while still exhibiting regime shifts (L3-ish vs DRAM-bound) where different noise sources dominate; simpler bandwidth microbenchmarks lack synchronization/loop-structure interactions that amplify jitter into p99 tails.",
        "Related Work": "HPC literature widely discusses OS noise/jitter, OpenMP affinity and NUMA first-touch, and frequency scaling effects, typically via observational comparisons (default vs pinned vs localalloc) and best-practice guidance. Systems work on tail latency often uses load injection, but rarely in the context of tightly-coupled HPC kernels with NUMA/cache regime shifts. The key distinction here is methodological: we propose a practical, open-source \u201cnoise emulator\u201d that (a) records compact per-run signatures of candidate perturbations under uncontrolled conditions and (b) replays them one-at-a-time (and in small factorial combinations) on a stabilized baseline to obtain causal effect sizes on CV and p99/median. This moves beyond correlation and provides an explicit counterfactual attribution: \u2018X% of p99 degradation is explained by remote pages\u2019 rather than \u2018pinning helped\u2019.",
        "Abstract": "Benchmark instability on modern HPC nodes is often dismissed as \u201csystem noise,\u201d yet practitioners need actionable answers: which mechanisms actually create run-to-run dispersion and p99 tail slowdowns, and which single fix will help most? We introduce Counterfactual Noise Injection (CNI), a controlled experimental methodology for causally attributing performance variability in stencil codes.\n\nCNI first constructs a stabilized baseline for Himeno (Jacobi 19-point stencil) using strict OpenMP affinity, NUMA-local allocation, and static scheduling. We then measure unstable executions under default settings and extract lightweight signatures of three candidate perturbation channels: frequency excursions/downclocking, NUMA placement (remote pages and cross-socket execution), and interrupt/jitter bursts. Next, we replay each channel in isolation by injecting synthetic perturbations into the stabilized baseline with tunable intensity: (i) induce frequency drops via optional DVFS control or an unprivileged AVX-heavy \u201cdownclock inducer\u201d; (ii) force controlled remote-page fractions via first-touch and numactl while holding thread placement fixed; (iii) generate periodic jitter via pinned timer/IO microbursts on selected cores. Across three Himeno sizes (~50MB, ~400MB, ~3.2GB), we quantify dose\u2013response curves for median, CV, and p95/p99 and fit a compact attribution model that decomposes natural instability into channel contributions.\n\nThe result is an inexpensive, portable harness that turns instability into a reproducible science experiment, yielding causal guidance for stable benchmarking and for selecting the minimal mitigation (pinning, localalloc, IRQ isolation, or frequency control) appropriate to each memory regime.",
        "Experiments": [
            "Stabilized baseline verification: For each Himeno size and thread count, run 50 repetitions with OMP_PROC_BIND=close, OMP_PLACES=cores, OMP_SCHEDULE=static, and numactl --localalloc. Report median MFLOPS, CV, p95/median, p99/median. Collect perf counters (LLC misses, bandwidth, dTLB misses, cycles stalled) and OS stats (context switches, migrations if available, interrupts).",
            "Natural instability capture: Repeat 100 runs under default settings (no explicit affinity/numa policy changes). Compute the same distribution metrics and extract per-run signatures: effective frequency summary (e.g., APERF/MPERF if accessible), migration/placement indicators (observed CPU IDs or scheduler stats), and jitter indicators (interrupt/context-switch burstiness).",
            "Injector A \u2014 frequency excursions (portable): Inject controlled downclocking using a pinned background AVX2/AVX-512 microkernel with adjustable duty cycle and core placement (same socket vs other socket). Optional (if permitted): direct DVFS toggling between two frequencies during the run. Sweep intensity; measure dose\u2013response on CV and p99/median.",
            "Injector B \u2014 NUMA remote-page fraction: Keep threads pinned; allocate arrays with controlled first-touch to achieve 0/25/50/75/100% remote pages (touch page ranges from a thread pinned to the opposite socket). Validate remote fraction via uncore bandwidth imbalance or remote-access counters when available. Measure impact on median/CV/p99 across sizes.",
            "Injector C \u2014 interrupt/jitter bursts: Create periodic jitter via a pinned high-rate timer thread and optional IO/network microbursts. Sweep burst rate and place jitter on (i) benchmark cores, (ii) separate cores on same socket, (iii) other socket. Measure tail amplification and relate to barrier/synchronization sensitivity.",
            "Small factorial interactions: Run a limited 2\u00d72\u00d72 design (low/high intensity for each channel) to test non-additive interactions (e.g., remote pages amplifying jitter tails).",
            "Attribution model + validation: Fit a simple model (e.g., linear + interaction terms or small GBDT) mapping channel intensities to (CV, p95/median, p99/median). Use it to explain natural-run variability via counterfactual decomposition. Validate by applying the model\u2019s predicted \u2018best single mitigation\u2019 and checking predicted tail reduction holds.",
            "Generality check: Repeat the pipeline on a second stencil miniapp (7-point Jacobi or miniHPCG-like kernel) to verify that dominant channels and regime shifts are not Himeno-specific."
        ],
        "Risk Factors and Limitations": [
            "Literature search returned no papers via the provided tool; positioning may miss specific prior art. Mitigation: broaden manual searches later (e.g., \u2018HPC noise injection\u2019, \u2018DVFS perturbation experiments\u2019, \u2018NUMA remote memory fault injection\u2019) and adjust novelty claims accordingly.",
            "Downclock induction strength varies by CPU and may be weaker on some systems. Mitigation: calibrate by measuring achieved frequency residency and report results as a function of measured frequency drop, not requested load.",
            "Remote-page control requires multi-socket NUMA hardware; on single-socket systems the NUMA injector is inapplicable. Mitigation: treat NUMA experiments as conditional and still evaluate frequency/jitter channels everywhere.",
            "Interrupt/jitter injection may not match real interrupt distributions. Mitigation: focus on controlled burstiness and validate similarity using the same counters/signatures used for natural runs.",
            "p99 estimation is sample-hungry. Mitigation: use p95 as a primary tail metric and confirm p99 on a smaller subset with 200+ runs."
        ]
    },
    {
        "Name": "phase_aligned_deterministic_runtime_v2",
        "Title": "Phase-Aligned Determinism: Collapsing Multi-Modal Performance in OpenMP Stencils via Deterministic First-Touch + Steady-State Gating",
        "Short Hypothesis": "Himeno\u2019s run-to-run instability on modern CPUs is often multi-modal (distinct \u201cfast\u201d and \u201cslow\u201d modes) rather than unimodal noise. The dominant cause is phase misalignment between initialization/first-touch (page placement), warmup (cache/TLB residency), and the start of measurement. Small timing differences can flip a run into a different mode (e.g., partially remote pages or different cache/TLB state), inflating CV and p99/median even when threads are pinned. If we (1) make first-touch deterministic and topology-consistent with the compute decomposition and (2) delay measurement until the iteration-time trajectory reaches a detected steady-state (adaptive gating), then the distribution becomes unimodal and tails shrink substantially without privileged controls (no DVFS/turbo toggles) and with minimal median impact. This is best studied on Himeno because it has a clear init + iterative steady-state structure and three memory-regime footprints where page placement and warmup effects should differ; microbenchmarks lack these phase transitions.",
        "Related Work": "Best practices (thread pinning, numactl, static scheduling) and OS-noise studies address variability but typically treat the program as a single phase and report averaged performance. First-touch NUMA placement is known, but prior work rarely tests whether *run-to-run timing differences during initialization* create discrete performance modes under otherwise fixed affinity. Likewise, warmup iterations are common, but fixed warmup lengths do not address run-dependent convergence to steady-state. This proposal is distinct in (i) explicitly testing and quantifying multi-modality (mode detection) as the core phenomenon, (ii) introducing an application-level, unprivileged protocol to \u201cseal\u201d page placement deterministically, and (iii) using adaptive steady-state gating to make measurement start reproducible. Compared to our earlier proposals, this is not an autotuner and not a noise-injection causal study; it is a minimal, principled runtime methodology aimed at collapsing the performance distribution itself.",
        "Abstract": "Even with pinned threads, stencil benchmarks can show unstable performance with large p95/p99 slowdowns. We posit that this instability is frequently multi-modal: runs fall into distinct performance modes due to phase misalignment between initialization (NUMA first-touch), warmup (cache/TLB residency), and the start of timed iterations. We propose Phase-Aligned Determinism (PAD), a lightweight, unprivileged methodology to make stencil performance reproducible.\n\nPAD has two components. First, deterministic first-touch: arrays are page-touched in parallel using the same decomposition as the compute loop, ensuring stable page ownership and avoiding accidental remote placement caused by initialization timing. Second, adaptive steady-state gating: rather than timing after a fixed number of warmup iterations, PAD begins measurement only once the iteration-time trajectory stabilizes (e.g., rolling-window variance below a threshold), reducing sensitivity to transient cache/TLB effects.\n\nUsing the Himeno benchmark across three footprints (~50MB, ~400MB, ~3.2GB), we will (i) detect and quantify performance multi-modality, (ii) show PAD collapses distributions (lower CV and p95/p99) while preserving median MFLOPS, and (iii) attribute improvements to reduced mode switching using simple counters and iteration-time traces. We will validate generality on a second stencil kernel and release an open-source harness for reproducible benchmarking.",
        "Experiments": [
            "Multi-modality baseline: For each Himeno size and thread count, run 100 repetitions with fixed affinity (OMP_PROC_BIND=close, OMP_PLACES=cores, OMP_SCHEDULE=static). Record per-iteration times for the first ~200 iterations. Quantify distribution shape (dip test and 2-component GMM fit) and report median, CV, p95/median, p99/median.",
            "Deterministic first-touch vs common inits: Compare (A) serial init, (B) naive parallel init, (C) PAD deterministic first-touch that touches pages in the same (k-slab or i-block) partition used by the compute loop. Keep compute identical. Evaluate changes in multi-modality metrics and tail ratios. Where available, collect NUMA-related proxies: per-socket bandwidth imbalance, stalled cycles, and (if supported) remote access counters.",
            "Adaptive steady-state gating: Implement gating that starts timing when a stability criterion is met, e.g., rolling-window CV of iteration time < 1% for W=20 iterations (with a max warmup cap). Compare against fixed warmup lengths (0, 10, 50, 100 iters). Evaluate tail reduction and overhead (additional warmup iterations).",
            "PAD composition and ablation: Run four configurations: baseline, first-touch only, gating only, full PAD. Determine which component matters most per problem size (cache-resident vs DRAM-bound) and whether benefits are additive.",
            "Robustness to mild background activity: Add a low-duty background thread pinned to a non-benchmark core (same socket vs other socket) generating periodic wakeups. Test whether PAD still collapses distributions compared to baseline pinned execution.",
            "Generality: Repeat key experiments on a second stencil kernel (7-point Jacobi or miniHPCG smoother) to show PAD\u2019s effect is not Himeno-specific."
        ],
        "Risk Factors and Limitations": [
            "If the platform\u2019s variability is dominated by strong external OS jitter or contention, PAD may not fully remove tails; it targets internal phase-induced mode switching. Mitigation: explicitly report when distributions remain unimodal-but-wide and recommend combining PAD with standard isolation practices.",
            "Some systems may already have deterministic initialization (e.g., benchmark code paths) reducing observed gains. Mitigation: include multiple initialization variants and show when/why PAD matters.",
            "Adaptive gating could be criticized as altering benchmark methodology. Mitigation: report both steady-state MFLOPS (PAD metric) and end-to-end time including warmup; position PAD as a reproducibility protocol rather than a pure speedup trick.",
            "NUMA attribution counters may be unavailable. Mitigation: rely on controlled interventions (numactl localalloc/interleave) and observable proxies (bandwidth imbalance, stalled cycles, iteration-time traces).",
            "On single-socket machines, first-touch NUMA effects are weaker; PAD\u2019s impact may be smaller. Mitigation: still evaluate cache/TLB warmup stabilization via gating and report topology dependence."
        ]
    },
    {
        "Name": "tlbpage_coloring_stencils",
        "Title": "TLB-First Stencil Optimization: Can Page-Coloring and Huge-Page Shaping Eliminate Himeno\u2019s Long-Tail Slowdowns?",
        "Short Hypothesis": "A substantial fraction of Himeno\u2019s run-to-run variability and p99/median tail slowdowns\u2014especially in the ~400MB and ~3.2GB regimes\u2014comes from unstable TLB behavior (dTLB misses and page-walk contention) rather than only NUMA placement, migration, or bandwidth. This is plausible because Himeno\u2019s 3D stencil streams through multiple large arrays with regular-but-multi-stream access, making it sensitive to (i) how virtual pages map to sets in the shared TLB/page-walk hardware and (ii) whether the OS returns fragmented physical pages across runs. If we deliberately \u201cshape\u201d page layout using user-level allocation strategies (transparent huge pages / explicit huge pages when available, page-aligned slab allocation, and lightweight page-color steering via controlled padding/offsets), we can reduce both median stalls and\u2014more importantly\u2014collapse tails without privileged system controls. This direction is best investigated on Himeno because its three canonical sizes cross the boundary where TLB pressure becomes a first-class bottleneck, and because its memory access is structured enough to connect layout interventions to counter changes; simpler microbenchmarks don\u2019t exhibit the same multi-array stencil reuse and synchronization patterns that amplify page-walk stalls into p99 tails.",
        "Related Work": "Prior HPC tuning for stencils focuses on cache blocking, vectorization, and NUMA affinity/first-touch. Separately, systems work discusses huge pages and TLB misses as an optimization, but typically reports average speedups and does not treat tail metrics (p95/p99) or run-to-run reproducibility as the primary objective. Page coloring is well-studied in OS research, yet is rarely explored as a practical, user-level technique for improving stability of HPC kernels under standard Linux allocators. This proposal is distinct in (1) making TLB/page-walk instability a testable primary hypothesis for Himeno variability, (2) introducing low-cost, user-space page-layout \u201cshaping\u201d (offset/padding-based color steering + huge-page policy) rather than requiring OS/kernel changes, and (3) evaluating success on distributional metrics (CV, p99/median) and counterfactual layout randomization tests to establish causality. It is not a trivial extension of \u2018use huge pages\u2019: we explicitly target tail reduction and reproducibility, and we test controlled layout perturbations to show when/why tails appear.",
        "Abstract": "Modern HPC benchmarking frequently attributes instability to NUMA placement, frequency scaling, or OS jitter. We propose an alternative, under-explored mechanism for stencil codes: unstable TLB and page-walk behavior caused by run-dependent physical page allocation and unfavorable page-to-TLB-set interactions across multiple large arrays. We study this hypothesis on the Himeno benchmark (19-point Jacobi stencil) across three memory regimes (~50MB, ~400MB, ~3.2GB), where TLB pressure should vary sharply.\n\nWe introduce TLB-First Shaping (TFS), a set of user-level memory-layout interventions: (i) huge-page policy selection (THP madvise/always/never; optional explicit hugetlbfs when accessible), (ii) page-aligned slab allocation with deterministic touch order, and (iii) lightweight page-color steering via controlled base-address offsets and padding between arrays to alter set-indexing interactions. We evaluate TFS using replicated runs and distributional metrics (median MFLOPS, CV, p95/p99 over median), while collecting counters for dTLB load misses, page-walk cycles, LLC misses, and bandwidth.\n\nTo establish causality, we add a controlled layout randomization baseline that intentionally perturbs offsets between arrays each run; if tails worsen with randomization and shrink with TFS, we obtain strong evidence that page-layout/TLB effects drive variability. The outcome is a practical recipe and open-source harness for making stencil performance both faster and more reproducible, plus a clear characterization of when TLB-centric interventions dominate NUMA-centric ones.",
        "Experiments": [
            "Baseline diagnosis across sizes: For each Himeno size and thread count, run 50\u2013100 repetitions under pinned threads (OMP_PROC_BIND=close, OMP_PLACES=cores, static schedule) and NUMA-local allocation (numactl --localalloc). Report median, CV, p95/median, p99/median. Collect perf counters: dTLB-load-misses, dTLB-walk cycles (or closest available), iTLB misses, LLC misses, stalled cycles, bandwidth. Goal: determine whether tail events correlate with TLB/page-walk spikes even after controlling for migration/NUMA.",
            "Counterfactual layout randomization (causality test): Modify allocation so that, each run, arrays receive randomized page-aligned base offsets and randomized padding gaps (while keeping total size constant). Keep affinity/NUMA fixed. Hypothesis: if tails and CV increase and TLB counters become bursty, layout is a causal contributor.",
            "Huge-page policy sweep: Compare (A) THP=never, (B) THP=madvise + madvise(MADV_HUGEPAGE) on arrays, (C) THP=always (if permitted), and (D) explicit hugetlbfs-backed allocations (optional). Evaluate effect on median/CV/p99 and on dTLB/page-walk counters. Include a \u2018fragmentation stress\u2019 condition by running a memory-fragmenting allocator microbenchmark before Himeno to test robustness.",
            "Page-color steering via offset/padding search: Implement a small search over a discrete set of offsets/paddings (e.g., 0..2MB in 4KB or 64KB steps; plus inter-array padding multiples of 2MB/1MB/64KB). Budget ~50\u2013150 configurations per size. Objective is multi-metric: minimize p99/median and CV subject to \u22642% median loss (or maximize median subject to p99/median constraint).",
            "Ablation: isolate TLB vs cache effects: Repeat key configurations with identical cache blocking/SIMD settings to ensure gains are not merely cache locality improvements. Use counters to show improvements primarily reduce page-walk/TLB stalls rather than LLC misses/bandwidth changes.",
            "Generality check: Apply the same TFS interventions to a second stencil miniapp (7-point Jacobi or a miniHPCG smoother). Success criterion: consistent tail reduction and TLB-counter stabilization in at least one additional code."
        ],
        "Risk Factors and Limitations": [
            "TLB/page-walk counters are CPU-specific and sometimes hard to interpret. Mitigation: use multiple proxy counters (dTLB misses, walk cycles if available, stalled cycles) and rely on controlled layout randomization as the main causal lever.",
            "Huge pages may be restricted or inconsistently configured on shared clusters. Mitigation: ensure the core contribution works with THP madvise/never and offset/padding steering alone; treat hugetlbfs as optional.",
            "Page-color steering in user space is approximate because physical page colors are not fully controllable without OS support. Mitigation: treat steering as a statistical technique (repeat allocations, measure distributions) and show reproducible improvements in tail metrics even with partial control.",
            "If variability is dominated by external noise (interrupts, frequency), TFS may have limited effect. Mitigation: run under a stabilized baseline (pinning + localalloc) and explicitly quantify residual tail reduction attributable to layout shaping.",
            "Added padding increases memory footprint and could hurt bandwidth on the largest size. Mitigation: constrain padding search and report overhead; optimize for tail reduction under a small memory-overhead budget (e.g., \u22645%)."
        ]
    },
    {
        "Name": "synchronization_tail_amplification_v2",
        "Title": "Barrier Tail Amplification in OpenMP Stencils: Turning Per-Thread Hiccups into Predictable p99 (and Fixing It)",
        "Short Hypothesis": "Himeno\u2019s p95/p99 slowdowns are often dominated by a max-over-threads effect: rare, localized per-thread \u201chiccups\u201d (interrupts, page-walk bursts, brief frequency dips) get amplified into whole-iteration tail events because of global synchronization (implicit barriers, reductions, and phase boundaries). If we instrument per-thread iteration timing and barrier wait time, we can (i) predict application-level p99 from per-thread hiccup statistics using a simple order-statistics model, and (ii) reduce p99/median substantially with minimal median impact by applying small synchronization-structure changes (hierarchical barriers and reduced barrier frequency) that limit amplification without requiring privileged system controls.",
        "Related Work": "Most Himeno/HPC stability guidance emphasizes pinning, NUMA-local allocation, DVFS/turbo control, OS noise isolation, and sometimes huge pages/TLB tuning\u2014i.e., reducing the *sources* of variability. Barrier algorithms are well-studied for average overhead, and OS-noise studies show sensitivity of tightly synchronized codes, especially MPI. What is missing is a focused, distribution-first treatment of *tail latency* in shared-memory stencils that (a) directly measures how much of p99 is explained by max-thread compute-time inflation versus collective slowdowns, (b) validates an explicit predictive model of p99 from per-thread hiccup distributions, and (c) proposes minimal code-level synchronization interventions aimed specifically at reducing p99/median rather than only improving mean throughput. This is not an autotuner, not a noise injector per se, and not a memory-layout study; it targets the amplification mechanism that can keep tails large even after standard pinning/NUMA fixes.",
        "Abstract": "Performance instability on modern HPC CPUs is often treated as an external nuisance (NUMA placement, DVFS, OS jitter). We hypothesize that in shared-memory stencil codes, long-tail slowdowns are frequently created by synchronization tail amplification: a rare slowdown on one thread becomes a full-iteration slowdown because barriers and reductions force all threads to wait. We study this phenomenon in the Himeno benchmark (19-point Jacobi stencil) across three memory regimes (~50MB, ~400MB, ~3.2GB).\n\nFirst, we instrument Himeno to record per-thread iteration compute time and barrier wait time with low overhead. This enables a decomposition of tail iterations into (i) single-/few-thread compute inflation versus (ii) collective compute inflation. We then test an order-statistics model predicting application-level p95/p99 from per-thread hiccup distributions and thread count.\n\nSecond, we introduce two simple, feasible interventions that reduce amplification without privileged controls: (1) hierarchical synchronization aligned to NUMA domains to confine waiting, and (2) reduced barrier frequency via k-slab pipelining with bounded slack, preserving Jacobi correctness while decreasing global synchronization opportunities for hiccups to dominate. Under both natural noise and controlled, user-level jitter injection, we evaluate improvements in p95/p99 and CV while tracking median MFLOPS.\n\nThe outcome is a practical explanation for why tails persist even under pinned/NUMA-local runs, plus lightweight synchronization patterns that measurably improve reproducibility for stencil-like workloads.",
        "Experiments": [
            "Tail decomposition baseline: For each Himeno size and thread count, run 60\u2013100 repetitions under pinned threads (OMP_PROC_BIND=close, OMP_PLACES=cores, OMP_SCHEDULE=static) and numactl --localalloc. Instrument per-thread compute time per iteration and barrier wait time (sample every K iterations after warmup). Report median MFLOPS, CV, p95/median, p99/median, and a \u2018tail attribution\u2019 statistic: fraction of p99 iterations where max-thread compute inflation explains >X% of the iteration slowdown.",
            "Predictive model validation: Fit a simple predictor for application iteration time using order statistics: T_iter \u2248 max_i(T_i) + B, where T_i are per-thread compute-time samples and B is measured barrier overhead. Predict p95/p99 across thread counts and sizes; evaluate prediction error for p95/p99 and whether errors shrink when including barrier-wait distributions explicitly.",
            "Intervention A \u2014 hierarchical barriers: Replace a single global barrier with a two-level barrier (intra-NUMA domain + representatives synchronize globally). Keep computation identical. Evaluate changes in p95/p99, CV, and median; check whether tail attribution shifts from barrier-wait dominated to compute-dominated (or vice versa).",
            "Intervention B \u2014 reduce global barrier frequency (bounded-slack k-slab pipelining): Restructure the loop to process k-slabs with bounded slack S (e.g., S\u2208{1,2,4}) using per-slab readiness flags (atomics) instead of a full global barrier each iteration. Validate numerical equivalence. Measure p95/p99, CV, median MFLOPS, and overhead (atomic ops, cache misses).",
            "Noise sensitivity mapping (portable jitter injection): Add a user-level jitter thread with adjustable duty cycle pinned to (i) one benchmark core, (ii) a non-benchmark core on same socket, (iii) other socket. Measure dose\u2013response of p95/p99 and whether interventions reduce the slope (tail sensitivity) compared to baseline.",
            "Generality: Apply the instrumentation + best-performing intervention to a second stencil (7-point Jacobi or miniHPCG smoother). Success criterion: consistent reduction in p95/p99 with \u22642\u20133% median loss (or a clearly explained trade-off)."
        ],
        "Risk Factors and Limitations": [
            "Instrumentation may perturb timing and tails. Mitigation: sampling, per-thread buffers, and verifying that uninstrumented vs instrumented distributions match within tolerance.",
            "If tail events are mostly global (uncore throttling, DRAM refresh, system-wide contention), desynchronization may not help. Mitigation: the tail decomposition explicitly detects collective slowdowns and reports when amplification is not the dominant mechanism.",
            "Bounded-slack pipelining may reduce locality or add atomic overhead. Mitigation: keep S small, compare against hierarchical barrier (lower-risk), and report Pareto trade-offs (median vs p99).",
            "Hierarchical barrier effectiveness depends on NUMA topology and OpenMP runtime behavior. Mitigation: implement barriers in application code (not relying on runtime internals) and evaluate on at least two OpenMP runtimes if feasible.",
            "Literature positioning risk due to limited automated search results. Mitigation: strengthen novelty claim around explicit p99 modeling + tail attribution + minimal synchronization interventions once a broader manual literature review is done."
        ]
    },
    {
        "Name": "self_calibrating_stencil_v2",
        "Title": "Self-Calibrating Himeno: A Closed-Loop Benchmark that Detects Slow Modes and Applies Minimal Fixes",
        "Short Hypothesis": "A large share of Himeno\u2019s instability is due to a low-dimensional, run-specific latent node state (primarily NUMA page locality, effective memory bandwidth headroom, and synchronization/jitter intensity) that causes discrete \u201cslow modes\u201d and long tails. A short, in-process calibration phase (\u22641\u20132s) can reliably infer this state using only user-level measurements on the same arrays, and a small set of minimal mitigations (re-touch placement, choose between two schedules, choose between two loop variants) can prevent slow-mode runs, reducing CV and p95/p99/median with negligible median loss and without privileged controls. This is best tested on Himeno because it has (i) large, persistent arrays whose placement can be corrected cheaply, (ii) a clear steady-state loop to evaluate distributional stability, and (iii) problem sizes that span cache- to DRAM-bound regimes where the latent state should matter differently.",
        "Related Work": "Best practices (pinning, numactl policies, fixed frequency) and OS-noise studies explain sources of variability but do not create a closed-loop mechanism that adapts per run. Autotuning typically searches offline for a best configuration; our goal is online identification-and-control with a tiny runtime budget, producing both a performance number and a diagnostic state report. This also differs from deterministic-first-touch methods by making the intervention conditional: only pay the re-touch/adjustment cost when calibration predicts a slow mode. (Tool-based literature search returned no papers; the proposal is positioned conservatively as a new closed-loop methodology rather than claiming no prior work exists.)",
        "Abstract": "Run-to-run instability on modern HPC nodes is often treated as unavoidable \u201csystem noise,\u201d yet many slowdowns are structured: runs fall into discrete slow modes driven by NUMA page placement, reduced bandwidth headroom, and jitter that is amplified by synchronization. We propose Self-Calibrating Himeno (SCH), a closed-loop benchmark variant that (1) estimates the node\u2019s run-specific state using a short calibration phase and (2) applies a minimal mitigation to avoid slow modes before timing begins.\n\nSCH adds \u22641\u20132 seconds of calibration using micro-probes that operate on the same arrays and thread placement as the real stencil: a page-sampled locality probe (latency mixture to infer remote-page fraction), a bandwidth headroom probe (short streaming pass to estimate achievable DRAM bandwidth under current conditions), and a jitter probe (short repeated compute+barrier timing to quantify burstiness). Based on these signals, SCH selects one of a few pre-defined actions: do nothing, deterministic re-touch aligned to the compute decomposition, switch OpenMP schedule/chunking, or choose between two precompiled loop variants (e.g., cache-tiled vs streaming-friendly).\n\nAcross the three canonical Himeno sizes (~50MB, ~400MB, ~3.2GB), we evaluate whether SCH reduces CV and p95/p99 tail ratios while preserving median MFLOPS, and we release an open-source harness that reports both performance and a per-run \u201cstate report\u201d to improve reproducibility and diagnosis on shared systems.",
        "Experiments": [
            "Slow-mode existence and predictability: Run 100 repetitions per size under a fixed affinity baseline (e.g., OMP_PROC_BIND=close, OMP_PLACES=cores, static schedule) but with natural OS variability. Test for multi-modality (e.g., Hartigan dip test or 2-component GMM on iteration time). Train a small classifier/regressor using calibration features to predict slow-mode membership and p95/p99. Metrics: AUC for slow-mode prediction; MAE for p95/p99; calibration overhead.",
            "Controlled ground-truth for NUMA locality inference: Force 0/25/50/75/100% remote pages via controlled first-touch (touch page ranges from a thread pinned to the opposite socket), keeping compute threads pinned. Validate the locality probe\u2019s estimated remote fraction against the known setting. Metrics: absolute error; monotonicity; correlation with MFLOPS and tail ratios.",
            "Closed-loop mitigation evaluation (main result): Implement a discrete policy set: (A) none, (B) deterministic re-touch (parallel first-touch matching compute partition), (C) schedule switch (static vs guided or different chunk), (D) variant switch (two variants: tiled vs untiled, or two tile sizes). Compare three systems: baseline fixed config, best-practice static config (pinning+localalloc), and SCH closed-loop. Metrics: median MFLOPS, CV, p95/median, p99/median; plus \u201cslow-mode rate\u201d (fraction of runs in slow mode).",
            "Calibration budget sweep: Evaluate budgets {0.1s, 0.5s, 1s, 2s}. Metrics: stability improvement vs overhead; identify the smallest budget that achieves most gains.",
            "Robustness under mild contention: Add a low-duty background memory streamer pinned to (i) same socket non-benchmark cores and (ii) other socket. Test whether SCH adapts (e.g., chooses streaming-friendly variant) and whether it maintains lower p95/p99 than static best-practice settings.",
            "Generality check: Apply SCH (calibration + the best-performing mitigation subset) to a second stencil kernel (7-point Jacobi or miniHPCG smoother). Success criteria: calibration predicts slow modes and reduces p95/p99 with \u22642\u20133% median loss."
        ],
        "Risk Factors and Limitations": [
            "Calibration probes may perturb cache/TLB state and slightly change steady-state performance. Mitigation: keep probes short, page-sampled, and separated from the timed region; quantify bias by comparing no-probe vs probe-only runs.",
            "Some platforms may not exhibit strong slow modes; distributions may be unimodal but wide. Mitigation: still evaluate p95/p99 reduction; report when SCH provides limited benefit and analyze which latent-state signals are uninformative.",
            "Remote-page inference without NUMA counters may be noisy. Mitigation: validate using controlled first-touch ground truth and use multiple signals (latency mixture + bandwidth imbalance proxies).",
            "Mitigation actions could trade median for stability. Mitigation: constrain policy to a small set and include a rule such as \u2018only mitigate when predicted tail risk exceeds threshold\u2019; report Pareto trade-offs explicitly.",
            "Per-run adaptation could be criticized as altering benchmark methodology. Mitigation: report both raw baseline and SCH-adjusted results; position SCH as a reproducibility/diagnostic mode rather than replacing standard scores."
        ]
    },
    {
        "Name": "stochastic_memory_placement_fingerprinting",
        "Title": "Fingerprinting Hidden NUMA & Page-Placement States: A 200ms Probe that Predicts (and Prevents) Himeno Slow Runs",
        "Short Hypothesis": "A large fraction of Himeno\u2019s run-to-run instability is not continuous noise but switching among a small number of hidden memory-placement states (e.g., different remote-page fractions, different interleavings, different physical fragmentation/huge-page coverage) that arise stochastically from the OS allocator and first-touch timing\u2014even when thread pinning is fixed. If we can cheaply fingerprint the current run\u2019s memory-placement state using a very short in-process probe on the benchmark\u2019s own arrays (without privileged counters), then we can (i) predict whether the run will land in a slow tail mode (p95/p99) and (ii) apply a minimal corrective action (deterministic re-touch / rebind + re-touch / hugepage-madvise + re-touch) before timing. This is best investigated on Himeno because its large persistent arrays and clear steady-state loop make it possible to probe the exact memory that will dominate runtime; simpler microbenchmarks cannot test whether the probe predicts a real application\u2019s tail behavior.",
        "Related Work": "Prior work and best practices emphasize pinning, numactl policies, disabling turbo, and general OS-noise isolation. Other work optimizes stencils via tiling/SIMD for average performance. Our proposal is distinct in framing instability as a small set of *latent memory-placement states* and introducing a practical, user-level *fingerprinting + corrective control loop* that operates on the application\u2019s real arrays and targets tail risk (p95/p99), not just mean/median. Unlike earlier ideas listed (PAD determinism, offline Pareto autotuning, causal noise injection, TLB shaping), this proposal\u2019s novelty is the explicit identification problem: learning a compact, counter-free fingerprint that predicts slow-mode membership across runs and machines, and using it to decide whether to intervene. It is not a trivial extension of deterministic first-touch because the intervention is conditional and driven by a learned fingerprint, enabling low overhead when the run is already in a good state.",
        "Abstract": "Modern HPC nodes exhibit benchmark instability driven by memory placement, allocator nondeterminism, and runtime timing effects. For the Himeno stencil benchmark, we hypothesize that tail slowdowns (p95/p99) often arise from switching among a small set of hidden memory-placement states\u2014e.g., varying remote-page fractions or huge-page coverage\u2014rather than from purely random jitter. We propose Memory-Placement Fingerprinting (MPF): a lightweight, in-process probe (\u2248200ms\u20131s) that operates on Himeno\u2019s actual arrays to infer the current run\u2019s latent placement state without privileged hardware counters. MPF performs page-sampled pointer-chasing and streaming micro-passes over each major array, measuring per-thread latency histograms, cross-thread bandwidth imbalance, and barrier-amplified hiccup rates. Using these features, MPF predicts tail risk (probability of falling into the slow mode) and triggers a minimal corrective action before timing: deterministic parallel re-touch aligned to the compute decomposition, optional rebind to a different OpenMP placement, and/or MADV_HUGEPAGE on arrays followed by re-touch. We evaluate MPF across three canonical Himeno sizes (~50MB, ~400MB, ~3.2GB) and multiple thread counts, reporting median MFLOPS, CV, and p95/p99 over median. The expected outcome is a practical methodology that turns unstable benchmarking into a measurable identification-and-control problem, reducing tail events with negligible impact on median performance and no need for privileged system configuration.",
        "Experiments": [
            "Establish slow-mode structure: For each problem size and thread count, run 100 repetitions under fixed affinity (OMP_PROC_BIND=close, OMP_PLACES=cores, OMP_SCHEDULE=static). Record per-run MFLOPS plus per-iteration timing traces (sampled). Test for multi-modality (Hartigan dip test; 2-component GMM) and quantify tail metrics (CV, p95/median, p99/median).",
            "Design the fingerprint probe (no counters): Implement a 200ms\u20131s probe that (i) page-samples each array with dependent loads (pointer-chase constructed from an index array) to emphasize latency/remote effects, and (ii) performs a short streaming pass to estimate achievable bandwidth. Collect features: per-thread latency quantiles, socket-level bandwidth imbalance proxy (aggregate per-thread throughput variance), and short barrier microbenchmark hiccup rate. Validate probe stability (repeat probe 20x) and overhead.",
            "Ground-truth controlled placement states: Create known memory-placement conditions by controlled first-touch (0/25/50/75/100% remote pages) and by numactl policies (localalloc vs interleave). Optionally induce fragmentation by allocating/freeing a large memory region before array allocation. Check that MPF features separate these states (clustering purity; silhouette score) and correlate with Himeno median and tail metrics.",
            "Predict slow-mode and tails: Train a lightweight classifier/regressor (e.g., logistic regression or small gradient-boosted trees) mapping MPF features + topology (sockets, threads) + size to (a) slow-mode membership and (b) predicted p95/p99. Metrics: AUC for slow-mode prediction; MAE for p95/p99; calibration curves; generalization across days and across mild background load.",
            "Minimal corrective actions (conditional control): Define a small action set: A0=do nothing, A1=deterministic parallel re-touch matching compute partition, A2=re-touch + MADV_HUGEPAGE, A3=re-touch after switching OMP_PLACES (cores vs sockets). Use the predictor to trigger actions only when tail risk exceeds a threshold. Compare against always-on PAD-style deterministic first-touch and against best-practice static settings. Metrics: median MFLOPS, CV, p95/p99 over median, and intervention rate/overhead.",
            "Ablation: Separate what MPF is detecting: Repeat experiments with (i) strict numactl --localalloc (minimize NUMA variation) to see if remaining predictability comes from fragmentation/huge-page/TLB effects, and (ii) THP disabled/enabled to test sensitivity. Report how predictor performance changes."
        ],
        "Risk Factors and Limitations": [
            "If the platform\u2019s variability is dominated by external contention (other jobs, network/IO interrupts), memory-placement fingerprints may not predict tails well. Mitigation: include a controlled mild-load condition and explicitly report when predictability collapses.",
            "Unprivileged probing may be too weak to distinguish subtle remote-page fractions on some CPUs. Mitigation: use dependent-load pointer chasing and per-thread latency histograms; increase probe budget up to 1s when needed and report the overhead\u2013accuracy trade-off.",
            "Corrective actions (re-touch, hugepage advice) may not be allowed or may have inconsistent effects under cluster policies. Mitigation: keep the action set purely user-level and optional; treat MADV_HUGEPAGE as best-effort and always evaluate re-touch alone.",
            "The probe itself may perturb cache/TLB state and slightly bias performance. Mitigation: separate probe and timed region with a fixed cool-down/warm-up and quantify any systematic bias by comparing runs with probe disabled/enabled when no action is taken.",
            "Generalization across architectures may be limited. Mitigation: train simple models, include topology as features, and validate on at least two distinct nodes/runtimes if available in-lab."
        ]
    },
    {
        "Name": "temporal_interference_spectroscopy_v2",
        "Title": "Temporal Interference Spectroscopy: Measuring and Avoiding Cadence\u2013Noise Resonances that Create Himeno\u2019s p99 Tails",
        "Short Hypothesis": "A meaningful portion of Himeno\u2019s long-tail slowdowns (p95/p99) is caused by phase-locking between the benchmark\u2019s iteration/synchronization cadence and a small number of quasi-periodic system activities (timer/housekeeping ticks, softirq bursts, background kernel threads, thermal/frequency control loops). If we sweep the application cadence while holding the computational work per stencil update constant, we will observe reproducible \u201ctail peaks\u201d (bands where p99/median worsens). These peaks reveal the dominant temporal interference scales on a node. Once identified, simple user-level countermeasures\u2014small cadence shifts or micro-dithering\u2014can avoid these resonances and reduce tails without privileged OS changes. This is best tested on Himeno because its iterative stencil structure provides a stable, controllable sampling clock and synchronization points that amplify phase-aligned perturbations into p99 tails; microbenchmarks lack this cadence/synchronization structure.",
        "Related Work": "Most HPC variability work focuses on reducing noise sources (pinning, NUMA placement, DVFS/turbo control, OS isolation) and reports average/median outcomes; tail metrics are less central. OS-noise literature often characterizes perturbation magnitude but not an application\u2019s frequency response as a first-class object. Datacenter tail-latency work emphasizes queueing/load and does not typically use cadence sweeps to identify resonance-like coupling. This proposal is distinct from our prior ideas (autotuning Pareto fronts, counterfactual noise injection, deterministic first-touch/gating, TLB shaping, barrier amplification modeling, online fingerprinting) because it introduces a new diagnostic primitive: estimating a node-specific cadence\u2192tail \u2018transfer function\u2019 and then using that measurement to design minimal anti-resonance mitigations (cadence shift/dither). It is not just \u2018add jitter\u2019: the novelty is systematic cadence scanning + response estimation + targeted avoidance.",
        "Abstract": "Benchmark instability on modern HPC nodes is often dismissed as \u201csystem noise,\u201d yet practitioners need actionable explanations for p99 tail slowdowns. We propose Temporal Interference Spectroscopy (TIS), a user-level method that treats an iterative stencil code as a sampling instrument for temporal interference.\n\nUsing the Himeno benchmark (19-point Jacobi stencil) across three memory regimes (~50MB, ~400MB, ~3.2GB), TIS systematically sweeps the iteration/synchronization cadence while keeping the work per stencil update unchanged. We implement cadence control primarily by batching B stencil updates between synchronization points (B\u2208{1,2,4,8}) and secondarily by adding calibrated micro-delays that do not change memory traffic. For each cadence setting, we run replicated trials and report distributional metrics (median MFLOPS, CV, p95/p99 over median) alongside lightweight OS statistics and hardware counters.\n\nWe expect to observe cadence bands where p99/median sharply degrades, indicating phase-locking between benchmark cadence and quasi-periodic system activity. We validate causality by injecting periodic user-level interference at controlled frequencies and confirming it amplifies tails most strongly near the same bands. Finally, we apply two minimal mitigations\u2014cadence shifting and micro-dithering\u2014to avoid resonant bands and reduce p99 tails with minimal median loss. TIS yields an inexpensive diagnostic tool and practical guidance for reproducible stencil benchmarking without requiring privileged system configuration.",
        "Experiments": [
            "Cadence knob implementation (keep work/update constant): (1) Barrier batching: restructure the OpenMP region so that global synchronization occurs every B updates (B\u2208{1,2,4,8}), while total updates is fixed; report per-update MFLOPS. (2) Optional micro-delay: add a short delay after each (batched) synchronization using both busy-wait and nanosleep variants to separate DVFS/idle effects.",
            "Core measurement: For each Himeno size and thread configuration (1-socket and 2-socket), sweep cadence (via B and delay) to cover ~0.1ms\u201320ms effective sync periods. For each point collect 40\u201360 runs. Metrics: median MFLOPS, CV, p95/median, p99/median.",
            "Response-curve extraction: Plot p99/median vs cadence; detect peaks (simple peak finding) and quantify peak strength/width. Collect correlates per run: context switches, migrations, voluntary/involuntary switches (getrusage), and perf stat counters (cycles, stalled cycles, LLC misses, dTLB misses). Test correlation between peak regions and elevated OS activity indicators.",
            "Causality check with periodic interference oscillator: Add a pinned helper thread that wakes periodically at frequency f and performs short bursts (compute-only and memory-touch variants). Sweep f; show that tail amplification is maximized when f aligns with identified peak bands, and weaker off-band.",
            "Mitigation A \u2014 cadence shifting: Choose a small constant cadence offset that moves the sync period away from a peak band; evaluate tail reduction on the original (unmodified) cadence setting by applying the offset only during timed region. Compare to baseline pinned+localalloc.",
            "Mitigation B \u2014 micro-dithering: Add tiny randomized per-sync delay \u03b5 (e.g., uniform [0,\u03b5], \u03b5 < 1% of sync period) to break phase-locking. Evaluate changes in p95/p99, CV, and median; verify that peaks flatten in the response curve.",
            "Generality: Repeat the main sweep + best mitigation on a second stencil miniapp (7-point Jacobi or miniHPCG smoother). Success: similar cadence-dependent tail peaks and measurable p99/median reduction with \u22642\u20133% median loss."
        ],
        "Risk Factors and Limitations": [
            "Literature positioning risk (no papers returned by tool). Mitigation: keep novelty claims focused on the cadence-response measurement framing rather than claiming no prior work exists; update related work after manual search.",
            "Cadence changes may alter cache/NUMA behavior (especially barrier batching). Mitigation: report both per-update MFLOPS and hardware counters to show memory traffic is comparable; treat batching as a cadence knob and explicitly quantify any locality changes.",
            "Busy-wait/nanosleep can change frequency/idle residency, confounding resonance effects. Mitigation: treat delay-based knob as secondary; measure APERF/MPERF when available and compare busy-wait vs nanosleep to separate DVFS effects.",
            "Some systems may show flat response (no strong peaks). Mitigation: still publishable as a negative result plus validated sensitivity via injected periodic interference; identify which platforms/noise regimes produce peaks.",
            "Micro-dithering may slightly reduce median throughput. Mitigation: constrain \u03b5 tightly and present Pareto trade-offs (median vs p99); target tail reduction with minimal overhead."
        ]
    },
    {
        "Name": "affinity_hysteresis_controller_v2",
        "Title": "Affinity with Hysteresis: A Tiny Feedback Controller to Prevent Rare Mapping Failures that Create p99 Tails in OpenMP Stencils",
        "Short Hypothesis": "Even when users set OMP_PROC_BIND/PLACES, Himeno still exhibits large CV/p99 on some systems because rare, transient \u201cmapping failures\u201d (brief CPU migrations, SMT sibling contention, or cross-socket drift during runtime sleep/wake and barrier wake-up) persist long enough to be amplified by synchronization into tail iterations. Static pinning is necessary but not sufficient because it is not continuously enforced and does not react to short-lived disturbances. A lightweight, in-application feedback controller with hysteresis can (i) detect imminent tail events from cheap signals (CPU-id churn + per-thread progress skew + barrier wait imbalance) and (ii) apply minimal corrective actions (re-assert affinity; temporarily cap active threads; adjust waiting strategy around barriers). This should reduce p95/p99 and CV with minimal median loss, especially in regimes where synchronization amplification dominates. Himeno is an ideal testbed because it is iterative (natural control loop), has clear synchronization points, and spans cache- to DRAM-bound regimes where sensitivity differs; microbenchmarks lack this structure and amplification.",
        "Related Work": "Best practices and studies on HPC variability emphasize static controls: thread pinning, NUMA first-touch/numactl, DVFS/turbo settings, OS isolation, and sometimes huge pages. Some work measures OS noise and synchronization sensitivity, but typically does not propose an application-level closed-loop controller that reacts during execution to prevent tails. Our earlier proposals covered offline Pareto autotuning, noise injection for causal attribution, deterministic first-touch/warmup gating, TLB shaping, barrier-tail modeling, and cadence resonance scanning. This proposal is distinct in (1) treating stability as a feedback control problem with an explicit health signal and hysteresis, (2) targeting transient mapping/runtime-induced tail events that occur despite nominal pinning, and (3) using only user-level mechanisms (pthread_setaffinity_np, OpenMP runtime knobs when available, and an application-level \u2018active thread\u2019 gate) without kernel changes. Semantic Scholar search returned no papers for our queries, so we position novelty conservatively as a new combination of feedback control + tail prevention in OpenMP stencils rather than claiming no prior art exists.",
        "Abstract": "OpenMP stencil codes can show large run-to-run variability and long-tail slowdowns (p95/p99) on modern HPC nodes, even when nominal thread pinning is enabled. We hypothesize that a key remaining cause is transient mapping degradation\u2014brief CPU migrations, SMT sibling contention, or runtime sleep/wake drift\u2014that becomes amplified by synchronization into tail iterations. We propose Affinity with Hysteresis (AWH): a tiny, user-level feedback controller embedded into iterative stencil codes that detects mapping degradation and applies minimal corrective actions before tails materialize.\n\nAWH samples three cheap signals during execution: (i) CPU-id stability per thread (sched_getcpu), (ii) per-thread progress skew (iterations or work units completed), and (iii) sampled barrier wait imbalance. These form a mapping-health score. When health remains below a threshold for a short window (hysteresis), AWH triggers one of three low-cost actuators: re-assert affinity via pthread_setaffinity_np, temporarily cap active threads (parking SMT siblings first) to avoid oversubscription/SMT contention, and switch waiting behavior around barriers (spin-then-yield vs block) using portable application-level waiting and optional runtime knobs.\n\nWe evaluate AWH on the Himeno benchmark across three footprints (~50MB, ~400MB, ~3.2GB), reporting median MFLOPS, CV, and p95/p99 over median under natural variability and controlled interference. We expect substantial tail reduction with negligible median loss, providing a practical complement to static pinning/NUMA policies for reproducible stencil benchmarking.",
        "Experiments": [
            "Feasibility + overhead check: Add CPU-id sampling every K iterations (e.g., K=50\u2013200), per-thread progress counters, and sampled barrier timing every M iterations. Compare uninstrumented vs instrumented (controller disabled) to ensure median change <1% and p99 does not worsen.",
            "Tail\u2013health linkage (does the signal predict tails?): Under a strong baseline (OMP_PROC_BIND=close, OMP_PLACES=cores, OMP_SCHEDULE=static, numactl --localalloc), run 100 repetitions per size. For each run, compute (a) p95/p99 iteration times and (b) summary health statistics (CPU-id churn rate, max/min progress skew, barrier wait imbalance). Test whether tail runs are preceded by health drops (e.g., precision/recall for predicting top-5% slowest iterations).",
            "Controller evaluation (main result): Compare (A) baseline pinned, (B) AWH re-pin only, (C) AWH active-thread cap only, (D) AWH wait-strategy only, (E) full AWH. Metrics: median MFLOPS, CV, p95/median, p99/median; plus intervention rate and average intervention duration.",
            "Precise actuator implementations:\n- Re-pin: each thread stores its intended CPU set at startup; on trigger, call pthread_setaffinity_np for all threads.\n- Active-thread cap: implement a per-thread \u2018active\u2019 flag; inactive threads skip compute and wait at a lightweight local gate; policy prioritizes deactivating SMT siblings first (based on /sys topology).\n- Wait-strategy: implement an application-level barrier wrapper that uses (i) short spinning then sched_yield, or (ii) futex-based blocking (Linux) as an optional fast path; select strategy based on health state.\nReport which actuator yields the best p99 reduction per size.",
            "Controlled interference stress test: Add a pinned interferer producing periodic wakeups and/or short memory bursts. Sweep duty cycle and placement (same core\u2019s SMT sibling vs separate core). Evaluate whether AWH reduces the slope of p99/median vs interference intensity compared to baseline.",
            "Cross-regime analysis: Repeat for all three Himeno sizes and at least two thread counts (1-socket and 2-socket). Collect a small set of counters (context switches, migrations if accessible, LLC misses, bandwidth) to ensure improvements align with reduced mapping degradation rather than accidental algorithmic changes.",
            "Generality: Apply the same controller to a second iterative stencil kernel (7-point Jacobi or miniHPCG smoother). Success criterion: consistent p95/p99 reduction with \u22642\u20133% median loss."
        ],
        "Risk Factors and Limitations": [
            "If the system enforces strict affinity with near-zero migrations and minimal runtime drift, AWH may provide limited benefit. Mitigation: focus on controlled interference and SMT contention cases; report when tails are dominated by global effects.",
            "Active-thread capping can reduce throughput in DRAM-bound regimes. Mitigation: cap only briefly with hysteresis; prefer disabling SMT siblings; enforce a median-loss budget and report Pareto trade-offs.",
            "Portable control of OpenMP runtime waiting is inconsistent across runtimes. Mitigation: rely primarily on application-level waiting/barrier wrapper; treat runtime-specific knobs as optional enhancements.",
            "Instrumentation might perturb tails. Mitigation: low-rate sampling, buffered logging, and an explicit \u2018instrumented-but-disabled\u2019 control to quantify bias.",
            "Root causes could be uncore-wide throttling/refresh events not addressable by affinity control. Mitigation: use health signals to separate mapping-related tails from global slowdowns and clearly scope claims to the mapping-failure subset."
        ]
    },
    {
        "Name": "memory_traffic_shaping_dither",
        "Title": "Traffic Shaping for Stencils: Can Micro-Dithering Memory Requests Eliminate p99 Tails Without Isolation?",
        "Short Hypothesis": "Himeno\u2019s long-tail slowdowns (p95/p99) on shared HPC nodes are often driven by brief, adversarial alignment between the stencil\u2019s highly regular memory-request bursts and time-varying contention in the uncore/DRAM system (refresh, background kernel activity, other sockets\u2019 bursts). Unlike prior approaches that try to remove noise (pinning, NUMA policies, OS isolation) or change synchronization structure, we hypothesize that adding a tiny, carefully designed *memory-traffic dither*\u2014a per-thread, low-overhead perturbation that slightly de-phases memory bursts while keeping total work and locality essentially unchanged\u2014can reduce worst-case queueing events and therefore shrink p99/median with negligible median impact. This is best investigated on Himeno because its access pattern is extremely regular and bursty (19-point stencil) and spans cache-ish to bandwidth-bound regimes where queueing effects should manifest differently; simpler microbenchmarks don\u2019t have the same multi-stream stencil structure and synchronization cadence that creates coherent bursts.",
        "Related Work": "Most existing Himeno/HPC stability guidance focuses on preventing variability by controlling placement and execution (OMP affinity, numactl first-touch, DVFS/turbo control, OS isolation) or by addressing deterministic phase effects (warmup/first-touch) and barrier amplification. There is also substantial work on cache blocking/SIMD for average throughput. Our proposal differs by treating the *memory system* as a queueing system where pathological alignment of bursty request trains produces tails, and by testing a novel mitigation: user-level traffic shaping via micro-dithering of memory issue timing/phasing. This is not the same as cadence resonance scanning (which varies iteration timing/synchronization periods) nor as adding random delays broadly; the key novelty is (i) dithering targeted at *memory issue phase* (not compute cadence), (ii) maintaining identical algorithmic work and near-identical cache behavior, and (iii) evaluating success primarily on tail metrics (p99/median) rather than mean/median speed.",
        "Abstract": "Regular stencil codes generate highly structured memory-request bursts. On modern multi-socket nodes, these bursts can occasionally align with transient uncore/DRAM contention, producing rare but severe queueing slowdowns that dominate p95/p99 performance\u2014especially for bandwidth-bound regimes. We propose Memory-Traffic Dithering (MTD), a lightweight, user-level technique that reduces tail slowdowns by slightly de-phasing memory bursts across threads while preserving total work and locality.\n\nWe implement MTD in the Himeno benchmark (19-point Jacobi stencil) by introducing tiny, bounded perturbations to memory issue timing: (1) per-thread phase offsets that shift the start of each k-slab (or i-block) by a few hundred cycles, (2) deterministic pseudo-random micro-pauses inserted only at block boundaries (not per-iteration) to avoid changing instruction mix significantly, and (3) optional \u201cstaggered prefetch\u201d where software prefetch distance is modulated per thread to decorrelate demand misses. Across three canonical sizes (~50MB, ~400MB, ~3.2GB), we run replicated trials and report distributional metrics (median MFLOPS, CV, p95/p99 over median) alongside counters for memory bandwidth, LLC misses, and stall cycles.\n\nWe validate that MTD reduces tails most in the DRAM-bound regime and under mild background contention, and we provide a simple guideline for choosing dither magnitude that achieves p99 reduction with <1\u20132% median loss. The outcome is a new, portable knob for reproducible stencil benchmarking that complements (rather than replaces) pinning and NUMA best practices.",
        "Experiments": [
            "Baseline characterization (distribution-first): For each Himeno size and two thread configurations (1-socket full cores, 2-socket full cores), run 60\u2013100 repetitions under a fixed \u2018good practice\u2019 baseline (OMP_PROC_BIND=close, OMP_PLACES=cores, OMP_SCHEDULE=static, numactl --localalloc if available). Report median MFLOPS, CV, p95/median, p99/median. Collect perf stat counters: cycles, instructions, LLC-load-misses, stalled-cycles-frontend/back-end, and (if available) uncore bandwidth (e.g., IMC reads/writes).",
            "Implement three MTD mechanisms (precise changes): (A) Phase-offset start: each thread waits for a calibrated number of TSC cycles before entering the main loop, with offsets proportional to thread_id (e.g., 0..P cycles). (B) Block-boundary micro-dither: after completing each tile/block (not each iteration), execute a bounded busy-wait of d cycles where d is from a deterministic PRNG seeded by thread_id and block index (mean 0, max D). (C) Staggered prefetch: if software prefetch is used, set per-thread prefetch distance = base + delta(thread_id mod m). Keep all numerical work identical.",
            "Dither magnitude sweep (dose\u2013response): Sweep P and D over a small grid (e.g., P\u2208{0,100,300,1000} cycles; D\u2208{0,50,200,800} cycles; delta\u2208{0,1,2 cache lines}). For each point run 40\u201360 repetitions. Primary metric: reduction in p99/median at \u22642% median MFLOPS loss. Secondary: CV reduction.",
            "Causality via controlled contention: Add a background memory streamer (simple memcpy/stream triad) pinned to (i) other socket cores, (ii) same socket non-benchmark cores. Sweep its duty cycle (e.g., 0%, 10%, 30%). Test whether MTD reduces the slope of p99/median vs contention intensity compared to baseline.",
            "Queueing signature validation: Check whether tail runs correlate with spikes in stalled cycles and/or bandwidth saturation. Evaluate whether MTD reduces variance of bandwidth over time (sampled via short periodic reads of uncore counters if available, otherwise infer via per-iteration timing variability).",
            "Ablation vs \u2018just add delays\u2019: Compare MTD against (i) uniform fixed delay of equal average overhead, and (ii) random delay inserted every iteration. Hypothesis: targeted block-boundary dithering achieves better p99 reduction per unit median loss than naive delays.",
            "Generality check: Apply best MTD setting to a second stencil (7-point Jacobi or miniHPCG smoother). Success criterion: consistent p95/p99 reduction under mild contention with <2\u20133% median loss."
        ],
        "Risk Factors and Limitations": [
            "MTD may be viewed as \u2018cheating\u2019 a benchmark by altering timing. Mitigation: position as a stability technique for real stencil applications; report both end-to-end time and steady-state MFLOPS, and ensure numerical results are identical.",
            "Busy-wait dithering can interact with DVFS/turbo and change frequency residency. Mitigation: keep dithers extremely small and only at block boundaries; measure effective frequency via APERF/MPERF when accessible and include a nanosleep-based variant to separate DVFS effects.",
            "If tails are dominated by NUMA remote placement or OS interrupts rather than memory queueing, MTD may have little effect. Mitigation: run under pinned+localalloc baseline to reduce placement noise and include controlled contention experiments to isolate queueing-driven tails.",
            "Uncore bandwidth counters may be unavailable. Mitigation: rely on portable core counters (stalled cycles) and iteration-time traces; treat uncore counters as optional.",
            "Choosing dither magnitude may be hardware-dependent. Mitigation: propose a simple auto-calibration (short sweep over 3\u20134 magnitudes) and report a robust default scaled by measured iteration time."
        ]
    },
    {
        "Name": "performance_distribution_contracts",
        "Title": "Performance Distribution Contracts: Making Stencil Benchmarks Reproducible by Enforcing Invariants (Not Just Pinning Threads)",
        "Short Hypothesis": "Himeno instability persists even after standard best practices (pinning + NUMA-local allocation) because the *causes* of slow tails are heterogeneous, but the *symptoms* are low-dimensional and observable: remote-page fraction, effective frequency residency, and synchronization wait amplification. If we define a small set of runtime-checkable invariants\u2014\"performance distribution contracts\"\u2014and enforce them with lightweight, user-level corrective actions (re-touch, re-pin, re-warm, and optional hugepage advice), then we can guarantee that the measured region comes from a consistent operating regime. This should collapse multi-modal performance distributions and reduce CV and p99/median without requiring privileged controls or heavy autotuning. This direction is necessary because median-only tuning and static settings do not provide a falsifiable guarantee that a run is \u2018comparable\u2019 to another run; contracts create a measurable, enforceable notion of comparability.",
        "Related Work": "Prior work and best practices address individual knobs (OMP affinity, numactl first-touch, DVFS/turbo settings, OS isolation) and typically report single-number throughput or, at best, variability under a few configurations. Our earlier proposals explored multi-objective autotuning, causal noise injection, deterministic first-touch + steady-state gating, TLB shaping, barrier-tail modeling, cadence resonance, and traffic dithering. This proposal is distinct in (1) introducing an explicit *contract* abstraction\u2014runtime-verifiable invariants that define when a run is valid\u2014and (2) treating reproducibility as a systems problem of *detect \u2192 certify \u2192 correct* rather than optimize. It is not an autotuner (no large search), not an injector (no counterfactual replay), and not only a methodology change (it outputs a pass/fail certificate plus minimal repairs). Semantic Scholar search returned no papers for our query, so we position novelty conservatively as a new benchmark engineering abstraction rather than claiming no prior art exists.",
        "Abstract": "HPC stencil benchmarks such as Himeno often exhibit unstable performance on modern multi-socket CPUs, with large run-to-run dispersion and long-tail slowdowns. Conventional mitigations (thread pinning, NUMA-local allocation, fixed scheduling) improve average behavior but do not provide a guarantee that two runs executed under comparable conditions. We propose Performance Distribution Contracts (PDC): a lightweight runtime framework that defines a small set of invariants which must hold for a timed region to be considered valid, and a set of user-level repair actions when invariants are violated.\n\nPDC instruments Himeno with low-overhead probes before and during the timed iterations: (i) a page-sampled locality probe to estimate remote-page fraction, (ii) an effective-frequency probe using unprivileged timing ratios (and APERF/MPERF when available), and (iii) a synchronization amplification probe measuring barrier wait imbalance from sampled per-thread iteration times. These signals define contracts such as \u201cremote-page fraction < r\u201d, \u201cfrequency residency within \u00b1x%,\u201d and \u201cbarrier-wait skew < s.\u201d If a contract fails, PDC applies minimal repairs: deterministic parallel re-touch aligned to the compute decomposition (to re-place pages), re-asserting affinity, and adaptive warmup extension until steady-state is detected.\n\nAcross three Himeno sizes (~50MB, ~400MB, ~3.2GB), PDC outputs both MFLOPS distributions and a certificate indicating which contracts held. We expect substantial reductions in CV and p95/p99 tails, and improved cross-day reproducibility, with minimal overhead and no privileged system configuration.",
        "Experiments": [
            "Define baseline variability and contract signals: For each Himeno size and two thread layouts (1-socket and 2-socket), run 80 repetitions under a strong baseline (OMP_PROC_BIND=close, OMP_PLACES=cores, OMP_SCHEDULE=static, numactl --localalloc when available). Record median MFLOPS, CV, p95/median, p99/median. Collect contract signals: (a) remote-page proxy via page-sampled pointer-chasing latency histogram per thread, (b) effective frequency proxy via cycles per fixed work micro-probe (and APERF/MPERF if readable), (c) barrier wait skew from sampled per-thread iteration times.",
            "Contract design study (which invariants are sufficient?): Evaluate multiple small contract sets: C1={locality only}, C2={locality+frequency}, C3={locality+sync}, C4={all three}. For each set, compute (i) false rejects (runs that fail contract but are fast), (ii) false accepts (runs that pass but fall in worst 5% MFLOPS), and (iii) tail reduction when repairs are enabled. Metrics: AUC for predicting worst-5% runs from contract signals; achieved p95/p99 reduction at fixed median loss budget (<2%).",
            "Repair actions and precise implementation: Implement three repairs: R1 deterministic re-touch (parallel first-touch matching compute partition); R2 re-assert affinity (pthread_setaffinity_np to intended CPU set); R3 adaptive warmup gating (start timing only after rolling-window CV of iteration time <1% for W=20, with max warmup cap). Evaluate each repair alone and in combination under each contract set. Report overhead (extra warmup time, re-touch time) and distribution metrics.",
            "Stress tests under mild noise: Add a controlled background interferer (periodic wakeups or memory streamer) pinned to non-benchmark cores on same socket vs other socket. Compare baseline vs PDC: tail sensitivity slope (change in p99/median per interferer duty cycle), plus contract violation rates.",
            "Cross-day reproducibility: Repeat the same experiment suite on 5 different days/times. Compare (i) raw distributions, (ii) distributions conditioned on contract pass, and (iii) PDC-repaired distributions. Metrics: Wasserstein distance between daily performance distributions; variance of median across days; tail stability (std of p99/median across days).",
            "Generality check: Apply PDC to a second stencil miniapp (7-point Jacobi or miniHPCG smoother). Success criterion: contract signals remain predictive of worst-5% runs and PDC reduces p95/p99 with <2\u20133% median loss."
        ],
        "Risk Factors and Limitations": [
            "Contract probes may perturb cache/TLB state and bias performance. Mitigation: keep probes short and page-sampled; include a probe-only control (instrumented but repairs disabled) to quantify bias.",
            "Remote-page estimation without NUMA counters may be noisy. Mitigation: validate probe using controlled first-touch experiments that force known remote fractions; use latency mixture features rather than a single scalar.",
            "Some platforms may have unimodal but wide distributions dominated by global effects (uncore throttling/DRAM refresh) not addressable by repairs. Mitigation: report when contracts do not predict tails and analyze which signals fail; position PDC as a diagnostic/certification tool even when repairs help little.",
            "Users may object that rejecting/repairing runs changes benchmark methodology. Mitigation: PDC reports both raw and certified performance, and explicitly logs which contracts failed and what repairs were applied; frame as reproducibility mode rather than replacing standard scores.",
            "Affinity re-assertion and APERF/MPERF availability vary across systems. Mitigation: make frequency contract optional; rely on portable timing-based proxies when counters are unavailable."
        ]
    },
    {
        "Name": "topology_progress_equalization_v2",
        "Title": "Topology-Aware Progress Equalization: Reducing p99 Tails in OpenMP Stencils by Shrinking the Slowest-Thread Gap",
        "Short Hypothesis": "Even with pinning and NUMA-local allocation, Himeno\u2019s p95/p99 slowdowns can be dominated by *persistent per-thread speed differences* (heterogeneity) caused by uncore/topology effects and imperfect memory service fairness. Because each iteration synchronizes, the slowest thread disproportionately determines tail iterations. If we (1) measure per-thread \u201cprogress\u201d cheaply and (2) apply a minimal compensation\u2014either slightly reweighting domain partition sizes or selectively throttling only the fastest threads\u2014then we can reduce the max-thread gap and thus reduce p99/median with little or no median MFLOPS loss. This is best tested on Himeno because it is iterative, barrier-synchronized, and spans cache- to DRAM-bound regimes where heterogeneity and synchronization interact; microbenchmarks lack the barrier-amplification pathway that turns small heterogeneity into tails.",
        "Related Work": "Common HPC guidance and studies focus on reducing external variability sources (pinning, first-touch/NUMA control, DVFS/turbo control, OS noise isolation) or improving average throughput (tiling/SIMD). Some work models synchronization sensitivity, but typically does not propose *equalization* as a tail-mitigation mechanism. This proposal differs from prior ideas above by treating within-run heterogeneity as the primary lever and by introducing a simple, user-level control loop that explicitly targets tail metrics via shrinking the slowest-thread gap. It is not an autotuner over many knobs: it uses a tiny calibration step and one of two small interventions with a small parameter sweep.",
        "Abstract": "Pinned, NUMA-local OpenMP stencils can still exhibit large p95/p99 slowdowns, suggesting that instability is not only from external noise. We hypothesize that persistent intra-node heterogeneity\u2014some threads consistently receiving worse effective memory service due to uncore/topology effects\u2014creates a slowest-thread gap that barriers amplify into tail iterations. We propose Topology-Aware Progress Equalization (TAPE), a lightweight method to reduce tails by making per-thread progress more uniform.\n\nTAPE adds a short calibration window (\u2264500ms) that measures per-thread progress using portable timing probes on the program\u2019s own arrays (cycles per stencil update and short streaming throughput). Based on these measurements, TAPE applies one of two minimal interventions: (i) topology-aware work reweighting via slightly non-uniform contiguous slab partitioning (slower threads get fewer slabs), or (ii) selective throttling of only the fastest threads using bounded block-boundary micro-pauses (or optional per-thread prefetch-distance modulation). We evaluate on the Himeno benchmark across three canonical sizes (~50MB, ~400MB, ~3.2GB), reporting median MFLOPS, CV, and p95/p99 over median, and directly measuring reduction in the slowest-thread gap.\n\nThe expected outcome is a new stability knob complementary to pinning and NUMA policies: rather than eliminating noise, equalize its amplification pathway by shrinking max-thread disparities at synchronization points.",
        "Experiments": [
            "Is the slowest-thread gap predictive of tails? Instrument per-thread compute time and barrier wait time (sample every K iterations) under a strong baseline (OMP_PROC_BIND=close, OMP_PLACES=cores, OMP_SCHEDULE=static, numactl --localalloc). For each run compute H = max(thread_iter_time)/median(thread_iter_time) and correlate H with p95/p99 iteration times and p99/median MFLOPS across 60\u2013100 repetitions per size.",
            "Calibration probe design (portable, low overhead): Implement a 200\u2013500ms probe that (a) runs a short fixed-work stencil micro-iteration on each thread\u2019s planned subdomain and (b) runs a short streaming pass over that subdomain. Features: per-thread cycles/update and bytes/s. Validate probe stability (repeat probe 10x) and that it identifies persistently slow threads (rank correlation with subsequent timed-region per-thread times).",
            "Intervention A \u2014 weighted contiguous partitioning: Replace uniform k-slab partitioning with weighted partitioning. Compute weights w_i = (cycles/update)_i (or inverse bandwidth) from calibration; assign slab counts proportional to 1/w_i with smoothing \u03b1\u2208{0,0.25,0.5,0.75,1} to avoid overreacting; keep slabs contiguous to preserve locality. Evaluate median, CV, p95/p99, p99/median, and H.",
            "Intervention B \u2014 selective fast-thread throttling: Keep uniform partitioning but add bounded micro-pauses only for the fastest quartile of threads at block boundaries (not per-iteration) with cap D\u2208{0,100,300,1000} cycles. Compare against a control that applies the same average pause to all threads. Evaluate tail metrics and H to show the benefit comes from equalization rather than uniform slowdown.",
            "Main tail objective sweep: For each size and two thread layouts (1-socket full cores; 2-socket full cores), run a small grid over (\u03b1,D) with \u226540 repetitions/point. Primary success criterion: reduce p99/median by \u226510% at \u22642% median MFLOPS loss (or report the Pareto curve).",
            "Mild contention robustness: Add a background memory streamer pinned to non-benchmark cores (same socket vs other socket) at duty cycles {0%,10%,30%}. Measure whether equalization reduces the slope of p99/median vs duty cycle, especially for the 3.2GB regime.",
            "Generality: Apply the best equalization variant to a second stencil (7-point Jacobi or miniHPCG smoother) and repeat the key metrics (median, CV, p95/p99, H)."
        ],
        "Risk Factors and Limitations": [
            "If tails are dominated by global slowdowns (uncore-wide throttling, DRAM refresh, system-wide interrupts) rather than max-thread gaps, equalization may not help. Mitigation: the first experiment explicitly tests whether H predicts tails; if not, scope claims accordingly.",
            "Weighted partitioning might reduce locality or complicate vectorization if partitions become too irregular. Mitigation: constrain to contiguous slabs and small reweighting via smoothing \u03b1; verify LLC misses/bandwidth proxies do not worsen materially.",
            "Selective throttling could be viewed as \u2018artificially\u2019 slowing fast threads. Mitigation: position as a tail-reduction technique for synchronized stencils where throughput is set by the slowest thread anyway; report Pareto trade-offs and include the uniform-throttle control.",
            "Calibration overhead could matter for short runs. Mitigation: cap probe time and amortize by running multiple timed trials per calibration; report overhead explicitly.",
            "Tool literature search returned no papers; novelty positioning may need adjustment after manual review. Mitigation: keep claims focused on the specific combination: (i) per-thread memory-progress calibration, (ii) equalization interventions, and (iii) tail-metric evaluation in OpenMP stencils."
        ]
    },
    {
        "Name": "thermal_uncore_state_spectroscopy",
        "Title": "Uncore State Spectroscopy: Explaining Himeno\u2019s Long Tails via Thermal/Power History and Memory-Controller Throttling",
        "Short Hypothesis": "A non-trivial fraction of Himeno\u2019s CV and p99/median tail slowdowns\u2014especially for the 400MB and 3.2GB regimes\u2014comes from hidden *uncore state* (memory-controller frequency, power limits, and thermal headroom) that depends on short-term execution history (\u201cwhat ran just before\u201d) rather than only on instantaneous pinning/NUMA placement. This is hard to answer with simpler microbenchmarks because the effect is hypothesized to be history-dependent and amplified by stencil synchronization; Himeno\u2019s iterative structure lets us (i) control preconditioning workloads, (ii) measure a steady-state trajectory, and (iii) observe whether tails correspond to particular uncore/thermal states. If true, we can reduce tails with user-level \u2018state reset\u2019 preconditioning (short, targeted warmups/cooldowns) and/or by selecting code variants that avoid triggering uncore downclock, without requiring privileged DVFS controls.",
        "Related Work": "Prior work on Himeno/HPC variability largely emphasizes thread affinity, NUMA first-touch, OS jitter, and sometimes huge pages/TLB. DVFS/turbo effects are discussed, but typically at the *core* frequency level and as static settings (disable turbo, set governor). Much less is systematically studied about *uncore* frequency/power states and, crucially, their dependence on recent history (thermal/power hysteresis) as a driver of p99 tails in stencil codes. Existing OS-noise and tail-latency studies also rarely treat uncore state as the primary latent variable for synchronized OpenMP kernels. This proposal distinguishes itself by (1) explicitly treating uncore/thermal history as the latent state, (2) introducing controlled \u2018preconditioning\u2019 experiments to causally test history dependence, and (3) targeting tail metrics (p95/p99) rather than only average throughput. The Semantic Scholar search with broad keywords returned no papers, so we position novelty conservatively and will strengthen citations via manual follow-up (e.g., uncore frequency scaling, RAPL/power-limit hysteresis, memory-controller throttling studies).",
        "Abstract": "Himeno benchmark results on modern HPC CPUs can show substantial run-to-run variability and long-tail slowdowns even when best practices (thread pinning, NUMA-local allocation) are applied. We hypothesize that a key missing variable is the CPU\u2019s uncore thermal/power state: memory-controller/uncore frequency and power-limit behavior can change based on short-term execution history, creating slow \u2018modes\u2019 that persist for seconds and dominate p95/p99.\n\nWe propose Uncore State Spectroscopy (USS), a methodology to (i) measure whether Himeno performance depends on pre-run history and (ii) mitigate tails with user-level preconditioning. USS constructs a stabilized baseline (fixed affinity, local allocation, static scheduling) and then precedes each timed run with a controlled preconditioning workload chosen to bias uncore state: AVX-heavy compute, memory streaming, mixed compute+memory, or an idle cooldown. We measure Himeno\u2019s iteration-time trajectory and distributional metrics (median MFLOPS, CV, p95/p99 over median) alongside accessible telemetry (e.g., RAPL energy, temperature sensors, and uncore frequency counters when available). We fit a simple state model linking preconditioning and telemetry to tail risk.\n\nFinally, we evaluate low-cost mitigations: a short \u2018state reset\u2019 warmup/cooldown protocol and a code variant that reduces uncore stress (e.g., less aggressive prefetching/AVX usage) selected only when tail risk is high. The outcome is a practical explanation and mitigation for history-dependent tails in stencil benchmarks, improving reproducibility without privileged frequency control.",
        "Experiments": [
            "Stabilized baseline + tail characterization: For each Himeno size (50MB/400MB/3.2GB) and two thread layouts (1-socket full cores, 2-socket full cores), run 60\u2013100 repetitions under OMP_PROC_BIND=close, OMP_PLACES=cores, OMP_SCHEDULE=static, and numactl --localalloc. Record median MFLOPS, CV, p95/median, p99/median. Record per-iteration times (sampled) to detect slow modes/trajectories.",
            "Preconditioning causality sweep (core experiment): Precede each timed Himeno run with a 5\u201320s preconditioning phase: (A) AVX-heavy FMA microkernel (induces power/thermal stress), (B) memory streamer (STREAM-like), (C) mixed compute+memory, (D) idle cooldown (sleep). Randomize order across repetitions. Hypothesis: distributions shift systematically; some preconditions increase p99/median disproportionately. Metrics: change in p99/median and CV relative to baseline; effect size per size/regime.",
            "Telemetry association: Collect user-accessible telemetry during preconditioning and Himeno (best-effort): RAPL package energy, core temperatures, and any available uncore frequency/IMC counters (platform-dependent). Fit a lightweight model predicting tail risk (top-5% slow runs) from telemetry + precondition label. Metrics: AUC for tail-risk prediction; correlation between predicted uncore state and observed iteration-time inflation.",
            "History-dependence vs instantaneous load control: Compare (i) same preconditioning but different delay gaps (0s/5s/20s) before timing, and (ii) same telemetry level but different history (e.g., two-step sequences AVX\u2192idle vs streamer\u2192idle). This tests hysteresis: whether tails depend on the path taken, not just instantaneous temperature/energy.",
            "Mitigation 1 \u2014 state reset protocol: Design a minimal pre-run protocol (e.g., 3s memory streamer + 2s idle) that empirically yields the most stable uncore state. Evaluate against no reset under randomized background conditions. Success metric: reduce p99/median by \u226510% with \u22642% median MFLOPS loss, across at least one large size.",
            "Mitigation 2 \u2014 tail-aware code variant selection: Implement two Himeno variants: V1 baseline optimized (SIMD/prefetch aggressive) and V2 \u2018uncore-friendly\u2019 (reduced prefetch distance and/or less AVX intensity, e.g., avoid AVX-512 where possible via compile flags). Use the telemetry-based predictor to choose V2 only when tail risk is high. Evaluate: median MFLOPS, CV, p95/p99, and regret vs always-V1 and always-V2.",
            "Generality check: Repeat preconditioning + reset protocol on a second stencil miniapp (7-point Jacobi or miniHPCG smoother) to test whether history-dependent uncore tails generalize beyond Himeno."
        ],
        "Risk Factors and Limitations": [
            "Uncore frequency counters/telemetry may be unavailable or restricted. Mitigation: rely on portable proxies (iteration-time trajectories, temperature via lm-sensors if accessible, RAPL if readable) and treat uncore counters as optional.",
            "Some systems may show little history dependence if cooling/power management is stable or fixed by admins. Mitigation: the preconditioning experiment still yields a publishable negative/conditional result by characterizing when history dependence is absent/present.",
            "Preconditioning could be viewed as altering benchmark methodology. Mitigation: position USS as a diagnostic and reproducibility tool; report both raw baseline results and USS-conditioned results, and keep protocols short and clearly separated from timed region.",
            "\u2018Uncore-friendly\u2019 code variant might reduce median performance more than expected. Mitigation: constrain changes (prefetch distance, minor vectorization choices) and enforce a median-loss budget; report Pareto trade-offs.",
            "Thermal/power effects can interact with OS noise and contention, complicating attribution. Mitigation: run under a stabilized baseline first, then add controlled background load as an additional factor rather than mixing everything at once."
        ]
    },
    {
        "Name": "memory_access_invariant_stencils",
        "Title": "Memory-Access Invariants: Making Himeno Stable by Forcing Identical Physical Page and Cache-Set Footprints Across Runs",
        "Short Hypothesis": "A major reason Himeno\u2019s performance distribution is wide is that two runs with identical code and pinning can still execute with different *physical* memory footprints: different physical-page selections, different cache-set/TLB-set conflicts across the multiple arrays, and different page interleavings due to allocator nondeterminism and fragmentation. These differences change effective bandwidth/latency enough to create slow tails, especially for the 400MB and 3.2GB regimes. If we can (1) explicitly construct an allocation/initialization protocol that makes the physical-page and cache-set footprint repeatable, and (2) verify it with lightweight invariants (page-frame sampling + set-conflict proxies), then we can collapse CV and p99/median without privileged controls and without changing the core stencil algorithm. This is best investigated on Himeno because its few large arrays dominate runtime and are easy to reallocate/re-touch, and because regime changes across the three canonical sizes should expose when physical-footprint nondeterminism matters most; simpler microbenchmarks don\u2019t connect footprint changes to a real stencil\u2019s tail behavior.",
        "Related Work": "Prior work and best practices focus on NUMA first-touch, thread affinity, DVFS/turbo, OS noise, and (sometimes) huge pages. Some systems literature studies page coloring and huge pages, but typically targets mean throughput, not run-to-run tail metrics, and rarely provides a *repeatability protocol* with verifiable invariants for a real stencil code. Our earlier proposals covered deterministic first-touch, TLB shaping, cadence resonance, barrier tail amplification, online fingerprinting, and distributional autotuning. This proposal is distinct in treating the allocator\u2019s physical-page selection itself as the object to control and certify: we aim to force two executions to have (approximately) the same physical-page multiset and similar cache-set/TLB-set pressure patterns, then test whether tails disappear. It is not \u2018just use huge pages\u2019: the core novelty is an invariant-based, repeatable physical-footprint construction and a causal test that isolates allocator-induced physical variation as a tail driver.",
        "Abstract": "HPC stencil benchmarks often show unstable performance even under pinned threads and NUMA-local allocation. We hypothesize that a key hidden variable is the *physical footprint* chosen by the OS allocator: across runs, large arrays can map to different physical page frames, producing different cache-set and TLB/page-walk conflict patterns and thereby different effective memory service. We propose Memory-Access Invariants (MAI), a reproducibility protocol for Himeno that forces repeatable physical footprints and verifies them.\n\nMAI combines (i) deterministic allocation (single large arena + fixed offsets for arrays), (ii) deterministic parallel page-touch aligned with the compute decomposition, and (iii) optional huge-page shaping (THP madvise) to reduce fragmentation sensitivity. To make the protocol falsifiable, MAI introduces lightweight invariants: sampling page-frame numbers via /proc/self/pagemap (when permitted) or via timing-based proxies when not, plus set-conflict proxies derived from controlled address-offset sweeps and dTLB/page-walk counters when available. We then perform a counterfactual test: deliberately randomize physical footprints across runs (by churn/fragmentation + randomized allocation offsets) and measure whether tails worsen; if so, MAI should reverse the effect.\n\nAcross three Himeno sizes (~50MB, ~400MB, ~3.2GB), we evaluate MAI on distributional metrics (median MFLOPS, CV, p95/p99 over median) and show when physical-footprint repeatability is a dominant lever for stability. The outcome is an inexpensive, portable method to make stencil benchmarking more reproducible and a clearer understanding of allocator-induced tail behavior.",
        "Experiments": [
            "Baseline under strong best practices: For each size and 1-socket/2-socket thread layouts, run 60 repetitions with OMP_PROC_BIND=close, OMP_PLACES=cores, OMP_SCHEDULE=static, and numactl --localalloc. Report median MFLOPS, CV, p95/median, p99/median. Collect perf counters: LLC-load-misses, dTLB-load-misses, stalled cycles; record per-iteration timing samples.",
            "Footprint randomization stressor (causal lever): Before allocating Himeno arrays, run a memory churner that allocates/frees many large blocks to increase fragmentation. Allocate Himeno arrays with randomized extra padding/offset between arrays each run (keeping total size constant) and touch pages in a slightly randomized order (control). Hypothesis: tails and CV increase, and TLB/cache-miss variance increases.",
            "MAI protocol implementation: Allocate a single aligned arena (e.g., mmap) and carve arrays at fixed offsets; touch pages deterministically in parallel using the same slab decomposition as compute (first-touch determinism). Optionally apply madvise(MADV_HUGEPAGE) to the arena. Compare MAI vs baseline vs randomized stressor on distribution metrics.",
            "Invariant measurement and certification: (A) If /proc/self/pagemap access is allowed, sample PFNs for 1/1024 pages per array and compute a footprint-stability score across runs (Jaccard similarity over sampled PFNs; per-socket distribution if NUMA info available). (B) If pagemap is restricted, use a timing-based footprint proxy: run a short page-sampled pointer-chase probe over arrays and compare latency histograms across runs; compute an \u2018invariant distance\u2019 between runs. Test whether invariant distance predicts tail runs (AUC for worst-5% MFLOPS).",
            "Ablation to separate NUMA vs physical-footprint effects: Repeat the above with numactl --interleave=all and with strict --localalloc. If MAI helps even under fixed NUMA policy, it supports the physical-footprint (cache/TLB conflict) hypothesis beyond remote-page placement.",
            "Generalization: Apply MAI to a second stencil miniapp (7-point Jacobi or miniHPCG smoother). Success criterion: MAI reduces p95/p99 and CV under the randomized stressor without >2\u20133% median loss."
        ],
        "Risk Factors and Limitations": [
            "Access to /proc/self/pagemap may be restricted on some systems. Mitigation: treat PFN sampling as optional and rely on timing-based footprint proxies plus controlled randomization as the main causal evidence.",
            "The allocator-induced physical variation may be a small effect compared to OS jitter or DVFS on some nodes, yielding limited gains. Mitigation: run under a stabilized baseline (pinning + localalloc) and use the randomization stressor to amplify the effect for measurement.",
            "Arena allocation and deterministic touching might inadvertently change cache locality or NUMA placement compared to the baseline. Mitigation: keep compute identical, verify NUMA placement with controlled first-touch, and report counter changes to show improvements are not just from unrelated tiling/SIMD effects.",
            "Huge pages may be unavailable or inconsistently configured. Mitigation: make THP/hugetlb optional; the core MAI protocol (arena + deterministic offsets + deterministic touch) should still function.",
            "Stressor realism: fragmentation/churn patterns may not match real cluster behavior. Mitigation: evaluate both natural baseline variability and stressor-induced variability; position the stressor as a causal tool, not as a claim about typical workloads."
        ]
    },
    {
        "Name": "hardware_event_replay_stencils",
        "Title": "Hardware-Event Replay for Reproducible HPC Tails: Can We Recreate Himeno\u2019s p99 Slowdowns by Replaying Only a Few Micro-Events?",
        "Short Hypothesis": "Himeno\u2019s large CV and p99/median are not \u201crandom noise\u201d but the result of a small number of rare micro-events (e.g., brief interrupt bursts, short migration episodes, transient uncore/bandwidth contention, or page-walk storms) that occur at specific times and get amplified by barrier synchronization. If we can record a compact, low-rate trace of these micro-events during an unstable run and then replay an equivalent event schedule on an otherwise stabilized baseline, we can (i) reproduce the tail distribution shape (especially p95/p99) and (ii) identify which event classes are necessary/sufficient to generate tails. This is best studied on Himeno because it is iterative (natural time axis), synchronization-amplifying, and spans cache- vs DRAM-bound regimes where different event classes should dominate; simpler microbenchmarks cannot test amplification and distributional reproduction.",
        "Related Work": "Prior work on HPC variability typically (a) recommends best practices (pinning, NUMA-local allocation, fixed frequency) or (b) performs observational sensitivity studies, and some work injects synthetic load/jitter. However, the literature rarely treats tail behavior as a distribution to be *reproduced* via a minimal \u201cevent script,\u201d analogous to deterministic replay in debugging but targeting performance tails rather than correctness. Our earlier proposals included counterfactual noise injection and cadence resonance; this proposal differs by introducing an explicit record\u2192compress\u2192replay loop where the artifact is a compact event schedule learned from real slow runs, and success is matching the full tail distribution (not just reducing it). It is not a trivial extension of load injection because the replay is time-structured and learned from natural traces, and the research question is about minimal sufficient event sets for p99 reproduction.",
        "Abstract": "Modern HPC nodes exhibit unstable benchmark performance with long-tail slowdowns that frustrate reproducible evaluation. We propose Hardware-Event Replay (HER), a methodology that treats tail performance as an emergent consequence of rare micro-events amplified by synchronization. HER records a compact trace during natural Himeno executions\u2014sampling at low rate (e.g., 100\u2013500 Hz) per-thread CPU id (migration), context-switch/interrupt counters, and a few perf-derived stall indicators (cycles, LLC misses, dTLB misses) plus iteration boundary timestamps. We then build a compressed \u201cevent script\u201d that approximates when and where perturbations occurred (e.g., a 2 ms jitter burst on one core; a 50 ms bandwidth contention episode on one socket). On a stabilized baseline (pinned threads, local allocation, static scheduling), HER replays the script using portable user-level actuators: pinned helper threads that generate short compute bursts, memory bursts, or timer-wakeup bursts on selected cores/sockets, and optional controlled re-touch to emulate page-walk storms. Across three Himeno sizes (~50MB, ~400MB, ~3.2GB), we evaluate whether replay reproduces the original tail distribution (median, CV, p95/p99/median, and distribution distance). We then ablate event classes to identify minimal sufficient sets and derive actionable guidance: which micro-events create p99 on which regime, and which mitigation (IRQ isolation, affinity enforcement, huge pages, or bandwidth shaping) is most effective. HER yields a new experimental primitive\u2014distributional performance replay\u2014that turns \u201csystem noise\u201d into a reproducible, falsifiable object of study.",
        "Experiments": [
            "Stabilized vs natural baseline: For each size and two thread layouts (1-socket full cores; 2-socket full cores), collect 100 runs under (A) stabilized settings (OMP_PROC_BIND=close, OMP_PLACES=cores, OMP_SCHEDULE=static, numactl --localalloc) and (B) default settings. Metrics: median MFLOPS, CV, p95/median, p99/median; also record per-iteration timing (sampled) to locate tail iterations.",
            "Low-rate event tracing design (portable): During each natural run, sample at 100\u2013500 Hz: sched_getcpu per thread, getrusage deltas (involuntary context switches), /proc/stat interrupt deltas (best-effort), and perf stat deltas for {cycles, instructions, LLC-load-misses, dTLB-load-misses, stalled-cycles-backend}. Align samples to iteration indices using periodic iteration timestamps (every K iterations). Verify overhead <1\u20132% by comparing traced vs untraced runs under stabilized settings.",
            "Event-script construction (compression): Convert traces into an event script with a small vocabulary: E1=migration episode (cpu-id churn), E2=jitter burst (context-switch/interrupt spike), E3=memory contention episode (backend-stall + bandwidth proxy spike), E4=page-walk storm (dTLB spike). Use a simple segmentation algorithm (thresholding + merging) to produce episodes with (start_time, duration, target_cores/sockets, intensity).",
            "Replay actuators (precise implementation): Implement three replay helpers pinned to specified cores: (A) timer-wakeup jitter thread (high-rate timers + short syscalls) to emulate E2; (B) memory streamer (STREAM-like) to emulate E3; (C) dependent-load pointer-chase over a large buffer to emulate E4. For E1, emulate migration impact by temporarily co-locating a helper on the target core\u2019s SMT sibling (or by briefly oversubscribing a core) rather than forcing actual migration.",
            "Distributional replay evaluation: For each recorded natural run, replay its event script while running Himeno under stabilized settings. Compare the replayed MFLOPS distribution to the original natural distribution using: (i) median/CV/p95/p99, (ii) Wasserstein distance between per-run MFLOPS distributions, and (iii) tail-iteration alignment score (do replay tail iterations occur near the same iteration indices?).",
            "Minimal sufficient event-set ablations: Replay with subsets of events {E2 only, E3 only, E4 only, E2+E3, E2+E4, E3+E4, all}. Identify which subsets reproduce p99/median within tolerance (e.g., \u00b15%) for each size. Outcome: a regime-specific \u201ctail recipe.\u201d",
            "Mitigation mapping from replay: For each regime-specific tail recipe, apply a corresponding mitigation on natural runs (e.g., IRQ affinity tuning for E2-dominant, hugepage/THP for E4-dominant, bandwidth isolation via core capping for E3-dominant) and test whether it reduces p99/median most strongly where the recipe predicts."
        ],
        "Risk Factors and Limitations": [
            "Semantic Scholar search returned no papers; novelty claims should be framed carefully as a new methodology rather than implying no prior work exists. Follow-up manual literature review on deterministic replay, OS-noise injection, and tail-latency reproduction is needed.",
            "Replay may not perfectly match natural tails because some causes are global/uncore-wide or depend on privileged mechanisms (true DVFS/thermal throttling). Mitigation: focus on reproducing distribution shape approximately and report which tail components are not replayable with user-level actuators.",
            "Tracing signals may be too coarse or noisy at low sampling rates. Mitigation: tune sampling rate (100\u20131000 Hz), use episode-based compression, and validate by controlled injections where ground truth is known.",
            "Some clusters restrict access to perf counters or /proc stats. Mitigation: design a minimal tracer using only portable signals (iteration time, sched_getcpu, getrusage) and treat perf-based features as optional enhancements.",
            "Replay helpers add extra load that might change frequency residency. Mitigation: keep helpers short and episode-based, measure effective frequency proxies when available, and include a control replay that matches average added work but not timing structure to show the importance of event timing."
        ]
    },
    {
        "Name": "llc_partitioning_stability",
        "Title": "Cache Partitioning for Reproducibility: Can LLC Way-Partitioning Collapse Himeno\u2019s p99 Tails Without Full Node Isolation?",
        "Short Hypothesis": "A significant portion of Himeno\u2019s CV and p99/median tail slowdowns on modern multi-core nodes is caused by *shared last-level cache (LLC) interference* from background kernel activity and co-located user processes, even when threads are pinned and NUMA-local allocation is used. This interference is bursty and non-uniform across LLC slices/ways, and is amplified by barrier-synchronized iterations (slowest-thread effect). If we apply lightweight, user-level cache partitioning\u2014primarily Intel CAT (Cache Allocation Technology) where available, and a portable fallback based on page coloring + controlled memory footprint shaping\u2014we can reduce tail slowdowns substantially with minimal impact on median MFLOPS. This setting (Himeno) is ideal because its three canonical sizes traverse cache-resident to DRAM-bound regimes, letting us test when LLC interference is a first-order tail driver; simpler microbenchmarks do not exhibit the same synchronization-amplified tail behavior.",
        "Related Work": "Prior work on Himeno/HPC variability emphasizes NUMA first-touch, thread pinning, DVFS/turbo control, OS jitter, huge pages/TLB, and synchronization effects. Cache partitioning (Intel CAT / way-partitioning) is studied in systems/security and some performance isolation contexts, but it is rarely evaluated as a *distributional stability intervention* for HPC stencil kernels with explicit tail metrics (p95/p99) and regime shifts across problem sizes. Our proposal differs from existing Himeno stability approaches and from our earlier proposals by making LLC interference the primary causal hypothesis and by testing a concrete, low-cost isolation mechanism that is weaker than full core isolation/cgroups yet potentially sufficient to eliminate p99 tails. It is not a trivial extension of \u201cpin threads\u201d or \u201cuse cgroups\u201d: the key novelty is (i) treating LLC as the isolation boundary, (ii) evaluating stability objectives (CV, p99/median) as first-class, and (iii) providing a portable fallback methodology when CAT is unavailable.",
        "Abstract": "HPC stencil benchmarks can exhibit large run-to-run variability and long-tail slowdowns even under best practices such as thread pinning and NUMA-local allocation. We propose that a key remaining mechanism is shared last-level cache (LLC) interference: bursty cache occupancy and eviction pressure from background kernel tasks or co-located processes causes occasional iteration slowdowns that are amplified by global synchronization.\n\nWe study this hypothesis on the Himeno benchmark (19-point Jacobi stencil) across three footprints (~50MB, ~400MB, ~3.2GB), spanning cache-sensitive and DRAM-bound regimes. We introduce a stability-oriented isolation technique based on LLC partitioning. On platforms supporting Intel CAT, we allocate a dedicated subset of LLC ways to Himeno\u2019s cores and confine background activity to the remaining ways. Where CAT is unavailable, we evaluate a portable approximation using page-color steering and memory-layout shaping to reduce cross-process cache-set collisions.\n\nAcross replicated runs, we evaluate median MFLOPS, coefficient of variation (CV), and tail degradation (p95/p99 over median), and we correlate tail events with cache-miss and stall counters. We further test controlled cache interferers (streaming and pointer-chasing) to establish dose\u2013response curves and determine which memory regime is most sensitive. The outcome is a practical recipe for improving reproducibility without full-node isolation, and a clearer understanding of when LLC interference dominates Himeno\u2019s tail behavior.",
        "Experiments": [
            "Baseline distributions under best practices: For each Himeno size and thread layout (1-socket and 2-socket full cores), run 60\u2013100 repetitions with OMP_PROC_BIND=close, OMP_PLACES=cores, OMP_SCHEDULE=static, and numactl --localalloc. Report median MFLOPS, CV, p95/median, p99/median. Collect perf counters: LLC-load-misses, LLC-loads, cycles, stalled-cycles-backend, dTLB-load-misses, context switches (getrusage).",
            "Controlled cache interference (causal lever): Add a pinned interferer process on non-benchmark cores that (A) streams through a buffer sized to thrash LLC, and (B) pointer-chases to create cache-miss latency pressure, with duty cycles {0%, 10%, 30%}. Measure dose\u2013response on median/CV/p99 across sizes; test whether tails grow disproportionately relative to median.",
            "LLC partitioning with CAT (when available): Use Intel RDT/CAT (e.g., pqos or resctrl) to assign Himeno cores to a COS with a restricted LLC way mask and assign interferer/background cores to a disjoint mask. Compare distributions against (i) no partitioning and (ii) full core isolation (cpuset/cgroup) as an upper bound. Metrics: p99/median reduction at \u22642% median loss.",
            "Portable fallback without CAT: Implement page-color steering + layout shaping: allocate Himeno arrays in a single arena with controlled offsets/padding; optionally randomize offsets for a stress condition. Goal is to reduce cross-process cache-set collisions statistically. Compare against baseline and against a \u2018randomized layout\u2019 condition to test sensitivity. Metrics: changes in LLC-miss variance and tail ratios.",
            "Tail attribution to cache vs DRAM: Repeat key points while varying problem size and adding/removing cache blocking (simple 3D tiling). If LLC partitioning mainly helps the ~50MB and potentially ~400MB regimes but not ~3.2GB, it supports the hypothesis that tails are cache-interference-driven rather than pure bandwidth contention.",
            "Cross-day robustness: Repeat a subset of configurations on 5 different days/times to assess whether LLC partitioning reduces distribution drift. Metrics: variance of median across days; std of p99/median across days; Wasserstein distance between daily MFLOPS distributions."
        ],
        "Risk Factors and Limitations": [
            "CAT/resctrl may be unavailable or restricted on some clusters. Mitigation: keep CAT as a \u2018when available\u2019 track and ensure the portable fallback is still publishable as an analysis of cache-interference sensitivity even if isolation is weaker.",
            "Page-color steering is approximate in user space and may yield noisy effects. Mitigation: treat it as a statistical intervention (repeat allocations) and rely on controlled interferers for causal evidence.",
            "If tails are dominated by NUMA remote pages, DVFS, or uncore bandwidth contention, LLC partitioning may have limited impact. Mitigation: run under pinned+localalloc baseline, include counters and size-regime analysis to identify when LLC is/ isn\u2019t the dominant factor.",
            "perf/uncore counters may be restricted. Mitigation: use portable core counters (LLC misses, stalled cycles) when possible and fall back to timing + controlled interference as the primary evidence.",
            "Partitioning can reduce effective cache for Himeno and hurt median throughput. Mitigation: sweep way allocations (e.g., 25/50/75% of ways) and report Pareto curves (median vs p99)."
        ]
    },
    {
        "Name": "metamorphic_variability_testing_v2",
        "Title": "Metamorphic Variability Testing for HPC: Automated Invariance Checks that Localize Himeno\u2019s p99 Instability",
        "Short Hypothesis": "Himeno instability is difficult to diagnose because we usually observe only end-to-end distributions under a few configurations, which conflates mechanisms (NUMA placement, TLB/cache footprint, synchronization amplification, DVFS/idle coupling). We hypothesize that we can localize the dominant mechanism by designing a small suite of metamorphic variants\u2014transformations that preserve numerical correctness and keep the core steady-state stencil work essentially unchanged, while perturbing only one suspected channel. If a channel-specific metamorph causes a large change in tail metrics (p95/p99/median) without commensurate change in work proxies (instructions/update, bytes/update), that is a falsifiable invariance violation indicating the responsible mechanism. This is best answered on Himeno because it is deterministic, iterative (enabling phase-aligned traces), and spans cache-ish to DRAM-bound regimes where different invariances should break; microbenchmarks lack the phase structure needed to localize where tails are created.",
        "Related Work": "HPC variability work commonly provides best practices (pinning, NUMA first-touch/numactl, DVFS control, isolation) or observational knob sweeps; stencil optimization work focuses on mean/median throughput via tiling/SIMD. Metamorphic testing is established in software testing, but (to our knowledge) is not used as a performance-distribution oracle to diagnose tail instability in HPC kernels. Unlike our prior proposals (autotuning Pareto fronts, noise injection, deterministic first-touch/gating, TLB shaping, barrier-tail modeling, cadence resonance, traffic dithering), this proposal contributes a new debugging abstraction: (1) a compact set of invariance-based tests, (2) an automated suspect ranking from invariance violations, and (3) a minimal failing example (MFE) generator that makes tails reproducible enough for follow-on root-cause analysis. Semantic Scholar searches returned no results, so we will position novelty conservatively as a new methodology rather than claiming no prior art exists.",
        "Abstract": "HPC stencil benchmarks often exhibit run-to-run variability and long-tail slowdowns (p95/p99) that persist even under thread pinning and NUMA-local allocation. Diagnosing the root cause is hard because multiple mechanisms interact and are usually studied only via end-to-end distributions. We propose Metamorphic Variability Testing (MVT), a methodology that turns tail instability into a falsifiable testing problem.\n\nMVT implements a small suite of metamorphic program variants for Himeno (19-point Jacobi stencil). Each variant preserves numerical correctness and is designed to keep steady-state stencil work essentially unchanged, while perturbing only one channel: NUMA placement determinism, TLB/cache footprint conflicts, synchronization amplification, or DVFS/idle coupling (without privileged control). For each variant, MVT checks invariances using replicated runs and phase-aligned iteration timing, reporting distributional metrics (median MFLOPS, CV, p95/p99 over median) alongside lightweight work proxies (e.g., instructions/cycle and analytically fixed bytes/update).\n\nLarge tail changes under invariance-preserving transformations constitute \u201cvariability bugs.\u201d MVT automatically ranks suspect mechanisms by violation magnitude and synthesizes a minimal failing example (MFE)\u2014a small set of parameter choices that reliably reproduces tail events in 10\u201320 runs. Across Himeno\u2019s three canonical sizes (~50MB, ~400MB, ~3.2GB), MVT yields actionable diagnoses and reproducible triggers, enabling more scientific benchmarking and faster stabilization of stencil performance on modern HPC nodes.",
        "Experiments": [
            "Baseline + instrumentation sanity: For each size (50MB/400MB/3.2GB) and two thread layouts (1-socket, 2-socket), run 50 repetitions under a strong baseline (OMP_PROC_BIND=close, OMP_PLACES=cores, OMP_SCHEDULE=static, numactl --localalloc when available). Record median, CV, p95/median, p99/median. Add low-overhead iteration-time sampling (every K iterations) and verify it changes median by <1%.",
            "Metamorph suite design (8 variants total, kept simple):\n(1) NUMA metamorphs: deterministic first-touch aligned to compute partition vs randomized-touch order; optional controlled remote fraction 0/25/50% via first-touch from opposite socket.\n(2) Footprint metamorphs: fixed arena allocation but vary only base offsets/padding between arrays across a small deterministic set; plus run-to-run randomized offsets.\n(3) Synchronization metamorphs: baseline barrier vs hierarchical barrier (by NUMA domain).\n(4) DVFS/idle metamorphs (unprivileged): add a short pre-timed anti-idle compute phase vs pre-timed forced-idle sleep/yield phase (excluded from timing).",
            "Invariance checks: For each variant, run 40\u201360 repetitions and compute (i) tail shift \u0394(p99/median) and \u0394(CV) relative to baseline, and (ii) work-proxy shift (IPC, cycles per fixed micro-work inside the run, and analytically constant bytes/update). Flag violations where tail shift is large but work proxies remain within a small band (e.g., \u00b12%).",
            "Suspect ranking: Define a simple channel score = median over variants in channel of |\u0394(p99/median)| subject to work-proxy constraint. Output per-size ranking (e.g., 400MB: footprint>sync>NUMA>DVFS). Validate stability of ranking across days (repeat on 3 days).",
            "Minimal failing example (MFE) synthesis: Search a tiny grid over parameters (remote fraction \u2208 {0,25,50}, offset \u2208 {0,256KB,1MB}, barrier \u2208 {global,hier}, prephase \u2208 {anti-idle,forced-idle}) to maximize tail reproducibility: high p99/median and low variance of p99 estimate across batches. Goal: find an MFE that produces a tail event in \u226530% of 20-run batches.",
            "Actionability check: For the top-ranked channel, apply one targeted mitigation (e.g., deterministic first-touch for NUMA; THP madvise for footprint; hierarchical barrier for sync; anti-idle prephase for DVFS/idle) and verify it reduces p99/median more than mitigations targeting lower-ranked channels, under the same measurement protocol.",
            "Generality: Repeat only the top-2 channel metamorphs + MFE synthesis on a second stencil kernel (7-point Jacobi or miniHPCG smoother). Success: similar suspect ranking and at least one transferable MFE parameter (e.g., offset sensitivity persists)."
        ],
        "Risk Factors and Limitations": [
            "Metamorphs might inadvertently change locality or memory traffic. Mitigation: keep variants minimal (no tiling changes), use analytic bytes/update, and treat work-proxy constraints as a guardrail to reject confounded variants.",
            "Some clusters restrict numactl policies or multi-socket access. Mitigation: NUMA metamorphs become conditional; the rest (footprint, sync, DVFS/idle) still apply on single-socket systems.",
            "Tail estimation is sample-hungry. Mitigation: use p95 as a primary tail metric and confirm p99 on a smaller subset; report confidence intervals via bootstrap.",
            "If variability is dominated by uncontrollable external contention, MVT may only identify \u2018environment\u2019 as the cause. Mitigation: include an optional mild controlled interferer to test whether channel rankings remain consistent under known noise.",
            "Novelty claims need careful positioning given missing automated search hits. Mitigation: frame contribution as a practical methodology and open-source harness, and update related work after manual literature review."
        ]
    },
    {
        "Name": "hardware_prefetch_tail_switch",
        "Title": "Do Hardware Prefetchers Create Himeno\u2019s p99 Tails? A User-Level Prefetch-Phase Switch for Stable Stencil Performance",
        "Short Hypothesis": "A meaningful fraction of Himeno\u2019s long-tail slowdowns (p95/p99) is caused by run-to-run (and within-run) differences in hardware prefetcher behavior\u2014especially across NUMA/cache regimes\u2014because modern CPUs dynamically adapt prefetch aggressiveness based on observed access streams and contention. In a multi-array 3D stencil, small timing differences (thread skew, barrier hiccups, page placement) can change which streams are \u201clearned\u201d as prefetchable, occasionally pushing the system into a less favorable prefetch state (over-prefetching that thrashes LLC/bandwidth, or under-prefetching that increases demand-miss latency). This is hard to answer with simpler microbenchmarks because they don\u2019t have multiple interacting streams plus synchronization that can tip the prefetcher into different states. If we can (i) detect when Himeno is in a \u2018bad prefetch mode\u2019 using only user-level signals and (ii) apply a tiny in-program intervention that re-trains or de-trains prefetchers at phase boundaries, we can reduce p99/median substantially with negligible median loss, without privileged controls.",
        "Related Work": "Stencil optimization work largely focuses on tiling/SIMD/prefetching for average throughput, and HPC variability work focuses on pinning, NUMA placement, DVFS, and OS jitter. Hardware prefetchers are widely studied in architecture, but are rarely treated as a primary driver of run-to-run tail behavior in real HPC kernels, and even more rarely with a user-level, portable control strategy that does not require MSR writes or BIOS toggles. This proposal differs from the earlier ideas listed by targeting a distinct mechanism (prefetcher state adaptation) and proposing a minimal, in-application \u2018prefetch phase switch\u2019 rather than autotuning, noise injection, determinism protocols, TLB/page shaping, or synchronization restructuring. It is not a trivial \u2018turn prefetch on/off\u2019 study: the novelty is to treat prefetcher behavior as a latent mode affecting tails, to diagnose it via counters/timing signatures, and to control it via short training/de-training sequences and access-pattern shaping at phase boundaries.",
        "Abstract": "Modern CPUs use adaptive hardware prefetchers whose behavior depends on recent access history and contention. For multi-stream stencil codes, this adaptivity can be beneficial on average yet harmful in the tail: rare shifts into over-aggressive or under-aggressive prefetch modes can create p95/p99 slowdowns that persist for many iterations and inflate run-to-run variability. We propose to test whether such prefetch-mode switching is a hidden driver of Himeno benchmark instability and to mitigate it without privileged controls.\n\nWe introduce a Prefetch Phase Switch (PPS): a tiny, optional pre-phase inserted before the timed region (and optionally periodically) that intentionally trains or de-trains prefetchers using short, controlled access patterns over the benchmark\u2019s real arrays. PPS has two variants: (1) \u201ctrain\u201d mode that performs a brief, stride-consistent sweep matching the stencil\u2019s dominant streams to stabilize prefetch recognition; and (2) \u201cde-train\u201d mode that performs a short randomized pointer-chase to reduce harmful stream detection when over-prefetching is suspected. We detect bad modes using lightweight signatures (iteration-time trajectory, LLC-miss rate, bandwidth proxy, and backend-stall cycles), then apply PPS conditionally.\n\nAcross three Himeno sizes (~50MB, ~400MB, ~3.2GB), we evaluate distributional metrics (median MFLOPS, CV, p95/p99 over median) and demonstrate when PPS collapses tails with minimal median impact. The outcome is a new, practical perspective: prefetcher adaptivity can be a tail-risk factor in HPC stencils, and small user-level phase shaping can improve reproducibility.",
        "Experiments": [
            "Baseline tail characterization + signature collection: For each Himeno size and two thread layouts (1-socket and 2-socket), run 80\u2013120 repetitions under best-practice stability settings (OMP_PROC_BIND=close, OMP_PLACES=cores, OMP_SCHEDULE=static, numactl --localalloc). Collect median, CV, p95/median, p99/median. Record per-iteration time (sampled) and perf counters: LLC-load-misses, stalled-cycles-backend, cycles, instructions; optionally bandwidth/uncore counters if available. Check whether tail runs show distinct counter signatures consistent with prefetch under/over-shoot (e.g., high backend stalls with lower bandwidth vs high bandwidth with higher LLC misses).",
            "Prefetcher sensitivity sweep (causal lever where possible): On systems where user-level toggles exist (e.g., via Linux perf_event interfaces, prctl, or vendor utilities), compare prefetchers enabled vs partially disabled as a sanity check. If not possible, emulate \u2018reduced prefetch benefit\u2019 by adding dependent-load chains (pointer-chase) inside a short probe and compare the change in tail behavior. Goal: establish that changing prefetch effectiveness changes p99 disproportionately.",
            "Implement PPS-train and PPS-de-train: (A) Train: a short (50\u2013300ms) parallel sweep over each array in the same loop order/stride as the main stencil (read-only). (B) De-train: a short pointer-chase over a page-sampled index permutation (dependent loads) to disrupt stream detectors. Both phases are excluded from timed region. Verify numerical output unchanged.",
            "Conditional PPS policy: Build a simple rule-based detector using the first N iterations\u2019 timing slope and a short perf sample: if early iterations show (i) unusually high LLC misses and bandwidth, trigger de-train; if they show (ii) unusually high backend stalls with low bandwidth, trigger train. Compare three modes: no PPS, always-train, always-de-train, conditional PPS. Metrics: median MFLOPS, CV, p95/p99 over median, and overhead (extra pre-phase time).",
            "Dose\u2013response and robustness: Sweep PPS duration {20ms, 50ms, 100ms, 300ms} and frequency (only pre-run vs every K iterations). Evaluate whether PPS reduces p99/median most in the 400MB and 3.2GB regimes and whether benefits persist under mild controlled contention (background streamer at 0/10/30% duty on other cores).",
            "Ablation to separate cache/TLB/NUMA effects: Repeat key comparisons with (i) THP disabled/enabled (madvise) and (ii) forced NUMA interleave vs localalloc. If PPS helps even when NUMA placement is fixed, it supports a prefetch-mode mechanism rather than merely correcting placement."
        ],
        "Risk Factors and Limitations": [
            "Directly toggling hardware prefetchers is often privileged; PPS relies on indirect control (training/de-training) and may have weaker or inconsistent effects across CPUs.",
            "Counter signatures for over- vs under-prefetch are architecture-dependent and may be confounded with bandwidth contention or TLB effects; mitigated by ablations (NUMA fixed, THP toggles) and controlled contention experiments.",
            "PPS phases add overhead and may be criticized as altering benchmark methodology; mitigated by reporting both steady-state MFLOPS and end-to-end time including PPS, and by focusing on reproducibility for real applications rather than leaderboard scores.",
            "If tails are dominated by OS jitter, frequency scaling, or remote NUMA pages, PPS may provide limited gains; the proposal is still publishable as a negative/conditional result that quantifies when prefetch-mode effects matter.",
            "Pointer-chase de-training may perturb cache/TLB state; mitigated by adding a short standardized warmup after PPS and quantifying any systematic bias with a probe-only control."
        ]
    },
    {
        "Name": "cross_size_variability_triage_v2",
        "Title": "Regime Spectroscopy for HPC Variability: Using Himeno\u2019s Three Footprints to Diagnose the Dominant Tail Mechanism",
        "Short Hypothesis": "Himeno\u2019s three standard sizes (\u224850MB, \u2248400MB, \u22483.2GB) induce sharp, repeatable shifts in the performance-limiting regime (LLC-sensitive \u2192 TLB/LLC+DRAM \u2192 DRAM-bandwidth dominated). The *cross-size pattern* of distributional instability (CV, p95/p99/median, and multi-modality) is therefore a compact fingerprint of the underlying instability mechanism. With only a small, fixed set of user-level paired interventions (NUMA policy, deterministic first-touch, huge-page advice, and barrier/schedule policy), we can reliably (i) rank likely causes\u2014NUMA placement, TLB/page-walk/fragmentation, frequency/thermal excursions, or jitter amplified by synchronization\u2014and (ii) recommend a minimal fix that reduces tails without sacrificing median. This is best studied with Himeno because its stencil structure is stable across sizes while the footprint crosses key architectural boundaries; single-size studies and microbenchmarks cannot disambiguate mechanisms as cleanly.",
        "Related Work": "Most HPC performance-stability guidance and studies focus on individual knobs (pinning, first-touch, DVFS, huge pages, OS noise) and typically report mean/median or a few variability summaries for one problem size. Autotuning work searches for best throughput, not diagnosis. Our contribution is a diagnostic abstraction: treat problem-size regime transitions as an experimental axis (\u201cregime spectroscopy\u201d) and learn a mapping from cross-size distributional signatures + small interventions to a mechanism ranking and minimal mitigation. This is not a trivial extension of knob sweeps: the novelty is the explicit use of size-induced regime changes to disambiguate causes and the production of an actionable triage output (cause ranking + smallest effective fix). (Semantic Scholar queries returned no results; we will position novelty conservatively and strengthen citations via manual follow-up.)",
        "Abstract": "Stencil benchmarks on modern HPC nodes often show unstable performance: large run-to-run dispersion and long-tail slowdowns persist even under thread pinning and NUMA best practices. Diagnosing the root cause is difficult because multiple mechanisms can produce similar end-to-end symptoms.\n\nWe propose Regime Spectroscopy for Variability (RSV): a lightweight diagnostic that uses Himeno\u2019s three canonical footprints (\u224850MB, \u2248400MB, \u22483.2GB) as controlled regime switches. RSV measures performance distributions (median MFLOPS, CV, p95/p99 over median) across the three sizes under a small, fixed suite of paired, user-level interventions: NUMA policy (localalloc vs interleave), initialization policy (baseline vs deterministic first-touch aligned to compute partition), page policy (THP madvise vs never), and synchronization policy (static vs guided schedule; optional application-level barrier wait policy).\n\nWe hypothesize that the cross-size pattern of tail behavior and intervention sensitivity forms a robust fingerprint that separates dominant mechanisms such as stochastic NUMA placement, TLB/page-walk instability, frequency/thermal excursions, and synchronization-amplified jitter. We operationalize this with a simple classifier that outputs a ranked mechanism diagnosis and recommends the minimal fix. We validate the diagnosis using controlled in-lab perturbations that emulate each mechanism and demonstrate that the recommended fix reduces p95/p99 tails with minimal median impact. RSV yields an inexpensive, portable tool for reproducible benchmarking and rapid root-cause localization for stencil-like workloads.",
        "Experiments": [
            "Baseline \u2018spectra\u2019 collection: For each size (64\u00d764\u00d7128, 128\u00d7128\u00d7256, 256\u00d7256\u00d7512) and two thread layouts (1-socket full cores; 2-socket full cores), run 40\u201360 repetitions under a fixed good-practice baseline (OMP_PROC_BIND=close, OMP_PLACES=cores, OMP_SCHEDULE=static; numactl --localalloc). Metrics: median MFLOPS, CV, p95/median, p99/median. Record per-iteration timing samples (every K iterations) to detect multi-modality and tail iteration structure.",
            "Minimal paired intervention suite (fractional factorial): Evaluate 8\u201312 configurations total (not a full 16) using a fractional factorial design over: (A) NUMA: localalloc vs interleave; (B) init: baseline init vs deterministic first-touch (parallel touch matching compute partition); (C) pages: THP never vs madvise(MADV_HUGEPAGE) on arrays; (D) sync/schedule: static vs guided (and optionally a spin-then-yield vs block barrier wrapper if feasible). Keep compute kernel identical. For each config and size, run 30\u201340 repetitions.",
            "Fingerprint features (kept simple): Construct features per node/config family: (i) tail slope across sizes: \u0394(p95/median) and \u0394(p99/median) from small\u2192mid\u2192large, (ii) sensitivity vectors: effect size of each intervention on p95/p99 per size (Cliff\u2019s delta), (iii) multi-modality indicator from iteration-time traces (e.g., dip test or 2-component GMM likelihood ratio).",
            "Ground-truth mechanism library via controlled perturbations (labels): Create four labeled conditions atop the good-practice baseline: (1) NUMA remote-page fraction forced to 0/50/100% via controlled first-touch from the opposite socket; (2) TLB/page-walk stress via THP off + fragmentation churn before allocation; (3) frequency excursions via pinned AVX-heavy interferer with duty cycle sweep (unprivileged); (4) jitter amplification via periodic wakeup thread pinned to one benchmark core. Measure RSV fingerprints under each label.",
            "Train and evaluate triage model: Train a small model (logistic regression or shallow GBDT) mapping fingerprints to dominant mechanism class and confidence. Evaluation: accuracy/F1 on held-out perturbation runs; calibration (reliability curve); and \u2018abstain\u2019 behavior when confidence is low.",
            "Minimal-fix recommender and validation (main result): Define a small action set tied to mechanisms: NUMA\u2192deterministic first-touch + localalloc; TLB\u2192THP madvise + deterministic arena allocation; jitter\u2192static schedule + barrier wait policy; frequency\u2192pre-run steady-state warmup or avoid AVX-heavy downclock triggers (compile flag variant). On naturally unstable runs (default settings and/or mild background load), apply the model\u2019s recommended minimal fix and measure improvement: reduction in p95/p99/median and CV with \u22642% median MFLOPS loss. Also measure cross-day stability (e.g., std of p99/median over 5 days).",
            "Generality check: Repeat the RSV spectra + diagnosis + minimal-fix validation on a second stencil miniapp (7-point Jacobi or miniHPCG smoother) to test transfer of fingerprints and recommendations."
        ],
        "Risk Factors and Limitations": [
            "Noisy environments may make fingerprints non-stationary; mitigation: include confidence/abstention, and report when diagnosis is unstable across days.",
            "Some interventions (THP policy, barrier wrappers) may be constrained by cluster policy or runtime; mitigation: keep the core suite strictly user-level and optionalize non-portable components.",
            "The three sizes may not uniquely disambiguate all mechanisms on all architectures; mitigation: allow an optional extra probe size or a tiny additional probe (pointer-chase latency) if ambiguity remains, while keeping the core \u2018regime spectroscopy\u2019 idea intact.",
            "Ground-truth perturbations may not perfectly match real-world causes; mitigation: evaluate success primarily by whether the recommended fix actually reduces tails on natural variability, not only by label accuracy.",
            "p99 estimation is sample-hungry; mitigation: prioritize p95 as the main tail metric and confirm p99 on a subset with more repetitions."
        ]
    },
    {
        "Name": "cache_state_seeded_benchmarking_v3",
        "Title": "Cache/TLB State Seeding for Reproducible Stencil Benchmarking: Controlling the Timed-Region Initial Condition in Himeno",
        "Short Hypothesis": "Even after pinning threads and enforcing NUMA-local allocation, Himeno\u2019s run-to-run variability and p95/p99 tails can remain large because the timed region begins from an uncontrolled micro-architectural initial condition (LLC residency pattern, cache-set conflicts, and TLB reach) that differs across runs due to prior activity and warmup trajectory differences. Unlike external noise channels (DVFS, interrupts), this is *internal state sensitivity*: small differences in early cache/TLB state can persist for many iterations and create heavy tails or multi-modal performance. If we add a short, deterministic, topology-consistent \u201cstate seeding\u201d prelude on the benchmark\u2019s own arrays plus a simple convergence gate (start timing only once iteration-time stabilizes), then performance distributions should collapse (lower CV and p95/p99 over median) with minimal median impact and without privileged controls. This is best investigated on Himeno because it has a long steady-state loop and large persistent arrays spanning cache-ish to DRAM-bound regimes; microbenchmarks cannot test whether controlling initial conditions stabilizes a real stencil\u2019s tail behavior.",
        "Related Work": "Standard HPC stability guidance focuses on thread affinity, NUMA first-touch, OS isolation, and DVFS/turbo settings; stencil optimization focuses on tiling/SIMD for mean/median throughput. Warmup iterations are commonly used, but typically as a fixed count and without a designed goal of making the cache/TLB *state* repeatable across runs. This proposal distinguishes itself by (i) treating micro-architectural start state as the primary experimental variable, (ii) introducing a deterministic, topology-aware seeding sequence that targets cache-set/TLB coverage on the actual arrays (not a separate microbenchmark), and (iii) establishing causality via a counterfactual \u2018state randomizer\u2019 that perturbs cache/TLB initial conditions between runs while keeping algorithmic work unchanged. Semantic Scholar searches returned no direct hits for the broad queries used; novelty claims will be positioned conservatively and refined with additional manual search during writing.",
        "Abstract": "HPC stencil benchmarks can exhibit unstable performance distributions on modern CPUs, with long-tail slowdowns that persist even under thread pinning and NUMA-local allocation. We propose that a hidden driver is sensitivity to the micro-architectural initial condition at the start of the timed region: run-dependent LLC/TLB state and cross-thread phase alignment can push execution into different steady-state trajectories.\n\nWe introduce Cache/TLB State Seeding (CSS), a lightweight user-level prelude that deterministically touches the benchmark\u2019s own arrays in a topology-consistent manner to establish a repeatable cache/TLB footprint before timing. CSS is paired with a convergence gate that begins measurement only once iteration time stabilizes. We evaluate CSS on the Himeno benchmark across three standard sizes (~50MB, ~400MB, ~3.2GB), reporting median MFLOPS, CV, and p95/p99 over median.\n\nTo test causality, we add a counterfactual initial-condition randomizer that perturbs cache/TLB state between runs without changing numerical work; if tails worsen under randomization and shrink under CSS, this supports initial-condition sensitivity as a real mechanism. The outcome is a portable reproducibility protocol that complements pinning/NUMA best practices by controlling micro-architectural start state rather than requiring privileged OS configuration.",
        "Experiments": [
            "Baseline distributions under best practices: For each Himeno size and two thread layouts (1-socket full cores, 2-socket full cores), run 80 repetitions with OMP_PROC_BIND=close, OMP_PLACES=cores, OMP_SCHEDULE=static, and numactl --localalloc. Record median MFLOPS, CV, p95/median, p99/median, and per-iteration timing for the first 200 iterations (to quantify warmup trajectory variability and multi-modality).",
            "Counterfactual initial-condition randomizer (causality lever): Before the timed region, execute one of two short (50\u2013200ms) perturbations excluded from timing: (A) streaming sweep over a separate buffer sized to exceed LLC (occupancy/eviction), (B) randomized pointer-chase over a page-sampled buffer (TLB/page-walk emphasis). Keep affinity fixed. Hypothesis: tails and warmup-trajectory divergence increase relative to baseline.",
            "CSS prelude (precise algorithmic change): Add a deterministic prelude that touches Himeno\u2019s own arrays. Each thread page-samples its assigned subdomain (one cache line per 4KB page) and interleaves touches across the major arrays in a fixed order matching the stencil\u2019s multi-stream pattern. End with a barrier to align phases across threads. Control knobs: seeding budget (20/50/100/200ms) and page-sampling stride (every page vs every 2\u20138 pages).",
            "Convergence-gated measurement: Replace fixed warmup with a gate: start timing when rolling-window CV of iteration time <1% for W=20 iterations (cap at 200 warmup iterations). Compare four modes: (i) baseline fixed warmup, (ii) CSS only, (iii) gating only, (iv) CSS+gating. Metrics: median MFLOPS, CV, p95/p99/median, plus overhead (extra warmup iterations and prelude time).",
            "Mechanism checks with lightweight counters (optional when available): Collect perf counters during early iterations and steady state: LLC-load-misses, dTLB-load-misses, stalled-cycles-backend. Test whether CSS reduces run-to-run variance of these counters and whether tail runs correspond to early counter anomalies. Report correlation/regression linking counter variance reduction to tail reduction.",
            "Regime dependence across sizes: Repeat all comparisons across the three footprints to test whether CSS benefits are strongest in cache/TLB-sensitive regimes (~50MB and ~400MB) and weaker in DRAM-dominated (~3.2GB), yielding a clear mechanism story.",
            "Generality check: Apply CSS+gating to a second stencil miniapp (7-point Jacobi or miniHPCG smoother). Success criterion: consistent reduction in p95/p99 and CV with \u22642\u20133% median loss in at least one additional stencil."
        ],
        "Risk Factors and Limitations": [
            "If variability is dominated by external contention (co-runners, strong OS jitter, DVFS), CSS may not reduce tails much. Mitigation: evaluate under a stabilized baseline first and use the randomizer to isolate initial-condition sensitivity; report conditional effectiveness.",
            "CSS changes benchmarking protocol and adds overhead. Mitigation: report both steady-state MFLOPS and end-to-end runtime including CSS; provide an overhead\u2013stability trade-off curve via seeding budget sweep.",
            "Architecture dependence: cache indexing/slicing details vary, so \u2018set equalization\u2019 is approximate. Mitigation: keep CSS simple (page-sampled deterministic touches) and focus on empirical distribution collapse rather than claiming perfect set control.",
            "Pointer-chase/stream randomizers may also influence DVFS/frequency residency. Mitigation: keep perturbations short, include both types, and (when possible) record APERF/MPERF or timing-based frequency proxies to rule out pure DVFS explanations.",
            "Some systems restrict perf counters. Mitigation: counters are optional; the primary evidence is distributional timing plus the counterfactual randomizer experiment."
        ]
    }
]