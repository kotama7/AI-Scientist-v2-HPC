# Glossary

This document defines key terms used in HPC-AutoResearch.

## Structure and Core Concepts

### BFTS (Best-First Tree Search)
A tree-search algorithm in which the agent builds an exploration tree and
selects the best nodes for further expansion. Each node represents one code
implementation, and new nodes are generated based on success or failure.

### Tree Search
A method that treats experiment code exploration as a tree. Starting from a root
node, the system expands branches through draft → debug → improve cycles.

### Node
A single experiment code implementation in the tree. A node runs through
Phase 0-4 and can spawn children after execution.

### Stage
A progression milestone in tree search:
- **Stage 1** (`initial_implementation`): Generate an initial implementation and verify it works
- **Stage 2** (`baseline_tuning`): Baseline tuning and evaluation on extra datasets
- **Stage 3** (`creative_research`): Creative improvements and experiment plans
- **Stage 4** (`ablation_studies`): Ablation studies and risk-factor validation

### Worker
A parallel agent process. The number of workers is set by `num_workers`, and each
worker is mapped to a GPU or CPU.

## Phase Concepts

### Phase 0 (Planning)
The planning phase. It collects environment information and generates the
Phase 1-4 execution plan.

### Phase 1 (Download/Install)
Downloads and installs dependencies inside a Singularity container using
`apt-get`, `pip install`, and source builds. The iterative installer max steps
are configured by `phase1_max_steps` (default: 100).

### Phase 2 (Coding)
Generates code files in the workspace.

### Phase 3 (Compile)
Builds code using tools like `gcc` and `make`.

### Phase 4 (Run)
Executes the built program and collects outputs (e.g., `.npy`).

### Split Mode
The default mode that explicitly separates Phase 0-4 and executes in a
Singularity container.

### Single Mode
Legacy execution mode that runs directly on the host and does not split phases.

## Memory Concepts

### MemGPT
A hierarchical memory management system. Enabled via `memory.enabled=true`
(default: enabled).

### Core Memory
Always-injected important context. The LLM manages key/value entries. Capacity
is limited by `core_max_chars` (default: 2000 chars, code fallback: 2000 chars).

### Recall Memory
A recent event timeline (node creation, compile success/failure, etc.). The
count is limited by `recall_max_events` (default: 5 events, code fallback: 20
entries).

### Archival Memory
Long-term memory with FTS5 full-text search. Stores detailed error and success
patterns. Retrieval uses top-k entries (`retrieval_k`, default: 4, code fallback: 8).

### Branch
A memory branch. Child nodes inherit parent memory, and writes are isolated to
the child branch.

### Memory Pressure
Pressure levels based on memory usage:
- **low**: below 70%
- **medium**: 70-85%
- **high**: 85-95%
- **critical**: above 95%

### LLM Compression
LLM-based text compression that preserves important information rather than
naive truncation.

## Resource Concepts

### Resource File
A JSON or YAML file defining datasets, GitHub repositories, and HuggingFace
models. Supplied via the `--resources` flag.

### Local Resource
A resource on the host system that is mounted into the container.

### Mount Path
The path inside the container where a resource is mounted (e.g.,
`/workspace/input/data`).

### Staging
Copying or symlinking resources into the workspace.

## Output Concepts

### Experiment Output Filename
The output filename for experiment results, formatted as `{experiment_name}_data.npy`
(e.g., `stability_oriented_autotuning_v2_data.npy`). This makes it clear which
experiment produced the output.

### Experiment Directory
A directory of the form `experiments/<timestamp>_<idea>_attempt_<id>/` that
contains all experiment artifacts.

### Tree Visualization
The HTML visualization of the search tree in `unified_tree_viz.html`.

### Token Tracker
Tracks LLM API token usage and writes to `token_tracker.json`.

### Final Memory
The end-of-run memory summary: `final_memory_for_paper.md` and
`final_memory_for_paper.json`.

## Paper Generation Concepts

### Plot Aggregation
Selects and aggregates plots generated by multiple nodes.

### VLM (Vision-Language Model)
A multimodal LLM used to analyze images and evaluate plot quality.

### Writeup
The process that generates a LaTeX paper from experiment results.

### Review
A NeurIPS-style automated review of the generated paper.

## Configuration Concepts

### bfts_config.yaml
Main configuration file. It is copied into each run directory under
`experiments/<run>/`.

### Persona
The agent role configured via `agent.role_description` (e.g., "HPC Researcher").
The `{persona}` token in prompts is replaced with this role; default is
"AI researcher" if not set.

### Singularity Image (SIF)
The Singularity container image, configured by `exec.singularity_image`.

### Overlay
A writable layer for Singularity containers.

## CLI Concepts

### launch_scientist_bfts.py
Main launcher script. Orchestrates idea loading → experiments → plots → writeup → review.

### generate_paper.py
Regenerates plots/writeup/review from an existing experiment directory.

### perform_ideation_temp_free.py
Generates idea JSON from workshop descriptions.

## Related Projects

### AI-Scientist-v2
The original project by Sakana AI. This fork extends it for HPC.

### AIDE
The project that inspired the tree search component.

### MemGPT
The project that introduced hierarchical memory concepts.
