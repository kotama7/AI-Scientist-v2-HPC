Your response MUST follow this exact format with TWO parts:

**PART 1: Memory Update (REQUIRED)**
Start your response with a <memory_update> block containing your memory operations.
You MUST include this block even if you have no updates (use empty object {}).

<memory_update>
{
  "mem_core_set": {"key": "value"},
  "mem_archival_write": [{"text": "insight", "tags": ["TAG"]}]
}
</memory_update>

**PART 2: Phase Artifacts (JSON)**
Immediately after the </memory_update> tag, output the JSON for the 4-phase pipeline (no markdown fences):
{
  "phase_artifacts": {
    "download": {"commands": [], "notes": "short"},
    "coding": {
      "workspace": {
        "root": "/workspace",
        "tree": ["workspace/", "workspace/src/", "workspace/working/"],
        "files": [
          {"path":"src/main.c","mode":"0644","encoding":"utf-8","content":"..."},
          {"path":"Makefile","mode":"0644","encoding":"utf-8","content":"..."}
        ]
      },
      "notes": "short"
    },
    "compile": {
      "build_plan": {
        "language": "c"|"cpp"|"fortran"|"python"|"other",
        "compiler_selected": "<one of available_compilers.name, or empty string for python>",
        "cflags": [],
        "ldflags": [],
        "workdir": "/workspace",
        "output": "bin/a.out"
      },
      "commands": ["... use {compiler_selected} or build_plan fields when templating ..."],
      "notes": "short"
    },
    "run": {
      "commands": ["..."],
      "expected_outputs": ["working/{experiment_name}_data.npy"],
      "notes": "short"
    }
  },
  "constraints": {
    "allow_sudo_in_singularity": true,
    "allow_apt_get_in_singularity": true,
    "write_only_under_workspace": true,
    "no_absolute_paths": true,
    "no_parent_traversal": true,
    "python_output_must_use_numpy": true,
    "non_python_output_must_use_npy": true
  }
}

**Memory Operations (use primitive function names):**

Write operations (stored immediately):
- "mem_core_set": {"key": "value"} - Set key-value pairs in always-visible memory
- "mem_archival_write": [{"text": "...", "tags": ["TAG"]}] - Write to long-term searchable memory
- "mem_recall_append": {"kind": "...", "content": "..."} - Append to recent events timeline

Read operations (results returned, then you re-output with the information):
- "mem_core_get": ["key1", "key2"] - Retrieve core memory values
- "mem_archival_search": {"query": "...", "k": 5} - Search long-term memory
- "mem_recall_search": {"query": "...", "k": 10} - Search recent events

Management operations:
- "mem_core_del": ["key"] - Delete keys from core memory
- "mem_recall_evict": {"oldest": N} - Move old recall events to archival
- "consolidate": true - Trigger memory consolidation

**Read Operation Flow:**
If you include read operations (mem_core_get, mem_archival_search, mem_recall_search), the system will:
1. Execute all operations (writes + reads)
2. The SYSTEM (not you) will return read results in a <memory_results> block
3. You then output your final response using the retrieved information

CRITICAL: The <memory_results> tag is OUTPUT BY THE SYSTEM ONLY. You must NEVER output <memory_results> yourself.
- DO NOT simulate or predict what the memory results might be
- DO NOT output <memory_results>...</memory_results> in your response
- If you need to read memory, include read operations in <memory_update>, then STOP and WAIT for the system to provide results
- Only output write operations and your phase_artifacts JSON in a single response

**Memory Update Guidelines:**
- Use "mem_core_set" for: optimal parameters, best configurations, key constraints, important thresholds
- Use "mem_archival_write" for: detailed explanations, lessons learned, patterns to avoid/prefer
- Do NOT record: temporary debug info, system-logged info, trivial observations
- Use read operations to retrieve past learnings before making decisions

**Example complete response:**
<memory_update>
{"mem_core_set": {"best_threads": "8"}, "mem_archival_write": [{"text": "8 threads optimal for this workload", "tags": ["PERFORMANCE"]}]}
</memory_update>
{"phase_artifacts": {"download": {"commands": [], "notes": "No downloads needed"}, ...}}

Rules and reminders:
- The <memory_update> block is MANDATORY. Missing it will cause a retry.
- NEVER output <memory_results> tags - this tag is reserved for the SYSTEM to provide read operation results. Outputting this tag yourself will cause a parse failure.
- Follow the four phases in order. Phase 1 handles downloads/installs (sudo/apt-get allowed inside Singularity with writable-tmpfs/overlay; if unavailable, install under /workspace such as pip --target /workspace/.pydeps or source builds).
- All commands will be executed inside Singularity containers; never suggest host-only actions or host package installs.
- Do not wrap commands with singularity/apptainer; provide the inner command only.
- Keep every path relative to /workspace; never emit absolute paths or parent traversal.
- In download/install, probe for tools before installing (e.g., `command -v git || sudo apt-get update && sudo apt-get install -y git`); avoid redundant installs.
- coding must list the workspace tree and every file to create; include working/ so /workspace/working/{experiment_name}_data.npy can be written.
- **Python experiments (language="python")**: Set compiler_selected to empty string (""), leave compile.commands as empty array [], and set output to "working/{experiment_name}_data.npy". The compile phase will be skipped. Run phase should execute python3 directly (e.g., "python3 src/main.py").
- **Compiled languages (c/cpp/fortran)**: compile must honor build_plan.compiler_selected taken from available_compilers; do not invent compilers or switch away from compiler_selected.
- run must produce /workspace/working/{experiment_name}_data.npy. If language is python, call numpy.save; otherwise output in .npy format (no Python post-processing for non-Python languages).
- Never mention or depend on language adapters, interpreter adapters, or external routers.
