# タスクデータのディレクトリパス
data_dir: "data"

# ログファイルの出力先ディレクトリ
log_dir: logs

# ワークスペースディレクトリ（実験作業領域）
workspace_dir: workspaces

# データをワークスペースにコピーするか（Falseの場合はシンボリックリンク）
# エージェントが元データを誤って変更することを防ぐため、コピーを推奨
copy_data: True

# 実験名（指定しない場合はランダムな名前が生成される）
exp_name: run

# コード実行環境の設定
exec:
  # Singularityコンテナイメージのパス
  singularity_image: /home/users/takanori.kotama/workplace/docker/ai-scientist-worker-nv.sif
  # GPU使用の有効化
  use_gpu: true
  # コンテナ内のワークスペースマウントポイント
  workspace_mount: /workspace
  # Phase 1の最大ステップ数
  phase1_max_steps: 100
  # プロンプトのログ記録を有効化
  log_prompts: true
  # 各コード実行のタイムアウト時間（秒）
  timeout: 7200


# メモリ・記憶管理の設定
memory:
  # メモリ機能の有効化（true: 有効, false: 無効）
  enabled: true
  # コアメモリの最大文字数
  core_max_chars: 16000
  # 想起する最大イベント数
  recall_max_events: 20
  # 検索時に取得する上位k件
  retrieval_k: 8
  # 全文検索（FTS）の使用（auto: 自動判定）
  use_fts: auto
  # 最終メモリ機能を有効化
  final_memory_enabled: true
  # 最終メモリのMarkdownファイル名
  final_memory_filename_md: final_memory_for_paper.md
  # 最終メモリのJSONファイル名
  final_memory_filename_json: final_memory_for_paper.json
  # 機密情報を編集（マスク）
  redact_secrets: true
  # メモリ予算の文字数上限
  memory_budget_chars: 24000
  # メモリログを有効化
  memory_log_enabled: true
  # メモリログの最大文字数
  memory_log_max_chars: 1600
  # LLMベースの圧縮を使用
  use_llm_compression: true
  # 圧縮に使用するLLMモデル
  compression_model: gpt-5.2
  # セクション生成モード: memory_summary | idea_then_memory
  paper_section_mode: idea_then_memory
  # 生成するセクション数（idea_then_memory時）
  paper_section_count: 12
  # 圧縮の最大試行回数
  max_compression_iterations: 5
  # セクション別の文字数予算（圧縮時の上限）
  # 注: 入力サイズ平均72,000文字に対し、圧縮率5-10倍を想定
  datasets_tested_budget_chars: 8000
  metrics_extraction_budget_chars: 12000
  plotting_code_budget_chars: 8000
  plot_selection_budget_chars: 8000
  vlm_analysis_budget_chars: 12000
  node_summary_budget_chars: 8000
  parse_metrics_budget_chars: 12000
  # アーカイブメモリ取り出し時の各エントリの文字数上限
  archival_snippet_budget_chars: 12000
  # 最終結果取得時の文字数上限
  results_budget_chars: 12000

  # Writeup用メモリ制限（final_writeup_memory.json生成時）
  # no_budget_limit=Falseの場合に適用される
  writeup_recall_limit: 10           # recall_memoryの最大件数
  writeup_archival_limit: 10         # archival_memoryの最大件数
  writeup_core_value_max_chars: 5000  # core_memoryのvalue最大文字数
  writeup_recall_text_max_chars: 5000 # recall_memoryのtext最大文字数
  writeup_archival_text_max_chars: 5000 # archival_memoryのtext最大文字数

  # Memory Pressure Management (MemGPT-style)
  # メモリ圧力管理（MemGPTスタイル）
  auto_consolidate: true                 # 自動メモリ統合を有効化
  consolidation_trigger: high            # 統合をトリガーする圧力レベル (medium/high/critical)
  recall_consolidation_threshold: 1.5    # recall_max_events * threshold を超えると統合

  max_memory_read_rounds: 3            # メモリ読み取りの最大ラウンド数

  # メモリ圧力の閾値設定
  pressure_thresholds:
    medium: 0.7    # 70%使用で中程度の圧力
    high: 0.85     # 85%使用で高い圧力
    critical: 0.95 # 95%使用で危機的な圧力

# レポート生成を有効化
generate_report: True

# 最終レポート生成のLLM設定
report:
  # 使用するLLMモデル
  model: gpt-5.2
  # 温度パラメータ（生成の多様性: 0.0-2.0）
  temp: 1.0

# 実験の設定
experiment:
  # 合成データセットの数
  num_syn_datasets: 1
  # データセットのソース（local, huggingface, auto）
  # auto: LLMが自動判定
  dataset_source: auto

# エージェントのハイパーパラメータ
agent:
  # エージェントのタイプ（並列処理）
  type: parallel
  # 並列ワーカー数
  num_workers: 4
  # 各ステージの最大反復回数
  stages:
    stage1_max_iters: 20
    stage2_max_iters: 20
    stage3_max_iters: 40
    stage4_max_iters: 20
  # 改善反復の実行回数（ステージ別max_itersが未指定の場合に使用）
  steps: 5
  # マルチシード評価の設定
  multi_seed_eval:
    # 評価に使用するシード数（num_workers < 3の場合はnum_workersと同じ、それ以外は3）
    num_seeds: 3
  # プロンプトに注入される役割の説明
  role_description: "HPC Researcher"

  # コーディング用LLM設定
  code:
    model: gpt-5.2
    temp: 1.0

  # プログラム出力・トレースバック評価用LLM設定
  feedback:
    model: gpt-5.2
    temp: 0.5

  # ビジョン言語モデルのフィードバック設定
  vlm_feedback:
    model: gpt-5.2
    temp: 0.5

  # 探索の設定
  search:
    # デバッグの最大深度
    max_debug_depth: 3
    # デバッグを実行する確率
    debug_prob: 0.5
    # ドラフト数
    num_drafts: 3

  # 結果サマリー生成用LLM設定
  summary:
    model: gpt-5.2
    temp: 0.3

  # 最適ノード選択用LLM設定
  select_node:
    model: gpt-5.2
    temp: 0.3
